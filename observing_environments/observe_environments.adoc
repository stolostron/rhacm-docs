[#observing-environments]
= Observing environments

You can use {product-title} to gain insight and optimize your managed clusters. Enable the observability service operator, `multicluster-observability-operator`, to monitor the health of your managed clusters. Learn about the architecture for the multicluster observability service in the following sections. 

image:../images/RHACM-ObservabilityArch.png[Multicluster observability architecture]

*Note*: The _on-demand log_ provides access for engineers to get logs for a given pod in real-time. Logs from the hub cluster are not aggregated. These logs can be accessed with the search service and other parts of the console.

* <<observability-service,Observability service>>
* <<observability-certificates,Observability certificates>>
* <<metric-types,Metric types>>
* <<observability-pod-capacity-requests,Observability pod capacity requests>>
* <<persistent-stores-observability,Persistent stores used in the observability service>>

[#observability-service]
== Observability service

By default, observability is included with the product installation, but not enabled. Due to the requirement for persistent storage, the observability service is not enabled by default. {product-title-short} supports the following stable object stores:

- Amazon S3 (or other S3 compatible object stores like Ceph)
- Google Cloud Storage
- Azure storage
- OpenShift Container Storage

When the service is enabled, the `observability-endpoint-operator` is automatically deployed to each imported or created cluster. This controller collects the data from {ocp} Prometheus, then sends it to the {product-title-short} hub cluster. 

When observability is enabled in a hub cluster, metrics are collected by handling the hub cluster as a managed cluster called `local-cluster`.
  
*Note*: In {product-title-short} the `metrics-collector` is only supported for {ocp} 4.x clusters. 

The observability service deploys an instance of Prometheus AlertManager, which enables alerts to be forwarded with third-party applications. It also includes an instance of Grafana to enable data visualization with dashboards (static) or data exploration. {product-title-short} supports version 6.4.x of Grafana. You can also design your Grafana dashboard. For more information, see xref:../observing_environments/design_grafana.adoc#designing-your-grafana-dashboard[Designing your Grafana dashboard].

You can customize the observability service by creating custom https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/[recording rules] or https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[alerting rules].

For more information about enabling observability, see xref:../observing_environments/observability_enable.adoc#enable-observability[Enable observability service].

[#observability-certificates]
=== Observability certificates

Observability certificates are automatically renewed upon expiration. View the following list to understand the effects when certificates are automatically renewed:

* Components on your hub cluster automatically restart to retrieve the renewed certificate.
* {product-title-short} sends the renewed certificates to managed clusters.
* The `metrics-collector` restarts to mount the renewed certificates.
+
*Note:* `metrics-collector` can push metrics to the hub cluster before and after certificates are removed. For more information about refreshing certificates across your clusters, see link:../security/certificates.adoc#refresh-a-managed-certificate[Refresh a managed certificate].

[#metric-types]
=== Metric types

By default, {ocp-short} sends metrics to Red Hat using the Telemetry service. The following additional metrics are available with {product-title-short} and are included with telemetry, but are _not_ displayed on the {product-title-short} _Observe environments overview_ dashboard:

- The `visual_web_terminal_sessions_total` is collected on the hub cluster.
- The `acm_managed_cluster_info` is collected on each managed cluster and sent to the hub cluster.

Learn from the {ocp-short} documentation what types of metrics are collected and sent using telemetry. See https://access.redhat.com/documentation/en-us/openshift_container_platform/4.7/html-single/support/index#about-remote-health-monitoring[Information collected by Telemetry] for information. 

[#observability-pod-capacity-requests]
=== Observability pod capacity requests

Observability components require 2636mCPU and 11388Mi memory to install the observability service. View the following table of the pod capacity requests that is for five managed clusters with `observability-addons` enabled:

.Observability pod capacity requests
|===
| Deployment or StatefulSet | Container name  | CPU (mCPU) | Memory (Mi) | Replicas | Pod total CPU | Pod total memory

.2+| alertmanager
|alertmanager
| 4
| 200
| 3
| 12
| 600

| config-reloader
| 4
| 25
| 3
| 12
| 75

.2+| grafana
| grafana
| 4
| 100
| 2
| 8
| 200

| grafana-dashboard-loader
| 4
| 50
| 2
| 8
| 100

| observability-observatorium-observatorium-api
| observatorium-api
| 20
| 128
| 2
| 40
| 256

| observability-observatorium-thanos-compact
| thanos-compact
| 100
| 512
| 1
| 100
| 512

| observability-observatorium-thanos-query
| thanos-query
| 300
| 1024
| 2
| 600
| 2048

| observability-observatorium-thanos-query-frontend
| thanos-query-frontend
| 100
| 256
| 2
| 200
| 512

| observability-observatorium-thanos-receive-controller
| thanos-receive-controller
| 4
| 32
| 1
| 4
| 32

| observability-observatorium-thanos-receive-default
| thanos-receive
| 300
| 512
| 3
| 900
| 1536

.2+| observability-observatorium-thanos-rule
| thanos-rule
| 50
| 512
| 3
| 150
| 1536

| configmap-reloader
| 4
| 25
| 3
| 12
| 75

.2+| observability-observatorium-thanos-store-memcached
| memcached
| 45
| 128
| 3
| 135
| 384

| exporter
| 5
| 50
| 3
| 15
| 150

| observability-observatorium-thanos-store-shard
| thanos-store
| 100
| 1024
| 3
| 300
| 3072

| observatorium-operator
| observatorium-operator
| 100
| 100
| 1
| 100
| 100

| rbac-query-proxy
| rbac-query-proxy
| 20
| 100
| 2
| 40
| 200
|===

[#persistent-stores-observability]
== Persistent stores used in the observability service

When you install {product-title-short} the following persistent volumes are created:

.Table list of persistent volumes
|===
| Persistent volume name | Purpose 
| alertmanager 
| Alertmanager stores the `nflog` data and silenced alerts in its storage. `nflog` is an append-only log of active and resolved notifications along with the notified receiver, and a hash digest of contents that the notificationn identified.

| thanos-compact 
| The compactor needs local disk space to store intermediate data for its processing, as well as bucket state cache. The required space depends on the size of the underlying blocks. The compactor must have enough space to download all of the source blocks, then build the compacted blocks on the disk. On-disk data is safe to delete between restarts and should be the first attempt to get crash-looping compactors unstuck. However, it is recommended to give the compactor persistent disks in order to effectively use bucket state cache in between restarts.

| thanos-rule 
| The thanos ruler evaluates Prometheus recording and alerting rules against a chosen query API by issuing queries at a fixed interval. Rule results are written back to the disk in the Prometheus 2.0 storage format. 

| thanos-receive-default 
| Thanos receiver accepts incoming data (Prometheus remote-write requests) and writes these into a local instance of the Prometheus TSDB. Periodically (every 2 hours), TSDB blocks are uploaded to the object storage for long term storage and compaction.

| thanos-store-shard| It acts primarily as an API gateway and therefore does not need significant amounts of local disk space. It joins a Thanos cluster on startup and advertises the data it can access. It keeps a small amount of information about all remote blocks on local disk and keeps it in sync with the bucket. This data is generally safe to delete across restarts at the cost of increased startup times.
|===

*Note*: The time series historical data is stored in object stores. Thanos uses object storage as the primary storage for metrics and meta data related to them. For more details about the object storage and downsampling, see xref:../observing_environments/observe_environments.adoc#enable-observability[Enable observability service].
