[#known-issues-continuity]
= Business continuity known issues

////
Please follow this format:

Title of known issue, be sure to match header and make title, header unique

Hidden comment: Release: #issue
Known issue process and when to write:

- Doesn't work the way it should
- Straightforward to describe
- Good to know before getting started
- Quick workaround, of any
- Applies to most, if not all, users
- Something that is likely to be fixed next release (never preannounce)
- Always comment with the issue number and version: //2.4:19417
- Link to customer BugZilla ONLY if it helps; don't link to internal BZs and GH issues.

Or consider a troubleshooting topic.
////

Review the known issues for {acm}. The following list contains known issues for this release, or known issues that continued from the previous release. 

For your {ocp} cluster, see link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/release_notes/ocp-4-12-release-notes#ocp-4-12-known-issues[{ocp-short} known issues]. 

For more about deprecations and removals, see xref:../release_notes/deprecate_remove.adoc#deprecations-removals[Deprecations and removals].

[#known-issues-backup-restore]
== Backup and restore known issues

Backup and restore known issues and limitations are listed here, along with workarounds if they are available.

[#open-cluster-namespace-stuck-terminating]
=== The _open-cluster-management-backup_ namespace is stuck in the _Terminating_ state
//2.10:ACM-10292

When the cluster-backup component is disabled on the `MultiClusterHub` resource, the `open-cluster-management-backup` namespace is stuck in the `Terminating` state if you have a Velero restore resource created by a {acm-short} restore operation.

The `Terminating` state is a result of the Velero restore resources waiting on the `restores.velero.io/external-resources-finalizer` to complete. To workaround this issue, complete the following steps:

. Delete all {acm-short} restore resources and wait for the Velero restore to be cleaned up before you disable the cluster backup option on the `MultiClusterHub` resource. 
. If your `open-cluster-management-backup` namespace is already stuck in the `Terminating` state, edit all the Velero restore resources and remove the finalizers. 
. Allow the Velero resources to delete the namespaces and resources. 

[#bare-metal-resources]
=== Bare metal hub resource no longer backed up by the managed clusters backup
//2.11:ACM-11766

If the resources for the bare metal cluster are backed up and restored to a secondary hub cluster by using the {acm-short} back up and restore feature, the managed cluster reinstalls on the nodes, which destroys the existing managed cluster. 

*Note:* This only affects bare metal clusters that were deployed by using zero touch provisioning, meaning that they have `BareMetalHost` resources that manage powering on and off bare metal nodes and attaching virtual media for booting. If a `BareMetalHost` resource was not used in the deployment of the managed cluster, there is no negative impact.

To work around this issue, the `BareMetalHost` resources on the primary hub cluster are no longer backed up with the managed cluster backup.

If you have a different use case and want the managed `BareMetalHost` resources on the primary hub cluster to be backed up, add the following backup label to the `BareMetalHost` resources on the primary hub cluster: `cluster.open-cluster-management.io/backup`.

To learn more about using this backup label to backup generic resources, see the topic, link:../business_continuity/backup_restore/backup_arch.adoc#resources-that-are-backed-up[Resources that are backed up]. 
 

[#restore-limitations]
=== Velero restore limitations

A new hub cluster can have a different configuration than the active hub cluster if the new hub cluster, where the data is restored, has user-created resources. For example, this can include an existing policy that was created on the new hub cluster before the backup data is restored on the new hub cluster.

Velero skips existing resources if they are not part of the restored backup, so the policy on the new hub cluster remains unchanged, resulting in a different configuration between the new hub cluster and active hub cluster.

To address this limitation, the cluster backup and restore operator runs a post restore operation to clean up the resources created by the user or a different restore operation when a `restore.cluster.open-cluster-management.io` resource is created.

For more information, see the link:../business_continuity/backup_restore/backup_restore.adoc#clean-hub-restore[Cleaning the hub cluster after restore] topic. 

[#imported-clusters-not-displayed]
=== Passive configurations do not display managed clusters

Managed clusters are only displayed when the activation data is restored on the passive hub cluster.

[#managed-cluster-resources-not-restored]
=== Managed cluster resource not restored
//2.5:22402

When you restore the settings for the `local-cluster` managed cluster resource and overwrite the `local-cluster` data on a new hub cluster, the settings are misconfigured. Content from the previous hub cluster `local-cluster` is not backed up because the resource contains `local-cluster` specific information, such as the cluster URL details.

You must manually apply any configuration changes that are related to the `local-cluster` resource on the restored cluster. See _Prepare the new hub cluster_ in the link:../business_continuity/backup_restore/backup_install.adoc#dr4hub-install-backup-and-restore[Installing the backup and restore operator] topic.

[#restored-hive-managed-clusters-unable-new-hub]
=== Restored Hive managed clusters might not be able to connect with the new hub cluster
//2.6:23930

When you restore the backup of the changed or rotated certificate of authority (CA) for the Hive managed cluster, on a new hub cluster, the managed cluster fails to connect to the new hub cluster. The connection fails because the `admin` `kubeconfig` secret for this managed cluster, available with the backup, is no longer valid. 

You must manually update the restored `admin` `kubeconfig` secret of the managed cluster on the new hub cluster.

[#imported-managed-clusters-pending-import]
=== Imported managed clusters show a _Pending Import_ status
//2.7:26797

Managed clusters that are manually imported on the primary hub cluster show a `Pending Import` status when the activation data is restored on the passive hub cluster. For more information, see link:../business_continuity/backup_restore/backup_msa.adoc#auto-connect-clusters-msa[Connecting clusters by using a Managed Service Account].

[#appliedmanifestwork-not-removed]
=== The _appliedmanifestwork_ is not removed from managed clusters after restoring the hub cluster
//2.7:27129

When the hub cluster data is restored on the new hub cluster, the `appliedmanifestwork` is not removed from managed clusters that have a placement rule for an application subscription that is not a fixed cluster set.

See the following example of a placement rule for an application subscription that is not a fixed cluster set:

[source,yaml]
----
spec:
  clusterReplicas: 1
  clusterSelector:
    matchLabels:
      environment: dev
----

As a result, the application is orphaned when the managed cluster is detached from the restored hub cluster.

To avoid the issue, specify a fixed cluster set in the placement rule. See the following example:

[source,yaml]
----
spec:
  clusterSelector:
    matchLabels:
      environment: dev
----

You can also delete the remaining `appliedmanifestwork` manually by running the folowing command:

----
oc delete appliedmanifestwork <the-left-appliedmanifestwork-name>
----

[#appliedmanifest-agentid-missing]
=== The _appliedmanifestwork_ not removed and _agentID_ is missing in the specification
//2.7+:ACM-7588

When you are using {acm-short} 2.6 as your primary hub cluster, but your restore hub cluster is on version 2.7 or later, the `agentID` is missing in the specification of `appliedmanifestworks` because the field is introduced in the 2.7 release. This results in the extra `appliedmanifestworks` for the primary hub on the managed cluster.

To avoid the issue, upgrade the primary hub cluster to {acm-short} 2.7, then restore the backup on a new hub cluster.

Fix the managed clusters by setting the `spec.agentID` manually for each `appliedmanifestwork`.

. Run the following command to get the `agentID`: 
+
----
oc get klusterlet klusterlet -o jsonpath='{.metadata.uid}'
----

. Run the following command to set the `spec.agentID` for each `appliedmanifestwork`:
+
----
oc patch appliedmanifestwork <appliedmanifestwork_name> --type=merge -p '{"spec":{"agentID": "'$AGENT_ID'"}}'  
----

[#msa-status-unknown]
=== The _managed-serviceaccount_ add-on status shows _Unknown_
//2.8:ACM-5887

The managed cluster `appliedmanifestwork` `addon-managed-serviceaccount-deploy` is removed from the imported managed cluster if you are using the Managed Service Account without enabling it on the {mce} resource of the new hub cluster.

The managed cluster is still imported to the new hub cluster, but 
the `managed-serviceaccount` add-on status shows `Unknown`.
 
You can recover the `managed-serviceaccount` add-on after enabling the Managed Service Account in the {mce-short} resource. See link:../business_continuity/backup_restore/backup_msa.adoc#enabling-auto-import[Enabling automatic import] to learn how to enable the Managed Service Account.

[#known-issues-volsync]
== Volsync known issues

[#volsync-remove-csv-managed]
=== Manual removal of the VolSync CSV required on managed cluster when removing the add-on
//2.5:21356

When you remove the VolSync `ManagedClusterAddOn` from the hub cluster, it removes the VolSync operator subscription on the managed cluster but does not remove the cluster service version (CSV). To remove the CSV from the managed clusters, run the following command on each managed cluster from which you are removing VolSync:

----
oc delete csv -n openshift-operators volsync-product.v0.6.0
----