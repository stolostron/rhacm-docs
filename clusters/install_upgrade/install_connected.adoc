[#installing-while-connected-online-mce]
= Installing while connected online

The {mce-short} is installed with Operator Lifecycle Manager, which manages the installation, upgrade, and removal of the components that encompass the {mce-short}.

*Required access:* Cluster administrator

*Important:* 

- For OpenShift Container Platform Dedicated environment, you must have `cluster-admin` permissions. By default `dedicated-admin` role does not have the required permissions to create namespaces in the OpenShift Container Platform Dedicated environment. 

- By default, the {mce-short} components are installed on worker nodes of your OpenShift Container Platform cluster without any additional configuration. You can install {mce-short} onto worker nodes by using the OpenShift Container Platform OperatorHub web console interface, or by using the OpenShift Container Platform CLI.

- If you have configured your OpenShift Container Platform cluster with infrastructure nodes, you can install {mce-short} onto those infrastructure nodes by using the OpenShift Container Platform CLI with additional resource parameters. Not all of the {mce-short} components have infrastructure node support, so some worker nodes are still required when installing {mce-short} on infrastructure nodes. See the _Installing multicluster engine on infrastructure nodes_ section for those details.

- If you plan to import Kubernetes clusters that were not created by OpenShift Container Platform or 
multicluster engine for Kubernetes, you will need to configure an image pull secret. For information on how to configure an image pull secret and other advanced configurations, see options in the xref:./adv_config_install#advanced-config-engine[Advanced configuration] section of this documentation. 

* <<connect-prerequisites-mce,Prerequisites>>
* <<confirm-ocp-installation-mce,Confirm your OpenShift Container Platform installation>>
* <<installing-from-the-operatorhub-mce,Installing from the OperatorHub web console interface>>
* <<installing-from-the-cli-mce,Installing from the OpenShift Container Platform CLI>>
* <<installing-on-infra-node-mce,Installing multicluster engine on infrastructure nodes>>

[#connect-prerequisites-mce]
== Prerequisites

Before you install multicluster engine for Kubernetes, see the following requirements:

* Your Red Hat OpenShift Container Platform cluster must have access to the {mce-short} in the OperatorHub catalog from the OpenShift Container Platform console. 

* You need access to the https://catalog.redhat.com/software/containers/search?p=1&application_categories_list=Container%20Platform%20%2F%20Management[catalog.redhat.com].

* OpenShift Container Platform version 4.8, or later, must be deployed in your environment, and you must be logged into with the OpenShift Container Platform CLI. See the following install documentation for OpenShift Container Platform:

  - https://access.redhat.com/documentation/en-us/openshift_container_platform/4.8/html/installing/index[OpenShift Container Platform version 4.8]
  - https://access.redhat.com/documentation/en-us/openshift_container_platform/4.9/html/installing/index[OpenShift Container Platform version 4.9]
  - https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/installing/index[OpenShift Container Platform version 4.10]
  - https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html/installing/index[OpenShift Container Platform version 4.11]
  

* Your OpenShift Container Platform command line interface (CLI) must be configured to run `oc` commands. See https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/cli_tools/openshift-cli-oc#cli-getting-started[Getting started with the CLI] for information about installing and configuring the OpenShift Container Platform CLI.

* Your OpenShift Container Platform permissions must allow you to create a namespace.

* You must have an Internet connection to access the dependencies for the operator.

* To install in a OpenShift Container Platform Dedicated environment, see the following:

** You must have the OpenShift Container Platform Dedicated environment configured and running.

** You must have `cluster-admin` authority to the OpenShift Container Platform Dedicated environment where you are installing the engine.

* If you plan to create managed clusters by using the Assisted Installer that is provided with {ocp}, see link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/installing/installing-on-premise-with-assisted-installer#preparing-to-install-with-ai[Preparing to install with the Assisted Installer] topic in the OpenShift Container Platform documentation for the requirements. 

[#confirm-ocp-installation-mce]
== Confirm your OpenShift Container Platform installation

You must have a supported OpenShift Container Platform version, including the registry and storage services, installed and working. For more information about installing OpenShift Container Platform, see the OpenShift Container Platform documentation.

. Verify that {mce-short} is not already installed on your OpenShift Container Platform cluster. The {mce-short} allows only one single installation on each OpenShift Container Platform cluster. Continue with the following steps if there is no installation.

. To ensure that the OpenShift Container Platform cluster is set up correctly, access the OpenShift Container Platform web console with the following command:

+
----
kubectl -n openshift-console get route console
----
+
See the following example output:
+
----
console console-openshift-console.apps.new-coral.purple-chesterfield.com               
console   https   reencrypt/Redirect     None
----

. Open the URL in your browser and check the result. If the console URL displays `console-openshift-console.router.default.svc.cluster.local`, set the value for `openshift_master_default_subdomain` when you install OpenShift Container Platform. See the following example of a URL: `https://console-openshift-console.apps.new-coral.purple-chesterfield.com`.

You can proceed to install 
{mce-short}.

[#installing-from-the-operatorhub-mce]
== Installing from the OperatorHub web console interface

**Best practice:** From the _Administrator_ view in your OpenShift Container Platform navigation, install the OperatorHub web console interface that is provided with OpenShift Container Platform.

. Select *Operators* > *OperatorHub* to access the list of available operators, and select _multicluster engine for Kubernetes_ operator.

. Click `Install`.

. On the _Operator Installation_ page, select the options for your installation:

+
* Namespace: 

  - The {mce-short} engine must be installed in its own namespace, or project. 

  - By default, the OperatorHub console installation process creates a namespace titled `multicluster-engine`. *Best practice:* Continue to use the `multicluster-engine` namespace if it is available.  
  
  - If there is already a namespace named `multicluster-engine`, select a different namespace.

+
* Channel: The channel that you select corresponds to the release that you are installing. When you select the channel, it installs the identified release, and establishes that the future errata updates within that release are obtained.

+
* Approval strategy: The approval strategy identifies the human interaction that is required for applying updates to the channel or release to which you subscribed. 

  - Select *Automatic*, which is selected by default, to ensure any updates within that release are automatically applied. 
  
  - Select *Manual* to receive a notification when an update is available. If you have concerns about when the updates are applied, this might be best practice for you.

+
*Note:* To upgrade to the next minor release, you must return to the _OperatorHub_ page and select a new channel for the more current release.

. Select *Install* to apply your changes and create the operator. 

. See the following process to create the _MultiClusterEngine_ custom resource.
 .. In the OpenShift Container Platform console navigation, select *Installed Operators* > *multicluster engine for Kubernetes*.
 .. Select the *MultiCluster Engine* tab.
 .. Select *Create MultiClusterEngine*.
 .. Update the default values in the YAML file. See options in the _MultiClusterEngine advanced configuration_ section of the documentation.

* The following example shows the default template that you can copy into the editor:

+
[source,yaml]
----
apiVersion: multicluster.openshift.io/v1
kind: MultiClusterEngine
metadata:
  name: multiclusterengine
spec: {}
----

+ 
. Select *Create* to initialize the custom resource. It can take up to 10 minutes for the 
{mce-short} engine to build and start.

+
After the _MultiClusterEngine_ resource is created, the status for the resource is `Available` on the _MultiCluster Engine_ tab.

[#installing-from-the-cli-mce]
== Installing from the OpenShift Container Platform CLI

. Create a {mce-short} engine namespace where the operator requirements are contained. Run the following command, where `namespace` is the name for your 
multicluster engine for Kubernetes engine namespace. The value for `namespace` might be referred to as _Project_ in the OpenShift Container Platform environment:

+
----
oc create namespace <namespace>
----

. Switch your project namespace to the one that you created. Replace `namespace` with the name of the 
multicluster engine for Kubernetes engine namespace that you created in step 1.

+
----
oc project <namespace>
----

. Create a YAML file to configure an `OperatorGroup` resource. Each namespace can have only one operator group. Replace `default` with the name of your operator group. Replace `namespace` with the name of your project namespace. See the following example:
+
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: <default>
spec:
  targetNamespaces:
  - <namespace>
----
. Run the following command to create the `OperatorGroup` resource. Replace `operator-group` with the name of the operator group YAML file that you created:

+
----
oc apply -f <path-to-file>/<operator-group>.yaml
----
+

. Create a YAML file to configure an OpenShift Container Platform Subscription. Your file should look similar to the following example:

+
[source,yaml]
----
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: multicluster-engine
spec:
  sourceNamespace: openshift-marketplace
  source: redhat-operators
  channel: stable-2.1
  installPlanApproval: Automatic
  name: multicluster-engine
----

+
*Note:* For installing the multicluster engine for Kubernetes engine on infrastructure nodes, the see xref:./install_connected.adoc#infra-olm-sub-add-config-mce[Operator Lifecycle Manager Subscription additional configuration] section.

+
. Run the following command to create the OpenShift Container Platform Subscription. Replace `subscription` with the name of the subscription file that you created:

+
----
oc apply -f <path-to-file>/<subscription>.yaml
----

. Create a YAML file to configure the `MultiClusterEngine` custom resource. Your default template should look similar to the following example:

+
[source,yaml]
----
apiVersion: multicluster.openshift.io/v1
kind: MultiClusterEngine
metadata:
  name: multiclusterengine
spec: {}
----

+
*Note:* For installing the {mce-short} on infrastructure nodes, see the xref:./install_connected.adoc#infra-mce-add-config[MultiClusterEngine custom resource additional configuration] section:

+
. Run the following command to create the `MultiClusterEngine` custom resource. Replace `custom-resource` with the name of your custom resource file:
 
+
----
oc apply -f <path-to-file>/<custom-resource>.yaml
----

+
If this step fails with the following error, the resources are still being created and applied. Run the command again in a few minutes when the resources are created:

+
----
error: unable to recognize "./mce.yaml": no matches for kind "MultiClusterEngine" in version "operator.multicluster-engine.io/v1"
----

. Run the following command to get the custom resource. It can take up to 10 minutes for the `MultiClusterEngine` custom resource status to display as `Available` in the `status.phase` field after you run the following command:

+
----
oc get mce -o=jsonpath='{.items[0].status.phase}'
----

If you are reinstalling the {mce-short} and the pods do not start, see xref:./uninstall.adoc#troubleshoot-uninstall-mce[Troubleshooting reinstallation failure] for steps to work around this problem.

*Notes:*

- A `ServiceAccount` with a `ClusterRoleBinding` automatically gives cluster administrator privileges to 
{mce-short} and to any user credentials with access to the namespace where you install 
{mce-short}.

[#installing-on-infra-node-mce]
== Installing on infrastructure nodes

An OpenShift Container Platform cluster can be configured to contain infrastructure nodes for running approved management components. Running components on infrastructure nodes avoids allocating OpenShift Container Platform subscription quota for the nodes that are running those management components.

After adding infrastructure nodes to your OpenShift Container Platform cluster, follow the xref:./install_connected.adoc#installing-from-the-cli-mce[Installing from the OpenShift Container Platform CLI] instructions and add the following configurations to the  Operator Lifecycle Manager Subscription and `MultiClusterEngine` custom resource.

[#adding-infra-nodes-mce]
=== Add infrastructure nodes to the OpenShift Container Platform cluster

Follow the procedures that are described in
https://access.redhat.com/documentation/en-us/openshift_container_platform/4.8/html/machine_management/creating-infrastructure-machinesets[Creating infrastructure machine sets] in the OpenShift Container Platform documentation. Infrastructure nodes are configured with a Kubernetes `taint` and `label` to keep non-management workloads from running on them.

To be compatible with the infrastructure node enablement provided by 
{mce-short}, ensure your infrastructure nodes have the following `taint` and `label` applied:

[source,yaml]
----
metadata:
  labels:
    node-role.kubernetes.io/infra: ""
spec:
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/infra
----

[#infra-olm-sub-add-config-mce]
=== Operator Lifecycle Manager Subscription additional configuration

Add the following additional configuration before applying the Operator Lifecycle Manager Subscription:

[source,yaml]
----
spec:
  config:
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    tolerations:
    - key: node-role.kubernetes.io/infra
      effect: NoSchedule
      operator: Exists
----

[#infra-mce-add-config]
=== MultiClusterEngine custom resource additional configuration

Add the following additional configuration before applying the `MultiClusterEngine` custom resource:

[source,yaml]
----
spec:
  nodeSelector:
    node-role.kubernetes.io/infra: ""
----
