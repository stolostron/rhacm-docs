[#upgrading-disconnected-cluster]
= Upgrading a disconnected cluster

You can use {cincinnati} with {mce-short} to upgrade cluster in a disconnected environment.

In some cases, security concerns prevent clusters from being connected directly to the internet. This makes it difficult to know when upgrades are available, and how to process those upgrades. Configuring {cincinnati-short} can help. 

{cincinnati-short} is a separate operator and operand that monitors the available versions of your managed clusters in a disconnected environment, and makes them available for upgrading your clusters in a disconnected environment. After {cincinnati-short} is configured, it can perform the following actions:

* Monitor when upgrades are available for your disconnected clusters.
* Identify which updates are mirrored to your local site for upgrading by using the graph data file.
* Notify you that an upgrade is available for your cluster by using the console.

The following topics explain the procedure for upgrading a disconnected cluster: 

* <<cincinnati-prerequisites,Prerequisites>>
* <<prepare-your-disconnected-mirror-registry,Prepare your disconnected mirror registry>>
* <<deploy-the-operator-for-cincinnati,Deploy the operator for {cincinnati-short}>>
* <<build-the-graph-data-init-container,Build the graph data init container>>
* <<configure-certificate-for-the-mirrored-registry,Configure certificate for the mirrored registry>>
* <<deploy-the-cincinnati-instance,Deploy the {cincinnati-short} instance>>
* <<override-the-default-registry,Override the default registry (optional)>>
* <<deploy-a-disconnected-catalog-source,Deploy a disconnected catalog source>>
* <<change-the-managed-cluster-parameter,Change the managed cluster parameter>>
* <<viewing-available-upgrades,Viewing available upgrades>>
* <<selecting-a-channel-discon,Selecting a channel>>
* <<upgrading-the-cluster,Upgrading the cluster>>

[#cincinnati-prerequisites]
== Prerequisites

You must have the following prerequisites before you can use {cincinnati-short} to upgrade your disconnected clusters:

* A deployed hub cluster that is running on {ocp} version 4.12 or later with restricted OLM configured. See link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html-single/operators/index#olm-restricted-networks[Using Operator Lifecycle Manager on restricted networks] for details about how to configure restricted OLM. 
+
*Note:* Make a note of the catalog source image when you configure restricted OLM.
* An {ocp-short} cluster that is managed by the hub cluster
* Access credentials to a local repository where you can mirror the cluster images. See link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/installing/disconnected-installation-mirroring[Disconnected installation mirroring] for more information about how to create this repository.
+
*Note:* The image for the current version of the cluster that you upgrade must always be available as one of the mirrored images. If an upgrade fails, the cluster reverts back to the version of the cluster at the time that the upgrade was attempted.

[#prepare-your-disconnected-mirror-registry]
== Prepare your disconnected mirror registry

You must mirror both the image that you want to upgrade to and the current image that you are upgrading from to your local mirror registry. Complete the following steps to mirror the images:

. Create a script file that contains content that resembles the following example:
+
----
UPSTREAM_REGISTRY=quay.io
PRODUCT_REPO=openshift-release-dev
RELEASE_NAME=ocp-release
OCP_RELEASE=4.12.2-x86_64
LOCAL_REGISTRY=$(hostname):5000
LOCAL_SECRET_JSON=/path/to/pull/secret <1>

oc adm -a ${LOCAL_SECRET_JSON} release mirror \
--from=${UPSTREAM_REGISTRY}/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE} \
--to=${LOCAL_REGISTRY}/ocp4 \
--to-release-image=${LOCAL_REGISTRY}/ocp4/release:${OCP_RELEASE}
----
+
<1> Replace `/path/to/pull/secret` with the path to your {ocp-short} pull secret.

. Run the script to mirror the images, configure settings, and separate the release images from the release content.
+
You can use the output of the last line of this script when you create your `ImageContentSourcePolicy`.

[#deploy-the-operator-for-cincinnati]
== Deploy the operator for {cincinnati-short}

To deploy the operator for {cincinnati-short} in your {ocp-short} environment, complete the following steps:

. On the hub cluster, access the {ocp-short} operator hub. 
. Deploy the operator by selecting `{cincinnati} Operator`. Update the default values, if necessary. The deployment of the operator creates a new project named `openshift-cincinnati`.
. Wait for the installation of the operator to finish. 
+
You can check the status of the installation by entering the `oc get pods` command on your {ocp-short} command line. Verify that the operator is in the `running` state.

[#build-the-graph-data-init-container]
== Build the graph data init container

{cincinnati-short} uses graph data information to determine the available upgrades. In a connected environment, {cincinnati-short} pulls the graph data information for available upgrades directly from the link:https://github.com/openshift/cincinnati-graph-data[Cincinnati graph data GitHub repository]. Because you are configuring a disconnected environment, you must make the graph data available in a local repository by using an `init container`. Complete the following steps to create a graph data `init container`:

. Clone the _graph data_ Git repository by entering the following command:
+
----
git clone https://github.com/openshift/cincinnati-graph-data
----

. Create a file that contains the information for your graph data `init`. You can find this sample link:https://github.com/openshift/cincinnati-operator/blob/master/dev/Dockerfile[Dockerfile] in the `cincinnati-operator` GitHub repository. The contents of the file is shown in the following sample:
+
----
FROM registry.access.redhat.com/ubi8/ubi:8.1 <1>

RUN curl -L -o cincinnati-graph-data.tar.gz https://github.com/openshift/cincinnati-graph-data/archive/master.tar.gz <2>

RUN mkdir -p /var/lib/cincinnati/graph-data/ <2>

CMD exec /bin/bash -c "tar xvzf cincinnati-graph-data.tar.gz -C /var/lib/
cincinnati/graph-data/ --strip-components=1"  <3>
----
+
In this example:
+
<1> The `FROM` value is the external registry where {cincinnati-short} finds the images.
+
<2> The `RUN` commands create the directory and package the upgrade files. 
+
<3> The `CMD` command copies the package file to the local repository and extracts the files for an upgrade.

. Run the following commands to build the `graph data init container`:
+
----
podman build -f <path_to_Dockerfile> -t <${DISCONNECTED_REGISTRY}/cincinnati/cincinnati-graph-data-container>:latest <1> <2>
podman push <${DISCONNECTED_REGISTRY}/cincinnati/cincinnati-graph-data-container><2>:latest --authfile=</path/to/pull_secret>.json <3>
----
+
<1> Replace `path_to_Dockerfile` with the path to the file that you created in the previous step.
+
<2> Replace `${DISCONNECTED_REGISTRY}/cincinnati/cincinnati-graph-data-container` with the path to your local graph data init container.
+
<3> Replace `/path/to/pull_secret` with the path to your pull secret file.
+
*Note:* You can also replace `podman` in the commands with `docker`, if you don't have `podman` installed.

[#configure-certificate-for-the-mirrored-registry]
== Configure certificate for the mirrored registry 

If you are using a secure external container registry to store your mirrored {ocp-short} release images, {cincinnati-short} requires access to this registry to build an upgrade graph. Complete the following steps to configure your CA certificate to work with the {cincinnati-short} pod:

. Find the {ocp-short} external registry API, which is located in `image.config.openshift.io`. This is where the external registry CA certificate is stored.  
+
See link:https://docs.openshift.com/container-platform/4.12/registry/configuring-registry-operator.html#images-configuration-cas_configuring-registry-operator[Configuring additional trust stores for image registry access] in the {ocp-short} documentation for more information.

. Create a ConfigMap in the `openshift-config` namespace. 

. Add your CA certificate under the key `updateservice-registry`. {cincinnati-short} uses this setting to locate your certificate:
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: trusted-ca
data:
  updateservice-registry: |
    -----BEGIN CERTIFICATE-----
    ...
    -----END CERTIFICATE-----
----

. Edit the `cluster` resource in the `image.config.openshift.io` API to set the `additionalTrustedCA` field to the name of the ConfigMap that you created.
+
----
oc patch image.config.openshift.io cluster -p '{"spec":{"additionalTrustedCA":{"name":"trusted-ca"}}}' --type merge
----
+
Replace `_trusted-ca_` with the path to your new ConfigMap.

The {cincinnati-short} Operator watches the `image.config.openshift.io` API and the
ConfigMap you created in the `openshift-config` namespace for changes, then
restart the deployment if the CA cert has changed.

[#deploy-the-cincinnati-instance]
== Deploy the {cincinnati-short} instance

When you finish deploying the {cincinnati-short} instance on your hub cluster, this instance is located where the images for the cluster upgrades are mirrored and made available to the disconnected managed cluster. Complete the following steps to deploy the instance:

. If you do not want to use the default namespace of the operator, which is `openshift-cincinnati`, create a namespace for your {cincinnati-short} instance:
.. In the {ocp-short} hub cluster console navigation menu, select *Administration* > *Namespaces*.
.. Select *Create Namespace*.
.. Add the name of your namespace, and any other information for your namespace.
.. Select *Create* to create the namespace.
. In the _Installed Operators_ section of the {ocp-short} console, select *{cincinnati} Operator*.
. Select *Create Instance* in the menu.
. Paste the contents from your {cincinnati-short} instance. Your YAML instance might resemble the following manifest:
+
[source,yaml]
----
apiVersion: cincinnati.openshift.io/v1beta2
kind: Cincinnati
metadata:
  name: openshift-update-service-instance
  namespace: openshift-cincinnati
spec:
  registry: <registry_host_name>:<port> <1>
  replicas: 1
  repository: ${LOCAL_REGISTRY}/ocp4/release
  graphDataImage: '<host_name>:<port>/cincinnati-graph-data-container'<2>
----
+
<1> Replace the `spec.registry` value with the path to your local disconnected registry for your images.
+
<2> Replace the `spec.graphDataImage` value with the path to your graph data init container. This is the same value that you used when you ran the `podman push` command to push your graph data init container.
. Select *Create* to create the instance. 
. From the hub cluster CLI, enter the `oc get pods` command to view the status of the instance creation. It might take a while, but the process is complete when the result of the command shows that the instance and the operator are running.

[#override-the-default-registry]
== Override the default registry (optional)

*Note:* The steps in this section only apply if you have mirrored your releases into your mirrored registry. 

{ocp-short} has a default image registry value that specifies where it finds the upgrade packages. In a disconnected environment, you can create an override to replace that value with the path to your local image registry where you mirrored your release images. 

Complete the following steps to override the default registry:

. Create a YAML file named `mirror.yaml` that resembles the following content: 
+
[source,yaml]
----
apiVersion: operator.openshift.io/v1alpha1
kind: ImageContentSourcePolicy
metadata:
  name: <your-local-mirror-name><1>
spec:
  repositoryDigestMirrors:
    - mirrors:
        - <your-registry><2>
      source: registry.redhat.io
----
+
<1> Replace `your-local-mirror-name` with the name of your local mirror. 
+
<2> Replace `your-registry` with the path to your local mirror repository.
+
*Note:* You can find your path to your local mirror by entering the `oc adm release mirror` command. 

. Using the command line of the managed cluster, run the following command to override the default registry: 
+
----
oc apply -f mirror.yaml
----

[#deploy-a-disconnected-catalog-source]
== Deploy a disconnected catalog source

On the managed cluster, disable all of the default catalog sources and create a new one.
Complete the following steps to change the default location from a connected location to your disconnected local registry: 

. Create a YAML file named `source.yaml` that resembles the following content: 
+
[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: OperatorHub
metadata:
  name: cluster
spec:
  disableAllDefaultSources: true

---
apiVersion: operators.coreos.com/v1alpha1
kind: CatalogSource
metadata:
  name: my-operator-catalog
  namespace: openshift-marketplace
spec:
  sourceType: grpc
  image: '<registry_host_name>:<port>/olm/redhat-operators:v1'<1>
  displayName: My Operator Catalog
  publisher: grpc
----
+
<1> Replace the value of `spec.image` with the path to your local restricted catalog source image.

. On the command line of the managed cluster, change the catalog source by running the following command:
+
----
oc apply -f source.yaml
----

[#change-the-managed-cluster-parameter]
== Change the managed cluster parameter

Update the `ClusterVersion` resource information on the managed cluster to change the default location from where it retrieves its upgrades. 

. From the managed cluster, confirm that the `ClusterVersion` upstream parameter is currently the default public {cincinnati-short} operand by entering the following command:
+
----
oc get clusterversion -o yaml
----
+
The returned content might resemble the following content:
+
[source,yaml]
----
apiVersion: v1
items:
- apiVersion: config.openshift.io/v1
  kind: ClusterVersion
[..]
  spec:
    channel: stable-4.13
    upstream: https://api.openshift.com/api/upgrades_info/v1/graph
----

. From the hub cluster, identify the route URL to the {cincinnati-short} operand by entering the following command: 
+
----
oc get routes
---- 
//do we get routes with the integrated console? A bug came out for other topics, could not get a review on this in time, please check next time this is edited. --bcs 6/23
+
Note the returned value for later steps.

. On the command line of the managed cluster, edit the `ClusterVersion` resource by entering the following command:
+
----
oc edit clusterversion version
----
+
Replace the value of `spec.channel` with your new version.
+
Replace the value of `spec.upstream` with the path to your hub cluster {cincinnati-short} operand. You can complete the following steps to determine the path to your operand:
+
.. Run the following command on the hub cluster:
+ 
----
oc get routes -A
----
+
.. Find the path to `cincinnati`. The path the operand is the value in the `HOST/PORT` field.

. On the command line of the managed cluster, confirm that the upstream parameter in the `ClusterVersion` is updated with the local hub cluster {cincinnati-short} URL by entering the following command:
+
----
oc get clusterversion -o yaml
----
+
The results resemble the following content:
+
[source,yaml]
----
apiVersion: v1
items:
- apiVersion: config.openshift.io/v1
  kind: ClusterVersion
[..]
  spec:
    channel: stable-4.13
    upstream: https://<hub-cincinnati-uri>/api/upgrades_info/v1/graph
----

[#viewing-available-upgrades]
== Viewing available upgrades

On the _Clusters_ page, the *Distribution version* of the cluster indicates that there is an upgrade available, if there is an upgrade in the disconnected registry. You can view the available upgrades by selecting the cluster and selecting *Upgrade clusters* from the _Actions_ menu. If the optional upgrade paths are available, the available upgrades are listed.  

*Note:* No available upgrade versions are shown if the current version is not mirrored into the local image repository.  

[#selecting-a-channel-discon]
== Selecting a channel

You can use the console to select a channel for your cluster upgrades on {ocp-short} version 4.6 or later. Those versions must be available on the mirror registry. Complete the steps in xref:../install_upgrade/upgrade_cluster.adoc#selecting-a-channel[Selecting a channel] to specify a channel for your upgrades. 

[#upgrading-the-cluster]
== Upgrading the cluster

After you configure the disconnected registry, {mce-short} and {cincinnati-short} use the disconnected registry to determine if upgrades are available. If no available upgrades are displayed, make sure that you have the release image of the current level of the cluster and at least one later level mirrored in the local repository. If the release image for the current version of the cluster is not available, no upgrades are available.

On the _Clusters_ page, the *Distribution version* of the cluster indicates that there is an upgrade available, if there is an upgrade in the disconnected registry. You can upgrade the image by clicking *Upgrade available* and selecting the version for the upgrade.  

The managed cluster is updated to the selected version. 

If your cluster upgrade fails, the Operator generally retries the upgrade a few times, stops, and reports the status of the failing component. In some cases, the upgrade process continues to cycle through attempts to complete the process. Rolling your cluster back to a previous version following a failed upgrade is not supported. Contact Red Hat support for assistance if your cluster upgrade fails.
