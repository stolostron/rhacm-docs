[#advanced-config-cluster]
= Cluster lifecycle advanced configuration 

You can configure some cluster settings during or after installation.

[#custom-api-certificates]
== Customizing API server certificates

The managed clusters communicate with the hub cluster through a mutual connection with the OpenShift Kube API server external load balancer. The default OpenShift Kube API server certificate is issued by an internal {ocp} cluster certificate authority (CA) when {ocp-short} is installed. If necessary, you can add or change certificates.

Changing the API server certificate might impact the communication between the managed cluster and the hub cluster. When you add the named certificate before installing the product, you can avoid an issue that might leave your managed clusters in an offline state. 

The following list contains some examples of when you might need to update your certificates: 

* You want to replace the default API server certificate for the external load balancer with your own certificate. By following the guidance in _Adding API server certificates_ in the {ocp-short} documentation, you can add a named certificate with host name `api.<cluster_name>.<base_domain>` to replace the default API server certificate for the external load balancer. Replacing the certificate might cause some of your managed clusters to move to an offline state. If your clusters are in an offline state after upgrading the certificates, follow the troubleshooting instructions for _Troubleshooting imported clusters offline after certificate change_ to resolve it.
+
*Note:* Adding the named certificate before installing the product helps to avoid your clusters moving to an offline state.

* The named certificate for the external load balancer is expiring and you need to replace it. If both the old and the new certificate share the same root CA certificate, despite the number of intermediate certificates, you can follow the guidance in _Adding API server certificates_ in the {ocp-short} documentation to create a new secret for the new certificate. Then update the serving certificate reference for host name `api.<cluster_name>.<base_domain>` to the new secret in the `APIServer` custom resource. Otherwise, when the old and new certificates have different root CA certificates, complete the following steps to replace the certificate: 
+
. Locate your `APIServer` custom resource, which resembles the following example: 
+
[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: APIServer
metadata:
  name: cluster
spec:
  audit:
    profile: Default
  servingCerts:
    namedCertificates:
    - names:
      - api.mycluster.example.com
      servingCertificate:
        name: old-cert-secret
----

. Create a new secret in the `openshift-config` namespace that contains the content of the existing and new certificates by running the following commands:
+
.. Copy the old certificate into a new certificate:
+
[source,bash]
----
cp old.crt combined.crt
----

.. Add the contents of the new certificate to the copy of the old certificate:
+
[source,bash]
----
cat new.crt >> combined.crt
----

.. Apply the combined certificates to create a secret:
+
[source,bash]
----
oc create secret tls combined-certs-secret --cert=combined.crt --key=old.key -n openshift-config
----

. Update your `APIServer` resource to reference the combined certificate as the `servingCertificate`.
+
[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: APIServer
metadata:
  name: cluster
spec:
  audit:
    profile: Default
  servingCerts:
    namedCertificates:
    - names:
      - api.mycluster.example.com
      servingCertificate:
        name: combined-cert-secret
----

. After about 15 minutes, the CA bundle containing both new and old certificates is propagated to the managed clusters.

. Create another secret named `new-cert-secret` in the `openshift-config` namespace that contains only the new certificate information by entering the following command:
+
[source,bash]
----
oc create secret tls new-cert-secret --cert=new.crt --key=new.key -n openshift-config {code}
----

. Update the `APIServer` resource by changing the name of `servingCertificate` to reference the `new-cert-secret`. Your resource might resemble the following example: 
+
[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: APIServer
metadata:
  name: cluster
spec:
  audit:
    profile: Default
  servingCerts:
    namedCertificates:
    - names:
      - api.mycluster.example.com
      servingCertificate:
        name: new-cert-secret
----
+
After about 15 minutes, the old certificate is removed from the CA bundle, and the change is automatically propagated to the managed clusters.

*Note:* Managed clusters must use the host name `api.<cluster_name>.<base_domain>` to access the hub cluster. You cannot use named certificates that are configured with other host names.

[#configuring-proxy-hub-and-managed-cluster]
== Configuring the proxy between hub cluster and managed cluster

To register a managed cluster to your {mce-short} hub cluster, you need to transport the  managed cluster to your {mce-short} hub cluster. Sometimes your managed cluster cannot directly reach your {mce-short} hub cluster. In this instance, configure the proxy settings to allow the communications from the managed cluster to access the {mce-short} hub cluster through a HTTP or HTTPS proxy server.

For example, the {mce-short} hub cluster is in a public cloud, and the managed cluster is in a private cloud environment behind firewalls. The communications out of the private cloud can only go through a HTTP or HTTPS proxy server. 

== Prerequisites

- You have a HTTP or HTTPS proxy server running that supports HTTP tunnels. For example, HTTP connect method. 
- You have a manged cluster that can reach the HTTP or HTTPS proxy server, and the proxy server can access the {mce-short} hub cluster. 

Complete the following steps to configure the proxy settings between hub cluster and managed cluster:

. Create a `KlusterConfig` resource with proxy settings. 
.. See the following configuration with HTTP proxy:
+
[source,yaml]
----
apiVersion: config.open-cluster-management.io/v1alpha1
kind: KlusterletConfig
metadata:
  name: http-proxy
spec:
  hubKubeAPIServerProxyConfig:
    httpProxy: "http://<username>:<password>@<ip>:<port>"
----
+ 
.. See the following configuration with HTTPS proxy:  
+
[source,yaml]
----
apiVersion: config.open-cluster-management.io/v1alpha1
kind: KlusterletConfig
metadata:
  name: https-proxy
spec:
  hubKubeAPIServerProxyConfig:
    httpsProxy: "https://<username>:<password>@<ip>:<port>"
    caBundle: <user-ca-bundle> 
----
+ 
*Note:* A CA certificate is required when the HTTPS proxy server is configured. The HTTPS proxy is used if both HTTP proxy and HTTPS proxy are specified.

. When creating a managed cluster, choose the `KlusterletConfig` resource by adding an annotation that refers to the `KlusterletConfig` resource. See the following example:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  annotations:
    agent.open-cluster-management.io/klusterlet-config: <klusterlet-config-name>
  name:<managed-cluster-name>
spec:
  hubAcceptsClient: true
  leaseDurationSeconds: 60 
----
+ 
*Note:* You might need to toggle the YAML view to add the annotation to the `ManagedCluster` resource when you operate on the {mce-short} console.

[#disabling-proxy-between-hub-and-managed-cluster]
== Disabling the proxy between hub cluster and managed cluster

If your development changes, you might need to disable the HTTP or HTTPS proxy. 

. Go to `ManagedCluster` resource.
. Remove the annotation, `agent.open-cluster-management.io/klusterlet-config`.

[#create-cluster-configuring-nodeselector-tolerations]
== Optional: Configuring the klusterlet to run on specific nodes

When you create a cluster using {product-title}, you can specify which nodes you want to run the managed cluster klusterlet to run on by configuring the `nodeSelector` and `tolerations` annotation for the managed cluster. Complete the following steps to configure these settings: 

. Select the managed cluster that you want to update from the clusters page in the console. 

. Set the YAML switch to `On` to view the YAML content. 

. Add the `nodeSelector` annotation to the managed cluster YAML definition. The key for this annotation is: `open-cluster-management/nodeSelector`. The value of this annotation is a string map with JSON formatting.

. Add the `tolerations` entry to the managed cluster YAML definition. The key of this annotation is: `open-cluster-management/tolerations`. The value of this annotation represents a link:https://github.com/kubernetes/api/blob/release-1.24/core/v1/types.go#L3007[toleration] list with JSON formatting.
The resulting YAML might resemble the following example: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  annotations:
    open-cluster-management/nodeSelector: '{"dedicated":"acm"}'
    open-cluster-management/tolerations: '[{"key":"dedicated","operator":"Equal","value":"acm","effect":"NoSchedule"}]' 
----

[#add-resources-adv-cluster]
== Additional resources

* link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/security_and_compliance/configuring-certificates#api-server-certificates[Adding API server certificates]

* xref:../support_troubleshooting/trouble_cluster_offline_cert_mce.adoc#troubleshooting-imported-clusters-offline-after-certificate-change-mce[Troubleshooting imported clusters offline after certificate change]

* xref:../cluster_lifecycle/cluster_proxy_addon.adoc#cluster-proxy-addon-settings[Configuring proxy settings for cluster proxy add-ons]
