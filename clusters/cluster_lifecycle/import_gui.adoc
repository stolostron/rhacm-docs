[#importing-managed-cluster-console]
= Importing a managed cluster by using the console

After you install {mce}, you are ready to import a cluster to manage. Continue reading the following topics learn how to import a managed cluster by using the console:

* <<import-gui-prereqs,Prerequisites>>
* <<creating-new-pull-secret,Creating a new pull secret>>
* <<importing-cluster,Importing a cluster>>
* <<import-configuring-cluster-api,Optional: Configuring the cluster API address>>
* <<removing-an-imported-cluster,Removing a cluster>>

[#import-gui-prereqs]
== Prerequisites

* A deployed hub cluster. If you are importing bare metal clusters, the hub cluster must be installed on a supported {ocp} version.
* A cluster you want to manage.
* The `base64` command line tool.
* A defined `multiclusterhub.spec.imagePullSecret` if you are importing a cluster that was not created by {ocp-short}. This secret might have been created when {mce} was installed. See _Custom image pull secret_ for more information about how to define this secret.

*Required user type or access level:* Cluster administrator

[#creating-new-pull-secret]
== Creating a new pull secret

If you need to create a new pull secret, complete the following steps:

. Download your Kubernetes pull secret from link:https://cloud.redhat.com/[cloud.redhat.com]. 

. Add the pull secret to the namespace of your hub cluster. 

. Run the following command to create a new secret in the `open-cluster-management` namespace: 
+
----
oc create secret generic pull-secret -n <open-cluster-management> --from-file=.dockerconfigjson=<path-to-pull-secret> --type=kubernetes.io/dockerconfigjson
----
+
Replace `open-cluster-management` with the name of the namespace of your hub cluster. The default namespace of the hub cluster is `open-cluster-management`.
+
Replace `path-to-pull-secret` with the path to the pull secret that you downloaded. 
+
The secret is automatically copied to the managed cluster when it is imported. 
+
* Ensure that a previously installed agent is deleted from the cluster that you want to import. You must remove the `open-cluster-management-agent` and `open-cluster-management-agent-addon` namespaces to avoid errors.
* For importing in a Red Hat OpenShift Dedicated environment, see the following notes:
** You must have the hub cluster deployed in a Red Hat OpenShift Dedicated environment.
** The default permission in Red Hat OpenShift Dedicated is dedicated-admin, but that does not contain all of the permissions to create a namespace. You must have `cluster-admin` permissions to import and manage a cluster with {mce-short}.

[#importing-cluster]
== Importing a cluster

You can import existing clusters from the console for each of the available cloud providers.

*Note:* A hub cluster cannot manage a different hub cluster. A hub cluster is set up to automatically import and manage itself, so you do not have to manually import a hub cluster to manage itself.

By default, the namespace is used for the cluster name and namespace, but you can change it.

*Important:* When you create a cluster, the controller creates a namespace for the cluster and its resources. Ensure that you include only resources for that cluster instance in that namespace. Destroying the cluster deletes the namespace and all of the resources in it.

Every managed cluster must be associated with a managed cluster set. If you do not assign the managed cluster to a `ManagedClusterSet`, the cluster is automatically added to the `default` managed cluster set. 

If you want to add the cluster to a different cluster set, you must have `clusterset-admin` privileges to the cluster set. If you do not have `cluster-admin` privileges when you are importing the cluster, you must select a cluster set on which you have `clusterset-admin` permissions. If you do not have the correct permissions on the specified cluster set, the cluster importing fails. Contact your cluster administrator to provide you with `clusterset-admin` permissions to a cluster set if you do not have cluster set options to select.

If you import a {ocp-short} Dedicated cluster and do not specify a vendor by adding a label for `vendor=OpenShiftDedicated`, or if you add a label for `vendor=auto-detect`, a `managed-by=platform` label is automatically added to the cluster. You can use this added label to identify the cluster as a {ocp-short} Dedicated cluster and retrieve the {ocp-short} Dedicated clusters as a group.

The following table provides the available options for _import mode_, which specifies the method for importing the cluster:

|===
| Run import commands manually | After completing and submitting the information in the console, including any Red Hat {aap-short} templates, run the provided command on the target cluster to import the cluster.
| Enter your server URL and API token for the existing cluster | Provide the server URL and API token of the cluster that you are importing. You can specify a Red Hat {aap-short} template to run when the cluster is upgraded.
| Provide the `kubeconfig` file | Copy and paste the contents of the `kubeconfig` file of the cluster that you are importing. You can specify a Red Hat {aap-short} template to run when the cluster is upgraded.
|===

*Note:* You must have the Red Hat {aap-short} Resource Operator installed from OperatorHub to create and run an {aap-short} job. 

To configure a cluster API address, see xref:../cluster_lifecycle/import_gui.adoc#import-configuring-cluster-api[Optional: Configuring the cluster API address].

To configure your managed cluster klusterlet to run on specific nodes, see xref:../cluster_lifecycle/import_gui.adoc#import-configuring-nodeselector-tolerations[Optional: Configuring the klusterlet to run on specific nodes].

[#import-configuring-cluster-api]
=== Optional: Configuring the cluster API address

Complete the following steps to optionally configure the *Cluster API address* that is on the cluster details page by configuring the URL that is displayed in the table when you run the `oc get managedcluster` command:

. Log in to your hub cluster with an ID that has `cluster-admin` permissions.

. Configure a `kubeconfig` file for your targeted managed cluster.

. Edit the managed cluster entry for the cluster that you are importing by running the following command, replacing `cluster-name` with the name of the managed cluster:
+
----
oc edit managedcluster <cluster-name> 
----

. Add the `ManagedClusterClientConfigs` section to the `ManagedCluster` spec in the YAML file, as shown in the following example:
+
[source,yaml]
----
spec:
  hubAcceptsClient: true
  managedClusterClientConfigs:
  - url: <https://api.new-managed.dev.redhat.com> <1>
----
+
<1> Replace the value of the URL with the URL that provides external access to the managed cluster that you are importing.

[#import-configuring-nodeselector-tolerations]
=== Optional: Configuring the klusterlet to run on specific nodes

You can specify which nodes you want the managed cluster klusterlet to run on by configuring the `nodeSelector` and `tolerations` annotation for the managed cluster. Complete the following steps to configure these settings: 

. Select the managed cluster that you want to update from the clusters page in the console. 

. Set the YAML switch to `On` to view the YAML content.
+
*Note:* The YAML editor is only available when importing or creating a cluster. To edit the managed cluster YAML definition after importing or creating, you must use the {ocp-short} command-line interface or the {acm-short} search feature.

. Add the `nodeSelector` annotation to the managed cluster YAML definition. The key for this annotation is: `open-cluster-management/nodeSelector`. The value of this annotation is a string map with JSON formatting.

. Add the `tolerations` entry to the managed cluster YAML definition. The key of this annotation is: `open-cluster-management/tolerations`. The value of this annotation represents a link:https://github.com/kubernetes/api/blob/release-1.24/core/v1/types.go#L3007[toleration] list with JSON formatting.
The resulting YAML might resemble the following example: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  annotations:
    open-cluster-management/nodeSelector: '{"dedicated":"acm"}'
    open-cluster-management/tolerations: '[{"key":"dedicated","operator":"Equal","value":"acm","effect":"NoSchedule"}]' 
----

You can also use a `KlusterletConfig` to configure the `nodeSelector` and `tolerations` for the managed cluster. Complete the following steps to configure these settings:

*Note:* If you use a `KlusterletConfig`, the managed cluster uses the configuration in the `KlusterletConfig` settings instead of the settings in the managed cluster annotation.

. Apply the following sample YAML content. Replace value where needed:
+
[source,yaml]
----
apiVersion: config.open-cluster-management.io/v1alpha1
kind: KlusterletConfig
metadata:
  name: <klusterletconfigName>
spec:
  nodePlacement:
    nodeSelector:
      dedicated: acm
    tolerations:
      - key: dedicated
        operator: Equal
        value: acm
        effect: NoSchedule
----

. Add the `agent.open-cluster-management.io/klusterlet-config: `<klusterletconfigName>` annotation to the managed cluster, replacing `<klusterletconfigName>` with the name of your `KlusterletConfig`.

[#removing-an-imported-cluster]
== Removing an imported cluster

Complete the following procedure to remove an imported cluster and the `open-cluster-management-agent-addon` that was created on the managed cluster.

On the _Clusters_ page, click *Actions* > *Detach cluster* to remove your cluster from management.

*Note:* If you attempt to detach the hub cluster, which is named `local-cluster`, be aware that the default setting of `disableHubSelfManagement` is `false`. This setting causes the hub cluster to reimport itself and manage itself when it is detached and it reconciles the `MultiClusterHub` controller. It might take hours for the hub cluster to complete the detachment process and reimport. If you want to reimport the hub cluster without waiting for the processes to finish, you can run the following command to restart the `multiclusterhub-operator` pod and reimport faster:

----
oc delete po -n open-cluster-management `oc get pod -n open-cluster-management | grep multiclusterhub-operator| cut -d' ' -f1`
----

You can change the value of the hub cluster to not import automatically by changing the `disableHubSelfManagement` value to `true`. For more information, see the _disableHubSelfManagement_ topic.

[#import-cluster-additional-resources]
=== Additional resources

- See xref:../install_upgrade/adv_config_install.adoc#custom-image-pull-secret[Custom image pull secret] for more information about how to define a custom image pull secret.

- See the link:../../install/adv_config_install.adoc#disable-hub-self-management[disableHubSelfManagement] topic.
