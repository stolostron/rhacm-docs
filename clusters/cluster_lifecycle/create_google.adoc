[#creating-a-cluster-on-google-cloud-platform]
= Creating a cluster on Google Cloud Platform

Follow the procedure to create a {ocp} cluster on Google Cloud Platform (GCP).
For more information about GCP, see link:https://cloud.google.com/docs/overview[Google Cloud Platform].

When you create a cluster, the creation process uses the {ocp-short} installer with the Hive resource. If you have questions about cluster creation after completing this procedure, see link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/installing/installing-on-gcp[Installing on GCP] in the {ocp-short} documentation for more information about the process.

* <<google_prerequisites,Prerequisites>>
* <<google_creating-your-cluster-with-the-console,Creating your cluster with the console>>

[#google_prerequisites]
== Prerequisites

See the following prerequisites before creating a cluster on GCP:

* You must have a deployed hub cluster.
* You must have a GCP credential. See xref:../credentials/credential_google.adoc#creating-a-credential-for-google-cloud-platform[Creating a credential for Google Cloud Platform] for more information.
* You must have a configured domain in GCP. See link:https://cloud.google.com/endpoints/docs/openapi/dev-portal-setup-custom-domain[Setting up a custom domain] for instructions on how to configure a domain.
* You need your GCP login credentials, which include user name and password.
* You must have an {ocp-short} image pull secret. See link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/images/managing-images#using-image-pull-secrets[Using image pull secrets].

*Note:* If you change your cloud provider access key on the cloud provider, you also need to manually update the corresponding credential for the cloud provider on the console of {mce-short}. This is required when your credentials expire on the cloud provider where the managed cluster is hosted and you try to delete the managed cluster.

[#google_creating-your-cluster-with-the-console]
== Creating your cluster with the console

To create clusters from the {mce-short} console, navigate to *Infrastructure* > *Clusters*. On the _Clusters_ page, click *Create cluster* and complete the steps in the console. 

*Note:* This procedure is for creating a cluster.
If you have an existing cluster that you want to import, see xref:../cluster_lifecycle/import_intro.adoc#import-intro[Cluster import introduction] for those steps.

If you need to create a credential, see xref:../credentials/credential_google.adoc#creating-a-credential-for-google-cloud-platform[Creating a credential for Google Cloud Platform] for more information.

The name of your cluster is used in the hostname of the cluster. There are some restrictions that apply to naming your GCP cluster. These restrictions include not beginning the name with `goog` or containing a group of letters and numbers that resemble `google` anywhere in the name. See link:https://cloud.google.com/storage/docs/naming-buckets#requirements[Bucket naming guidelines] for the complete list of restrictions. 

*Important:* When you create a cluster, the controller creates a namespace for the cluster and its resources. Ensure that you include only resources for that cluster instance in that namespace. Destroying the cluster deletes the namespace and all of the resources in it.

*Tip:* Select *YAML: On* to view content updates as you enter the information in the console.

If you want to add your cluster to an existing cluster set, you must have the correct permissions on the cluster set to add it. If you do not have `cluster-admin` privileges when you are creating the cluster, you must select a cluster set on which you have `clusterset-admin` permissions. If you do not have the correct permissions on the specified cluster set, the cluster creation fails. Contact your cluster administrator to provide you with `clusterset-admin` permissions to a cluster set if you do not have any cluster set options to select.

Every managed cluster must be associated with a managed cluster set. If you do not assign the managed cluster to a `ManagedClusterSet`, it is automatically added to the `default` managed cluster set.

If there is already a base DNS domain that is associated with the selected credential for your GCP account, that value is populated in the field. You can change the value by overwriting it. See link:https://cloud.google.com/endpoints/docs/openapi/dev-portal-setup-custom-domain[Setting up a custom domain] for more information. This name is used in the hostname of the cluster.

The release image identifies the version of the {ocp-short} image that is used to create the cluster. If the version that you want to use is available, you can select the image from the list of images. If the image that you want to use is not a standard image, you can enter the URL to the image that you want to use. See xref:../cluster_lifecycle/release_images.adoc#release-images-intro[Release images] for more information about release images. 

The Node pools include the control plane pool and the worker pools. The control plane nodes share the management of the cluster activity. The information includes the following fields:

* Region: Specify a region where you want to run your control plane pools. A closer region might provide faster performance, but a more distant region might be more distributed.

* CPU architecture: If the architecture type of the managed cluster is not the same as the architecture of your hub cluster, enter a value for the instruction set architecture of the machines in the pool. Valid values are _amd64_, _ppc64le_, _s390x_, and _arm64_.

You can specify the instance type of your control plane pool. You can change the type and size of your instance after it is created.

You can create one or more worker nodes in a worker pool to run the container workloads for the cluster. They can be in a single worker pool, or distributed across multiple worker pools. If zero worker nodes are specified, the control plane nodes also function as worker nodes. The information includes the following fields:

* Instance type: You can change the type and size of your instance after it is created. 

* Node count: This setting is required when you define a worker pool.

The networking details are required, and multiple networks are required for using IPv6 addresses. You can add an additional network by clicking *Add network*.

Proxy information that is provided in the credential is automatically added to the proxy fields. You can use the information as it is, overwrite it, or add the information if you want to enable a proxy. The following list contains the required information for creating a proxy:  

* HTTP proxy: The URL that should be used as a proxy for `HTTP` traffic. 

* HTTPS proxy: The secure proxy URL that should be used for `HTTPS` traffic. If no value is provided, the same value as the `HTTP Proxy URL` is used for both `HTTP` and `HTTPS`.

* No proxy sites: A comma-separated list of sites that should bypass the proxy. Begin a domain name with a period `.` to include all of the subdomains that are in that domain. Add an asterisk `*` to bypass the proxy for all destinations.

* Additional trust bundle: One or more additional CA certificates that are required for proxying HTTPS connections.

When you review your information and optionally customize it before creating the cluster, you can select *YAML: On* to view the `install-config.yaml` file content in the panel. You can edit the YAML file with your custom settings, if you have any updates.

If you are using {product-title} and want to configure your managed cluster klusterlet to run on specific nodes, see xref:../cluster_lifecycle/adv_config_cluster.adoc#create-cluster-configuring-nodeselector-tolerations[Optional: Configuring the klusterlet to run on specific nodes] for the required steps.

*Note:* You do not have to run the `oc` command that is provided with the cluster details to import the cluster. When you create the cluster, it is automatically configured under the management of {mce-short}. 

Continue with xref:../cluster_lifecycle/access_cluster.adoc#accessing-your-cluster[Accessing your cluster] for instructions for accessing your cluster. 
