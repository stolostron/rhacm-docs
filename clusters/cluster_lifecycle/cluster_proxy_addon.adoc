[#cluster-proxy-addon]
= Using cluster proxy add-ons

In some environments, a managed cluster is behind a firewall and cannot be accessed directly by the hub cluster. To gain access, you can set up a proxy add-on to access the `kube-apiserver` of the managed cluster to provide a more secure connection.

*Important:* There must not be a cluster-wide proxy configuration on your hub cluster.

*Required access:* Editor

To configure a cluster proxy add-on for a hub cluster and a managed cluster, complete the following steps:

. Configure the `kubeconfig` file to access the managed cluster `kube-apiserver` by completing the following steps:

.. Provide a valid access token for the managed cluster. 
+
*Note:* : You can use the corresponding token of the service account. You can also use the default service account that is in the default namespace.

... Export the `kubeconfig` file of the managed cluster by running the following command:
+
----
export KUBECONFIG=<managed-cluster-kubeconfig>
----

... Add a role to your service account that allows it to access pods by running the following commands:
+
----
oc create role -n default test-role --verb=list,get --resource=pods 
oc create rolebinding -n default test-rolebinding --serviceaccount=default:default --role=test-role
----

... Run the following command to locate the secret of the service account token:
+
----
oc get secret -n default | grep <default-token>
----
+
Replace `default-token` with the name of your secret.

... Run the following command to copy the token:
+
----
export MANAGED_CLUSTER_TOKEN=$(kubectl -n default get secret <default-token> -o jsonpath={.data.token} | base64 -d) 
----
+
Replace `default-token` with the name of your secret.

.. Configure the `kubeconfig` file on the {product-title-short} hub cluster.

... Export the current `kubeconfig` file on the hub cluster by running the following command:
+
----
oc config view --minify --raw=true > cluster-proxy.kubeconfig
----

... Modify the `server` file with your editor. This example uses commands when using `sed`. Run `alias sed=gsed`, if you are using OSX.
+
----
export TARGET_MANAGED_CLUSTER=<managed-cluster-name>

export NEW_SERVER=https://$(oc get route -n multicluster-engine cluster-proxy-addon-user -o=jsonpath='{.spec.host}')/$TARGET_MANAGED_CLUSTER

sed -i'' -e '/server:/c\    server: '"$NEW_SERVER"'' cluster-proxy.kubeconfig

export CADATA=$(oc get configmap -n openshift-service-ca kube-root-ca.crt -o=go-template='{{index .data "ca.crt"}}' | base64)

sed -i'' -e '/certificate-authority-data:/c\    certificate-authority-data: '"$CADATA"'' cluster-proxy.kubeconfig
----

... Delete the original user credentials by entering the following commands: 
+
----
sed -i'' -e '/client-certificate-data/d' cluster-proxy.kubeconfig
sed -i'' -e '/client-key-data/d' cluster-proxy.kubeconfig
sed -i'' -e '/token/d' cluster-proxy.kubeconfig
----

... Add the token of the service account:
+
----
sed -i'' -e '$a\    token: '"$MANAGED_CLUSTER_TOKEN"'' cluster-proxy.kubeconfig
----

. List all of the pods on the target namespace of the target managed cluster by running the following command: 
+
----
oc get pods --kubeconfig=cluster-proxy.kubeconfig -n <default> 
----
+
Replace the `default` namespace with the namespace that you want to use.

. Access other services on the managed cluster. This feature is available when the managed cluster is a {ocp} cluster. The service must use `service-serving-certificate` to generate server certificates:

+
* From the managed cluster, use the following service account token:
+
----
export PROMETHEUS_TOKEN=$(kubectl get secret -n openshift-monitoring $(kubectl get serviceaccount -n openshift-monitoring prometheus-k8s -o=jsonpath='{.secrets[0].name}') -o=jsonpath='{.data.token}' | base64 -d)
----

* From the hub cluster, convert the certificate authority to a file by running the following command:
+
----
oc get configmap kube-root-ca.crt -o=jsonpath='{.data.ca\.crt}' > hub-ca.crt
----

. Get Prometheus metrics of the managed cluster by using the following commands:
+
----
export SERVICE_NAMESPACE=openshift-monitoring
export SERVICE_NAME=prometheus-k8s
export SERVICE_PORT=9091
export SERVICE_PATH="api/v1/query?query=machine_cpu_sockets"
curl --cacert hub-ca.crt $NEW_SERVER/api/v1/namespaces/$SERVICE_NAMESPACE/services/$SERVICE_NAME:$SERVICE_PORT/proxy-service/$SERVICE_PATH -H "Authorization: Bearer $PROMETHEUS_TOKEN"
----
