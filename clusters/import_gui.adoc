[#importing-an-existing-cluster-with-the-console]
= Importing an existing cluster with the console

After you install {product-title}, you are ready to import a cluster to manage. You can import from both the console and the CLI.

Follow this procedure to import from the console. You need your terminal for authentication during this procedure.

* <<gui_prerequisites,Prerequisites>>
* <<importing-a-cluster,Importing a cluster>>
* <<removing-an-imported-cluster,Removing a cluster>>

[#gui_prerequisites]
== Prerequisites

* You need a {product-title} hub cluster that is deployed. If you are importing bare metal clusters, you must have the hub cluster installed on {ocp} version 4.8 or later.
* You need a cluster that you want to manage and Internet connectivity.
* Install `kubectl`. To install `kubectl`, see _Install and Set Up kubectl_ in the https://kubernetes.io/docs/tasks/tools/install-kubectl/[Kubernetes documentation].
* You need a cluster that you want to manage and Internet connectivity.
* You need the `base64` command line tool.
* If you are importing a cluster that was not created by {ocp}, you need a `multiclusterhub.spec.imagePullSecret` defined. This secret might have been created when {product-title} was installed. See link:../install/install_connected.adoc#installing-from-the-operator-hub[Installing from the OperatorHub] for more information about defining the secret. 
* Ensure the agent is deleted on the cluster that you want to import. The `open-cluster-management-agent` and `open-cluster-management-agent-addon` namespaces must be removed to avoid errors.
* For importing in a Red Hat OpenShift Dedicated environment, see the following notes:
** You must have the hub cluster deployed in a Red Hat OpenShift Dedicated environment.
** The default permission in Red Hat OpenShift Dedicated is dedicated-admin, but that does not contain all of the permissions to create a namespace. You must have `cluster-admin` permissions to import and manage a cluster with {product-title}.


*Required user type or access level*: Cluster administrator

[#importing-a-cluster]
== Importing a cluster

You can import existing clusters from the {product-title} console for each of the available cloud providers.

*Note:* A hub cluster cannot manage a different hub cluster. A hub cluster is set up to automatically import and manage itself, so you do not have to manually import a hub cluster to manage itself.

. From the navigation menu, select *Infrastructure* > *Clusters*.

. In the _Managed clusters_ tab, click *Import cluster*.

. Provide a name for the cluster. By default, the namespace is used for the cluster name and namespace.

*Important:* When you create a cluster, the {product-title-short} controller creates a namespace for the cluster and its resources. Ensure that you include only resources for that cluster instance in that namespace. Destroying the cluster deletes the namespace and all of the resources in it.

. Specify a _Cluster set_, if you want to add it to an existing cluster set on which you have `cluster-admin` privileges. If you do not have `cluster-admin` privileges when you are creating the cluster, you must select a cluster set on which you have `clusterset-admin` permissions. If you do not have the correct permissions on the specified cluster set, the cluster creation fails. Contact your cluster administrator to provide you with `clusterset-admin` permissions to a cluster set if you do not have cluster set options to select.
+
Every managed cluster must be associated with a managed cluster set. If you do not assign the managed cluster to a `ManagedClusterSet`, it is automatically added to the `default` managed cluster set.

. *Optional:* Add any _Additional labels_. 
+
**Note:** If you import a Red Hat OpenShift Dedicated cluster and do not specify a vendor by adding a label for `vendor=OpenShiftDedicated`, or if you add a label for `vendor=auto-detect`, a `managed-by=platform` label is automatically added to the cluster. You can use this added label to identify the cluster as a Red Hat OpenShift Dedicated cluster and retrieve the Red Hat OpenShift Dedicated clusters as a group.

. Select the _import mode_ that you want to use to identify the cluster that you are importing from the following options:
+
* *Run import commands manually*: Generate import commands that you can copy and run, based on the information that you provided. Click *Save import and generate code* to generate the command that you use to deploy the `open-cluster-management-agent-addon`. A confirmation message is displayed.
+
.. In the _Import an existing cluster_ window, select *Copy command* to copy the generated command and token to the clipboard.
+
*Important:* The command contains pull secret information that is copied to each of the imported clusters. Anyone who can access the imported clusters can also view the pull secret information.
Consider creating a secondary pull secret at https://cloud.redhat.com/ or create a service account to protect your personal credentials.
+
See https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/images/managing-images#using-image-pull-secrets[Using image pull secrets] or https://docs.openshift.com/container-platform/4.10/authentication/understanding-and-creating-service-accounts.html[Understanding and creating service accounts] for more information about pull secrets.

.. Log in to the managed cluster that you want to import.

.. *For the Red Hat OpenShift Dedicated environment only:* Complete the following steps:

... Create the `open-cluster-management-agent` and `open-cluster-management` namespaces or projects on the managed cluster.

... Find the klusterlet operator in the {ocp-short} catalog. 

... Install it in the `open-cluster-management` namespace or project that you created. 
+
*Important:* Do not install the operator in the `open-cluster-management-agent` namespace.

... Extract the bootstrap secret from the import command by completing the following steps:

.... Generate the import command:

..... Select *Infrastructure* > *Clusters* from the {product-title-short} console main navigation.

..... Select *Add a cluster* > *Import an existing cluster*.

..... Add the cluster information, and select *Save import and generate code*.

.... Copy the import command.

.... Paste the import command into a file that you create named `import-command`.

.... Run the following command to insert the content into the new file:
+
----
cat import-command | awk '{split($0,a,"&&"); print a[3]}' | awk '{split($0,a,"|"); print a[1]}' | sed -e "s/^ echo //" | base64 -d
----

.... Find and copy the secret with the name `bootstrap-hub-kubeconfig` in the output.

.... Apply the secret to the `open-cluster-management-agent` namespace on the managed cluster.

.... Create the klusterlet resource using the example in the installed operator, the clusterName should be changed the same name as cluster name that was set during the import.
+
*Note:* When the `managedcluster` resource is successfully registered to the hub, there are two klusterlet operators installed. One klusterlet operator is in the `open-cluster-management` namespace, and the other is in the `open-cluster-management-agent` namespace. Multiple operators  does not affect the function of the klusterlet.

.. *For cluster imports that are not in the Red Hat OpenShift Dedicated environment* Complete the following steps: 

... If necessary, configure your `kubectl` commands for your managed cluster.
+
See link:../about/supported_providers.adoc#supported-providers[Supported providers] to learn how to configure your `kubectl` command line interface. 

... To deploy the `open-cluster-management-agent-addon` to the managed cluster, run the command and token that you copied.
  
.. Select *View cluster* to view a summary of your cluster in the _Overview_ page.

* *Enter your server URL and API token for the existing cluster*: Provide the server URL and API token of the cluster that you are importing.

* *Kubeconfig*: Copy and paste the content of the `kubeconfig` file of the cluster that you are importing. 
  
. *Optional:* Configure the *Cluster API address* that is on the cluster details page by configuring the URL that is displayed in the table when you run the `oc get managedcluster` command.

.. Log in to your hub cluster with an ID that has `cluster-admin` permissions.

.. Configure your `kubectl` for your targeted managed cluster.
+
See link:../about/supported_providers.adoc#supported-providers[Supported providers] to learn how to configure your `kubectl`.

.. Edit the managed cluster entry for the cluster that you are importing by entering the following command:
+
----
oc edit managedcluster <cluster-name>
----
Replace `_cluster-name_` with the name of the managed cluster.

.. Add the `ManagedClusterClientConfigs` section to the `ManagedCluster` spec in the YAML file, as shown in the following example:
+
[source,yaml]
----
spec:
  hubAcceptsClient: true
  managedClusterClientConfigs:
  - url: https://multicloud-console.apps.new-managed.dev.redhat.com
----
+
Replace the value of the URL with the URL that provides external access to the managed cluster that you are importing.

Your cluster is imported. You can import another by selecting *Import another*.

[#importing-a-cluster-non-ocp]
=== Importing a cluster that was not created by {ocp-short}

When you deploy a new hub, you must define the pull secret. The pull secret you define during the hub install is used for importing clusters that were not created by {ocp-short}. {ocp-short} clusters do not use the pull secret you defined during the hub install.

Complete the following steps to import clusters that were not created by {ocp-short} with the correct pull secret:

. Run the following command to create a secret that is copied to the managed cluster:
+
----
oc create secret generic pull-secret -n open-cluster-management --from-file=.dockerconfigjson=../../pull-secret --type=kubernetes.io/dockerconfigjson
----

. Apply the operator CRD by running the following command:
+
----
 oc apply -f v2_multiclusterhub.yaml -n open-cluster-management
----

The `operator.yaml` file might resemble the following example:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
  kind: MultiClusterHub
  metadata:
    name: multiclusterhub
  spec:
    availabilityConfig: High
    hive:
    backup:
    velero: {}
    failedProvisionConfig: {}
    imagePullSecret: pull-secret
    ingress:
    sslCiphers:
      - ECDHE-ECDSA-AES256-GCM-SHA384
      - ECDHE-RSA-AES256-GCM-SHA384
      - ECDHE-ECDSA-CHACHA20-POLY1305
      - ECDHE-RSA-CHACHA20-POLY1305
      - ECDHE-ECDSA-AES128-GCM-SHA256
      - ECDHE-RSA-AES128-GCM-SHA256
    overrides: {}
    separateCertificateManagement: false
----
  
[#removing-an-imported-cluster]
== Removing an imported cluster

Complete the following procedure to remove an imported cluster and the `open-cluster-management-agent-addon` that was created on the managed cluster.

On the _Clusters_ page, click *Actions* > *Detach cluster* to remove your cluster from management.

*Note:* If you attempt to detach the hub cluster, which is named `local-cluster`, be aware that the default setting of `disableHubSelfManagement` is `false`. This setting causes the hub cluster to reimport itself and manage itself when it is detached and it reconciles the `MultiClusterHub` controller. It might take hours for the hub cluster to complete the detachment process and reimport. If you want to reimport the hub cluster without waiting for the processes to finish, you can enter the following command to restart the `multiclusterhub-operator` pod and reimport faster:

----
oc delete po -n open-cluster-management `oc get pod -n open-cluster-management | grep multiclusterhub-operator| cut -d' ' -f1`
----

You can change the value of the hub cluster to not import automatically by changing the `disableHubSelfManagement` value to `true`. For more information, see the link:../install/adv_config_install.adoc#disable-hub-self-management[disableHubSelfManagement] topic.
