[#hub-backup-and-restore]
= Cluster backup and restore operator
//Would it be accurate if we said, "The cluster backup and restore operator YAML is automatically enabled by the `MultiClusterHub` resource..."
//Are the charts specifically Helm charts? 
//what is the default namespace where OADP is installed?
The cluster backup and restore operator is automatically installed by the `MultiClusterHub` resource, when you install or upgrade to the latest version of {product-title}. The link:https://github.com/openshift/oadp-operator[OADP Operator] is also automatically installed, which uses link:https://velero.io/[Velero] on the {product-title-short} hub cluster; Velero is used to backup and restore {product-title-short} hub cluster resources. 

For a list of supported storage providers for Velero, see https://velero.io/docs/v1.7/supported-providers/#s3-compatible-object-store-providers[S3-Compatible object store providers].

* <<prerequisites-backup-restore,Prerequisites>>
* <<backup-restore-architecture,Backup and restore operator architecture>>
* <<restore-backup,Restore a backup>>
* <<backup-validation-using-a-policy,Backup validation using a policy>>

[#prerequisites-backup-restore]
== Prerequisites

- You must install the latest version of the OADP Operator. See the link:https://github.com/openshift/oadp-operator/blob/master/docs/install_olm.md[Install OADP Operator using OperatorHub] documentation. 

- Be sure to complete the steps to link:https://github.com/openshift/oadp-operator/blob/master/docs/install_olm.md#create-credentials-secret[Create credentials secret] for the cloud storage where the backups are saved. 

- Use the created secret when you link:https://github.com/openshift/oadp-operator/blob/master/docs/install_olm.md#create-the-velero-custom-resource[Create the Velero Custom Resource].

**Note**: The cluster backup and restore operator resources must be created in the same namespace where the OADP Operator is installed.

[#backup-restore-architecture]
== Backup and restore operator architecture

The operator defines the `backupSchedule.cluster.open-cluster-management.io` resource, which is used to set up {product-title-short} backup schedules, and `restore.cluster.open-cluster-management.io` resource, which is used to process and restore these backups. The operator creates corresponding Velero resources, and defines the options needed to backup remote clusters and any other hub cluster resources that need to be restored. View the following diagram:

image:../images/cluster_backup_controller_dataflow.png[Backup and restore architecture diagram] 

[#schedule-backup]
== Schedule a cluster backup

After you create a `backupschedule.cluster.open-cluster-management.io` resource you can run the following command to get the status of the scheduled cluster backups: `oc get bsch -n <oadp-operator-ns>`. The `<oadp-operator-ns>` is the namespace where `BackupSchedule` is created and must be in the same namespace where the OADP Operator is installed.

The `backupSchedule.cluster.open-cluster-management.io` resource creates the following three `schedule.velero.io` resources:

* `acm-managed-clusters-schedule`: This resource is used to schedule backups for the managed cluster resources, including managed clusters, cluster pools, and cluster sets.
+
**Note**: The following resources are being retrieved by this backup; they are required for restoring all managed clusters information on the new hub cluster:
+
*** Secrets and ConfigMaps from the `hive` and `openshift-operator-lifecycle-manager` namespaces, and from all of the `ManagedClusters resources` namespaces created on the hub cluster.
*** Cluster-level `ManagedCluster` resource.
*** Other namespace-scoped resources used to restore the managed cluster details, such as `ServiceAccount`, `ManagedClusterInfo`, `ManagedClusterSet`, `ManagedClusterSetBindings`, `KlusterletAddonConfig`, `ManagedClusterView`, `ClusterPool`, `ClusterProvision`, `ClusterDeployment`, `ClusterSyncLease`, `ClusterSync`, and `ClusterCurator`.

* `acm-credentials-schedule`: This resource is used to schedule backups for the user created credentials and any copy of those credentials. These credentials are identified by the `cluster.open-cluster-management.io/type` label selector; all secrets that define the label selector are included in the backup.
+
**Note**: If you have any user-defined private channels, you can include the channel secrets in this credentials backup if you set the `cluster.open-cluster-management.io/type` label selector to this secret. Without the `cluster.open-cluster-management.io/type` label selector, channel secrets are not identified by the `acm-credentials-schedule` backup and need to be manually recreated on the restored cluster.

* `acm-resources-schedule`: This resource is used to schedule backups for the `Applications` and `Policy` resources, including any required resources, such as:
+
`Applications`: `Channels`, `Subscriptions`, `Deployables` and `PlacementRules`
+
`Policy`: `PlacementBindings`, `Placement`, and `PlacementDecisions` 
+
There are no resources being collected from the `local-cluster` or `open-cluster-management` namespaces.

[#restore-backup]
== Restore a backup

In a usual restore scenario, the hub cluster where the backups are run becomes unavailable, and the backed up data needs to be moved to a new hub cluster. This is done by running the cluster restore operation on the new hub cluster. In this case, the restore operation runs on a different hub cluster than the one where the backup is created.

There are also cases where you want to restore the data on the same hub cluster where the backup was collected, so the data from a previous snapshot can be recovered. In this case, both restore and backup operations are run on the same hub cluster.

After you create a `restore.cluster.open-cluster-management.io` resource on the hub cluster, you can run the following command to get the status of the restore operation: `oc get restore -n <oadp-operator-ns>`. You should also be able to verify that the backed up resources that are contained by the backup file are created.

**Note**: The `restore.cluster.open-cluster-management.io` resource is run once. If you want to run the same restore operation again after the restore operation is complete, you have to create a new `restore.cluster.open-cluster-management.io` resource with the same `spec` options.

The restore operation is used to restore all three backup types that are created by the backup operation. However, you can choose to install only a certain type of backup (only managed clusters, only user credentials, or only hub cluster resources).

The restore defines the following three required `spec` properties, where the restore logic is defined for the types of backed up files:

* `veleroManagedClustersBackupName` is used to define the restore option for the managed clusters.
* `veleroCredentialsBackupName` is used to define the restore option for the user credentials.
* `veleroResourcesBackupName` is used to define the restore option for the hub cluster resources (`Applications` and `Policy`).
+
The valid options for the previously mentioned properties are following values:
+
** `latest` - This property restores the last available backup file for this type of backup.
** `skip` - This property does not attempt to restore this type of backup with the current restore operation.
** `<backup_name>` - This property restores the specified backup pointing to it by name. 

The name of the `restore.velero.io` resources that are created by the `restore.cluster.open-cluster-management.io` is generated using the following template rule, `<restore.cluster.open-cluster-management.io name>-<velero-backup-resource-name>`. View the following descriptions:

* `restore.cluster.open-cluster-management.io name` is the name of the current `restore.cluster.open-cluster-management.io` resource, which initiates the restore.
* `velero-backup-resource-name` is the name of the Velero backup file that is used for restoring the data. For example, the `restore.cluster.open-cluster-management.io` resource named `restore-acm` creates `restore.velero.io` restore resources. View the following examples for the format:
+
** `restore-acm-acm-managed-clusters-schedule-20210902205438` is used for restoring managed cluster backups. In this sample, the `backup.velero.io` backup name used to restore the resource is `acm-managed-clusters-schedule-20210902205438`.
** `restore-acm-acm-credentials-schedule-20210902206789` is used for restoring credential backups. In this sample, the `backup.velero.io` backup name used to restore the resource is `acm-managed-clusters-schedule-20210902206789`.
** `restore-acm-acm-resources-schedule-20210902201234` is used for restoring application and policy backups. In this sample, the `backup.velero.io` backup name used to restore the resource is `acm-managed-clusters-schedule-20210902201234`.
+
*Note*: If `skip` is used for a backup type, `restore.velero.io` is not created.

View the following YAML sample of the cluster `Restore` resource. In this sample, all three types of backed up files are being restored, using the latest available backed up files:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Restore
metadata:
  name: restore-acm
spec:
  veleroManagedClustersBackupName: latest
  veleroCredentialsBackupName: latest
  veleroResourcesBackupName: latest
----

**Notes**:

** Only managed clusters created using the `hive` API are automatically imported when the backup is restored on another hub cluster. All other managed clusters show up as _Pending Import_ and must be manually imported back on the new hub cluster.
** When you restore a backup on a new hub cluster, make sure that the previous hub cluster, where the backup was created, is shut down. If it is running, the previous hub cluster tries to reimport the managed clusters as soon as the managed cluster reconciliation finds that the managed clusters are no longer available.

[#backup-validation-using-a-policy]
== Backup validation using a policy

The cluster backup and restore operator Helm chart (`cluster-backup-chart`) installs the `backup-restore-enabled` policy on your hub cluster, which is used to inform you about issues with the backup and restore component. The `backup-restore-enabled` policy includes a set of templates that check for the following constraints:

- *Pod validation*
+
The following templates check the pod status for the backup component and dependencies:
+
** `acm-backup-pod-running` template checks if the backup and restore operator pod is running.
** `oadp-pod-running` template checks if the OADP operator pod is running. 
** `velero-pod-running` template checks if the Velero pod is running.

- *Backup storage validation*
+
* `backup-storage-location-available` template checks if a `BackupStorageLocation.velero.io` resource is created and if the status value is `Available`. This implies that the connection to the backup storage is valid. 

- *BackupSchedule collision validation*
+
* `acm-backup-clusters-collision-report` template verifies that the status is not `BackupCollision`, if a `BackupSchedule.cluster.open-cluster-management.io` exists on the current hub cluster. This verifies that the current hub cluster is not in collision with any other hub cluster when you write backup data to the storage location.
+
For a definition of the `BackupCollision` state read the https://github.com/stolostron/cluster-backup-operator#backup-collisions[Backup Collisions section].

- *BackupSchedule and restore status validation*
+
* `acm-backup-phase-validation` template checks that the status is not in `Failed`, or `Empty` state, if a `BackupSchedule.cluster.open-cluster-management.io` exists on the current cluster. This ensures that if this cluster is the primary hub cluster and is generating backups, the `BackupSchedule.cluster.open-cluster-management.io` status is healthy.
* The same template checks that the status is not in a `Failed`, or `Empty` state, if a `Restore.cluster.open-cluster-management.io` exists on the current cluster. This ensures that if this cluster is the secondary hub cluster and is restoring backups, the `Restore.cluster.open-cluster-management.io` status is healthy.

- *Backups exist validation*
+
* `acm-managed-clusters-schedule-backups-available` template checks if `Backup.velero.io` resources are available at the location specified by the `BackupStorageLocation.velero.io`, and if the backups are created by a `BackupSchedule.cluster.open-cluster-management.io` resource. This validates that the backups have been run at least once, using the backup and restore operator.

- *Backups are actively running as a cron job*
+
* A `BackupSchedule.cluster.open-cluster-management.io` actively runs and saves new backups at the storage location. This validation is done by the `backup-schedule-cron-enabled` policy template. The template checks that there is a `Backup.velero.io` with `velero.io/schedule-name: acm-validation-policy-schedule` label at the storage location.
+
The `acm-validation-policy-schedule` backups are set to expire after the time is set for the backups cron schedule. If no cron job is running to create backups, the old `acm-validation-policy-schedule` backup is deleted because it expired and a new one is not created. As a result, if no `acm-validation-policy-schedule backups` exist at any moment, it means that there are no active cron jobs generating backups.
+
This policy is intended to help notify the hub cluster administrator of any backup issues when the hub cluster is active and produces or restore backups.


Learn how to enable and manage the cluster backup and restore operator, see xref:../clusters/backup_restore_enable.adoc#backup-restore-enable[Enable the backup and restore operator].


