[#hosted-bare-metal-adding-agents-ibmz]
= Adding IBM Z agents to the InfraEnv resource (Technology Preview)

To attach compute nodes to a hosted control plane, create agents that help you to scale the node pool. Adding agents in an IBM Z environment requires additional steps, which are described in detail in this section.  

*Note:* Unless stated otherwise, these procedures apply to both z/VM and RHEL KVM installations on IBM Z and IBM LinuxONE.

[#hosted-bare-metal-adding-agents-ibmz-kvm]
== Adding IBM Z KVM as agents

For IBM Z with KVM, run the following command to start your IBM Z environment with the downloaded PXE images from the `InfraEnv` resource. After the Agents are created, the host communicates with the Assisted Service and registers in the same namespace as the `InfraEnv` resource on the management cluster.

[source,bash]
----
virt-install \
   --name "<vm_name>" \ <1>
   --autostart \
   --ram=16384 \
   --cpu host \
   --vcpus=4 \
   --location "<path_to_kernel_initrd_image>,kernel=kernel.img,initrd=initrd.img" \ <2>
   --disk <qcow_image_path> \ <3>
   --network network:macvtap-net,mac=<mac_address> \ <4>
   --graphics none \
   --noautoconsole \
   --wait=-1
   --extra-args "rd.neednet=1 nameserver=<nameserver>   coreos.live.rootfs_url=http://<http_server>/rootfs.img random.trust_cpu=on rd.luks.options=discard ignition.firstboot ignition.platform.id=metal console=tty1 console=ttyS1,115200n8 coreos.inst.persistent-kargs=console=tty1 console=ttyS1,115200n8" <5>
----

<1> Specify the name of the virtual machine.
<2> Specify the location of the `kernel_initrd_image` file.
<3> Specify the disk image path.
<4> Specify the Mac address.
<5> Specify the server name of the agents.

For ISO boot, download ISO from the `InfraEnv` resource and boot the nodes by running the following command:

[source,bash]
----
virt-install \
  --name "<vm_name>" \ <1>
  --autostart \
  --memory=16384 \
  --cpu host \
  --vcpus=4 \
  --network network:macvtap-net,mac=<mac_address> \ <2>
  --cdrom "<path_to_image.iso>" \ <3>
  --disk <qcow_image_path> \
  --graphics none \
  --noautoconsole \
  --os-variant <os_version> \ <4>
  --wait=-1
----
<1> Specify the name of the virtual machine.
<2> Specify the Mac address.
<3> Specify the location of the `image.iso` file.
<4> Specify the pperating system version that you are using.

[#hosted-bare-metal-adding-agents-ibmz-zvm]
== Adding IBM Z LPAR as agents

With {ocp-short} 4.16, you can add the Logical Partition (LPAR) on IBM Z or IBM LinuxONE as a compute node to a hosted control plane.

. Create a boot parameter file for the agents.

+
.Example parameter file
[source,yaml]
----
rd.neednet=1 cio_ignore=all,!condev \
console=ttysclp0 \
ignition.firstboot ignition.platform.id=metal
coreos.live.rootfs_url=http://<http_server>/rhcos-<version>-live-rootfs.<architecture>.img \// <1>
coreos.inst.persistent-kargs=console=ttysclp0
ip=<ip>::<gateway>:<netmask>:<hostname>::none nameserver=<dns> \// <2>
rd.znet=qeth,<network_adaptor_range>,layer2=1
rd.<disk_type>=<adapter> \// <3>
zfcp.allow_lun_scan=0
ai.ip_cfg_override=1 \// <4>
random.trust_cpu=on rd.luks.options=discard
----
<1> For the `coreos.live.rootfs_url` artifact, specify the matching `rootfs` artifact for the `kernel` and `initramfs` that you are starting. Only HTTP and HTTPS protocols are supported.
<2> For the `ip` parameter, manually assign the IP address, as described in _Installing a cluster with z/VM on IBM Z and IBM LinuxONE_.
<3> For installations on DASD-type disks, use `rd.dasd` to specify the DASD where Red Hat Enterprise Linux CoreOS (RHCOS) is to be installed. For installations on FCP-type disks, use `rd.zfcp=<adapter>,<wwpn>,<lun>` to specify the FCP disk where RHCOS is to be installed.
<4> Specify this parameter when you use an Open Systems Adapter (OSA) or HiperSockets.

. Generate the `.ins` and `initrd.img.addrsize` files.
+
The `.ins` file includes installation data and is on the FTP server. You can access the file from the HMC system. The `.ins` file contains details such as mapping of the location of installation data on the disk or FTP server, the memory locations where the data is to be copied.
+
*Note*: In {ocp-short} 4.16, the `.ins` file and `initrd.img.addrsize` are not automatically generated as part of boot-artifacts from the installer. You must manually generate these files.

.. Run the following commands to get the size of the `kernel` and `initrd`: 

+
[source,yaml]
----
KERNEL_IMG_PATH='./kernel.img'
INITRD_IMG_PATH='./initrd.img'
CMDLINE_PATH='./generic.prm'
kernel_size=$(stat -c%s $KERNEL_IMG_PATH )
initrd_size=$(stat -c%s $INITRD_IMG_PATH)
----

.. Round the `kernel` size up to the next MiB boundary. This value is the starting address of `initrd.img`.

+
[source,bash]
----
offset=$(( (kernel_size + 1048575) / 1048576 * 1048576 ))
----

.. Create the kernel binary patch file that contains the `initrd` address and size by running the following commands:

+
[source,bash]
----
INITRD_IMG_NAME=$(echo $INITRD_IMG_PATH | rev | cut -d '/' -f 1 | rev)
KERNEL_OFFSET=0x00000000
KERNEL_CMDLINE_OFFSET=0x00010480
INITRD_ADDR_SIZE_OFFSET=0x00010408
OFFSET_HEX=$(printf '0x%08x\n' $offset)
----

.. Convert the address and size to binary format by running the following commands:

+
[source,bash]
----
printf "$(printf '%016x\n' $initrd_size)" | xxd -r -p > temp_size.bin
----

.. Combine the address and size binaries by running the following command:

+
[source,bash]
----
cat temp_address.bin temp_size.bin > "$INITRD_IMG_NAME.addrsize"
----

.. Clean up temporary files by running the following command:

+
[source,bash]
----
rm -rf temp_address.bin temp_size.bin
----

.. Create the `.ins` file. The file is based on the paths of the `kernel.img`, `initrd.img`, `initrd.img.addrsize`, and `cmdline` files and the memory locations where the data is to be copied.

+
[source,yaml]
----
$KERNEL_IMG_PATH $KERNEL_OFFSET
$INITRD_IMG_PATH $OFFSET_HEX
$INITRD_IMG_NAME.addrsize $INITRD_ADDR_SIZE_OFFSET
$CMDLINE_PATH $KERNEL_CMDLINE_OFFSET
----

. Transfer the `initrd`, `kernel`, `generic.ins`, and `initrd.img.addrsize` parameter files to the file server. For more information about how to transfer the files with FTP and boot, see link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/performing_a_standard_rhel_8_installation/installing-in-an-lpar_installing-rhel[Installing in an LPAR].    

. Start the machine.

. Repeat the procedure for all other machines in the cluster.

[#hosted-bare-metal-adding-agents-ibmz-zvm-lpar]
== Adding IBM z/VM as agents

If you want to use a static IP for z/VM guest, you must configure the `NMStateConfig` attribute for the z/VM agent so that the IP parameter persists in the second start.

Complete the following steps to start your IBM Z environment with the downloaded PXE images from the `InfraEnv` resource. After the Agents are created, the host communicates with the Assisted Service and registers in the same namespace as the `InfraEnv` resource on the management cluster.

. Update the parameter file to add the `rootfs_url`, `network_adaptor` and `disk_type` values. 

+
.Example parameter file
[source,yaml]
----
rd.neednet=1 cio_ignore=all,!condev \
console=ttysclp0  \
ignition.firstboot ignition.platform.id=metal \
coreos.live.rootfs_url=http://<http_server>/rhcos-<version>-live-rootfs.<architecture>.img \// <1>
coreos.inst.persistent-kargs=console=ttysclp0
ip=<ip>::<gateway>:<netmask>:<hostname>::none nameserver=<dns> \// <2>
rd.znet=qeth,<network_adaptor_range>,layer2=1
rd.<disk_type>=<adapter> \// <3>
zfcp.allow_lun_scan=0
ai.ip_cfg_override=1 \// <4>
----
<1> For the `coreos.live.rootfs_url` artifact, specify the matching `rootfs` artifact for the `kernel` and `initramfs` that you are starting. Only HTTP and HTTPS protocols are supported.
<2> For the `ip` parameter, manually assign the IP address, as described in _Installing a cluster with z/VM on IBM Z and IBM LinuxONE_.
<3> For installations on DASD-type disks, use `rd.dasd` to specify the DASD where Red Hat Enterprise Linux CoreOS (RHCOS) is to be installed. For installations on FCP-type disks, use `rd.zfcp=<adapter>,<wwpn>,<lun>` to specify the FCP disk where RHCOS is to be installed.
<4> Specify this parameter when you use an Open Systems Adapter (OSA) or HiperSockets.

. Move `initrd`, kernel images, and the parameter file to the guest VM by running the following commands:

+
[source,bash]
----
vmur pun -r -u -N kernel.img $INSTALLERKERNELLOCATION/<image name>
----

+
[source,bash]
----
vmur pun -r -u -N generic.parm $PARMFILELOCATION/paramfilename
----

+
[source,bash]
----
vmur pun -r -u -N initrd.img $INSTALLERINITRAMFSLOCATION/<image name>
----

+
//lahinson - nov 2023 - adding comment to ensure proper formatting

. Run the following command from the guest VM console:

+
[source,bash]
----
cp ipl c
----

+
//lahinson - nov 2023 - adding comment to ensure proper formatting

. To list the agents and their properties, enter the following command:

+
[source,bash]
----
oc -n <hosted_control_plane_namespace> get agents
----

+
See the following example output:

+
[source,bash]
----
NAME    CLUSTER APPROVED    ROLE    STAGE
50c23cda-cedc-9bbd-bcf1-9b3a5c75804d    auto-assign
5e498cd3-542c-e54f-0c58-ed43e28b568a    auto-assign
----

. Run the following command to approve the agent. 

+
*Optional:* You can set the agent ID `<installation_disk_id>` and `<hostname>` in the specification.

+
[source,bash]
----
oc -n <hosted_control_plane_namespace> patch agent 50c23cda-cedc-9bbd-bcf1-9b3a5c75804d -p '{"spec":{"installation_disk_id":"/dev/sda","approved":true,"hostname":"worker-zvm-0.hostedn.example.com"}}' --type merge
----

. Run the following command to verify that the agents are approved:

+
[source,bash]
----
oc -n <hosted_control_plane_namespace> get agents
----

+
.Example output
[source,bash]
----
NAME                                            CLUSTER     APPROVED   ROLE          STAGE
50c23cda-cedc-9bbd-bcf1-9b3a5c75804d             true       auto-assign
5e498cd3-542c-e54f-0c58-ed43e28b568a             true       auto-assign
----