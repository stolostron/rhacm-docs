[#deploying-aws-private-clusters]
= Deploying a private hosted cluster on AWS (Technology Preview)

After you set up the hosted control planes command line interface, `hcp`, and enable the `local-cluster` as the hosting cluster, you can deploy a hosted cluster or a private hosted cluster on AWS. To deploy a public hosted cluster on AWS, see _Deploying a hosted cluster on AWS_.

By default, hosted control plane guest clusters are publicly accessible through public DNS and the default router for the management cluster.

For private clusters on AWS, all communication with the guest cluster occurs over AWS PrivateLink. To configure hosted control planes for private cluster support on AWS, take the following steps.

*Important:* Although public clusters can be created in any region, private clusters can be created only in the region that is specified by `--aws-private-region`.

* <<prerequisites-aws-private-clusters,Prerequisites>>
* <<create-aws-private-hosted-cluster,Creating a private hosted cluster on AWS>>
* <<access-aws-private-hosted-cluster,Accessing a private hosting cluster on AWS>>
* <<additional-resources-private-hosted-cluster-aws,Additional resources>>

[#prerequisites-aws-private-clusters]
== Prerequisites

To enable private hosted clusters for AWS, you must first enable AWS PrivateLink. For more information, see xref:../../clusters/hosted_control_planes/enable_aws_private_link.adoc#hosted-enable-private-link[Enabling AWS PrivateLink].

[#create-aws-private-hosted-cluster]
== Creating a private hosted cluster on AWS

. Create the private cluster IAM policy document by entering the following command:
+
----
cat << EOF >> policy.json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "ec2:CreateVpcEndpointServiceConfiguration",
        "ec2:DescribeVpcEndpointServiceConfigurations",
        "ec2:DeleteVpcEndpointServiceConfigurations",
        "ec2:DescribeVpcEndpointServicePermissions",
        "ec2:ModifyVpcEndpointServicePermissions",
        "ec2:CreateTags",
        "elasticloadbalancing:DescribeLoadBalancers"
      ],
      "Resource": "\*"
    }
  ]
}
----

. Create the IAM policy in AWS by entering the following command:
+
----
aws iam create-policy --policy-name=hypershift-operator-policy --policy-document=file://policy.json
----

. Create a `hypershift-operator` IAM user by entering the following command:
+
----
aws iam create-user --user-name=hypershift-operator
----

. Attach the policy to the `hypershift-operator` user by entering this command, replacing `<policy-arn>` with the ARN of the policy that you created:
+
----
aws iam attach-user-policy --user-name=hypershift-operator --policy-arn=<policy-arn>
----

. Create an IAM access key for the user by entering this command:
+
----
aws iam create-access-key --user-name=hypershift-operator
----

. Create a private hosted cluster by entering the following command, replacing variables with your values as needed:
+
----
hcp create cluster aws \
--name <hosted-cluster-name> \ <1>
--node-pool-replicas=<node-pool-replica-count> \ <2>
--base-domain <basedomain> \ <3>
--pull-secret <path-to-pull-secret> \ <4>
--aws-creds <path-to-aws-credentials> \ <5>
--region <region> \ <6>
--endpoint-access Private <7>
----

+
<1> Specify the name of your hosted cluster, for instance, `example`.
<2> Specify the node pool replica count, for example, `3`.
<3> Specify your base domain, for example, `example.com`.
<4> Specify the path to your pull secret, for example, `/user/name/pullsecret`.
<5> Specify the path to your AWS credentials file, for example, `/user/name/.aws/credentials`.
<6> Specify the AWS region name, for example, `us-east-1`.
<7> Defines whether a cluster is public or private.

+
The API endpoints for the cluster are accessible through a private DNS zone:

- `api.<hosted-cluster-name>.hypershift.local`
- `*.apps.<hosted-cluster-name>.hypershift.local`

[#access-aws-private-hosted-cluster]
== Accessing a private hosting cluster on AWS

You can access a private cluster by using a bastion instance.

//lahinson - july 2023 - update hypershift cli command here
. Start a bastion instance by entering the following command:
+
----
hcp create bastion aws --aws-creds=<aws-creds> --infra-id=<infra-id> --region=<region> --ssh-key-file=<ssh-key>
----

+
Replace `<ssh-key>` with the SSH public key file to connect to the bastion. The default location for the SSH public key file is `~/.ssh/id_rsa.pub`. Replace `<aws-creds>` with the path to your AWS credentials file, for example, `/user/name/.aws/credentials`.

. Find the private IPs of nodes in the cluster node pool by entering the following command:
+
----
aws ec2 describe-instances --filter="Name=tag:kubernetes.io/cluster/<infra-id>,Values=owned" | jq '.Reservations[] | .Instances[] | select(.PublicDnsName=="") | .PrivateIpAddress'
----

. Create a `kubeconfig` file for the cluster that can be copied to a node by entering the following command:
+
----
hcp create kubeconfig > <cluster-kubeconfig>
----

. Enter the following command to SSH into one of the nodes through the bastion by using the IP that is printed from the `create bastion` command:
+
----
ssh -o ProxyCommand="ssh ec2-user@<bastion-ip> -W %h:%p" core@<node-ip>
----

. From the SSH shell, copy the `kubeconfig` file contents to a file on the node by entering the following command:
+
----
mv <path-to-kubeconfig-file> <new-file-name>
----

. Export the kubeconfig file by entering the following command:
+
----
export KUBECONFIG=<path-to-kubeconfig-file>
----

. Observe the guest cluster status by entering the following command:
+
----
oc get clusteroperators clusterversion
----

[#additional-resources-private-hosted-cluster-aws]
== Additional resources

For more information about deploying a public hosted cluster on AWS, see xref:../hosted_control_planes/managing_hosted_aws.adoc#hosted-deploy-cluster-aws[Deploying a hosted cluster on AWS].
