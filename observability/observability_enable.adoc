[#enabling-observability-service]
= Enabling observability service

Monitor the health of your managed clusters with the observability service (`multicluster-observability-operator`).

*Required access:* Cluster administrator or the `open-cluster-management:cluster-manager-admin` role.

* <<prerequisites-observability,Prerequisites>>
* <<enabling-observability,Enabling observability>>
* <<creating-mco-cr,Creating the MultiClusterObservability CR>>
* <<enabling-observability-ocp,Enabling observability from the {ocp} console>>
* <<external-metric-query,Using the external metric query>>
* <<disabling-observability-resource,Disabling observability>>

[#prerequisites-observability]
== Prerequisites
 
- You must install {product-title}. See link:../install/install_connected.adoc#installing-while-connected-online[Installing while connected online] for more information.
- You must define a storage class in the `MultiClusterObservability` CR, if there is no default storage class specified.
- You must configure an object store to create a storage solution. {product-title-short} supports the following cloud providers with stable object stores:

* https://aws.amazon.com/getting-started/hands-on/lightsail-object-storage/[Amazon Web Services S3 (AWS S3)]
* https://www.redhat.com/en/technologies/storage/ceph[Red Hat Ceph (S3 compatible API)]
* https://cloud.google.com/storage[Google Cloud Storage]
* https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction[Azure storage]
* https://www.redhat.com/en/technologies/cloud-computing/openshift-data-foundation[Red Hat OpenShift Data Foundation (formerly known as Red Hat OpenShift Container Storage)]
* https://www.ibm.com/docs/en/baw/20.x?topic=storage-preparing-cloud-public-roks[Red Hat OpenShift on IBM (ROKS)]
//* https://www.ibm.com/docs/en/spectrum-scale/5.0.5?topic=overview-s3-api[IBM Spectrum Scale]
+
*Important*: When you configure your object store, ensure that you meet the encryption requirements necessary when sensitive data is persisted. For more information on Thanos supported object stores, see https://thanos.io/tip/thanos/storage.md/#object-storage[Thanos documentation].

[#enabling-observability]
== Enabling observability

Enable the observability service by creating a `MultiClusterObservability` custom resource (CR) instance. Before you enable observability, see xref:../observability/observe_environments.adoc#observability-pod-capacity-requests[Observability pod capacity requests] for more information. 

*Note:* When observability is enabled or disabled on {ocp-short} managed clusters that are managed by {product-title-short}, the observability endpoint operator updates the `cluster-monitoring-config` `ConfigMap` by adding additional alertmanager configuration that restarts the local Prometheus automatically.

Complete the following steps to enable the observability service: 
 
. Log in to your {product-title-short} hub cluster. 
. Create a namespace for the observability service with the following command:
+
----
oc create namespace open-cluster-management-observability
----

. Generate your pull-secret. If {product-title-short} is installed in the `open-cluster-management` namespace, run the following command:
 
+
----
DOCKER_CONFIG_JSON=`oc extract secret/multiclusterhub-operator-pull-secret -n open-cluster-management --to=-`
----
+
If the `multiclusterhub-operator-pull-secret` is not defined in the namespace, copy the `pull-secret` from the `openshift-config` namespace into the `open-cluster-management-observability` namespace. Run the following command:
+
----
DOCKER_CONFIG_JSON=`oc extract secret/pull-secret -n openshift-config --to=-`
----
+
Then, create the pull-secret in the `open-cluster-management-observability` namespace, run the following command:
+
----
oc create secret generic multiclusterhub-operator-pull-secret \
    -n open-cluster-management-observability \
    --from-literal=.dockerconfigjson="$DOCKER_CONFIG_JSON" \
    --type=kubernetes.io/dockerconfigjson
----

. Create a secret for your object storage for your cloud provider. Your secret must contain the credentials to your storage solution. For example, run the following command:
+
----
oc create -f thanos-object-storage.yaml -n open-cluster-management-observability
----
+
View the following examples of secrets for the supported object stores:

** For Amazon S3 or S3 compatible, your secret might resemble the following file:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: s3
    config:
      bucket: YOUR_S3_BUCKET
      endpoint: YOUR_S3_ENDPOINT
      insecure: true
      access_key: YOUR_ACCESS_KEY
      secret_key: YOUR_SECRET_KEY
----
+
For more details, see https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html[Amazon Simple Storage Service user guide].

** For Google, your secret might resemble the following file: 
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: GCS
    config:
      bucket: YOUR_GCS_BUCKET
      service_account: YOUR_SERVICE_ACCOUNT
----
+
For more details, see https://cloud.google.com/storage/docs/introduction[Google Cloud Storage].

** For Azure your secret might resemble the following file:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: AZURE
    config:
      storage_account: YOUR_STORAGE_ACCT
      storage_account_key: YOUR_STORAGE_KEY
      container: YOUR_CONTAINER
      endpoint: blob.core.windows.net
      max_retries: 0
----
+
For more details, see https://docs.microsoft.com/en-us/azure/storage/[Azure Storage documentation].
+
*Note:* If you use Azure as an object storage for a {ocp} cluster, the storage account associated with the cluster is not supported. You must create a new storage account.

** For Red Hat OpenShift Data Foundation, your secret might resemble the following file:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: s3
    config:
      bucket: YOUR_RH_DATA_FOUNDATION_BUCKET
      endpoint: YOUR_RH_DATA_FOUNDATION_ENDPOINT
      insecure: false
      access_key: YOUR_RH_DATA_FOUNDATION_ACCESS_KEY
      secret_key: YOUR_RH_DATA_FOUNDATION_SECRET_KEY
----
+
For more details, see https://www.redhat.com/en/technologies/cloud-computing/openshift-data-foundation[Red Hat OpenShift Data Foundation].

** For Red Hat OpenShift on IBM (ROKS), your secret might resemble the following file:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: s3
    config:
      bucket: YOUR_ROKS_S3_BUCKET
      endpoint: YOUR_ROKS_S3_ENDPOINT
      insecure: true
      access_key: YOUR_ROKS_ACCESS_KEY
      secret_key: YOUR_ROKS_SECRET_KEY
----
+
For more details, follow the IBM Cloud documentation, https://cloud.ibm.com/objectstorage/create[Cloud Object Storage]. Be sure to use the service credentials to connect with the object storage. For more details, follow the IBM Cloud documentation, https://cloud.ibm.com/objectstorage/create%5BCloud[Cloud Object Store] and https://cloud.ibm.com/docs/cloud-object-storage/iam?topic=cloud-object-storage-service-credentials%5BService[Service Credentials].

. You can retrieve the S3 access key and secret key for your cloud providers with the following commands:
+
----
YOUR_CLOUD_PROVIDER_ACCESS_KEY=$(oc -n open-cluster-management-observability get secret <object-storage-secret> -o jsonpath="{.data.thanos\.yaml}" | base64 --decode | grep access_key | awk '{print $2}')

echo $ACCESS_KEY

YOUR_CLOUD_PROVIDER_SECRET_KEY=$(oc -n open-cluster-management-observability get secret <object-storage-secret> -o jsonpath="{.data.thanos\.yaml}" | base64 --decode | grep secret_key | awk '{print $2}')

echo $SECRET_KEY
----

You must decode, edit, and encode your `base64` string in the secret.

[#creating-mco-cr]
=== Creating the MultiClusterObservability CR

Complete the following steps to create the `MultiClusterObservability` custom resource (CR) for your managed cluster:

. Create the `MultiClusterObservability` custom resource YAML file named `_multiclusterobservability_cr.yaml_`. 
+
View the following default YAML file for observability:
+
[source,yaml]
----
apiVersion: observability.open-cluster-management.io/v1beta2
kind: MultiClusterObservability
metadata:
  name: observability
spec:
  observabilityAddonSpec: {}
  storageConfig:
    metricObjectStorage:
      name: thanos-object-storage
      key: thanos.yaml
----
+
You might want to modify the value for the `retentionConfig` parameter in the `advanced` section. For more information, see https://thanos.io/v0.8/components/compact/#downsampling-resolution-and-retention[Thanos Downsampling resolution and retention]. Depending on the number of managed clusters, you might want to update the amount of storage for stateful sets, see link:../apis/observability.json.adoc#observability-api[Observability API] for more information.
+
. To deploy on infrastructure machine sets, you must set a label for your set by updating the `_nodeSelector_` in the `MultiClusterObservability` YAML. Your YAML might resemble the following content:
+
----
  nodeSelector:
    node-role.kubernetes.io/infra: 
----
+
For more information, see https://docs.openshift.com/container-platform/4.11/machine_management/creating-infrastructure-machinesets.html[Creating infrastructure machine sets].

. Apply the observability YAML to your cluster by running the following command:
+
----
oc apply -f multiclusterobservability_cr.yaml
----
+
All the pods in `open-cluster-management-observability` namespace for Thanos, Grafana and AlertManager are created. All the managed clusters connected to the {product-title-short} hub cluster are enabled to send metrics back to the {product-title-short} Observability service.

. Validate that the observability service is enabled and the data is populated by launching the Grafana dashboards. Click the **Grafana link** that is near the console header, from either the console _Overview_ page or the _Clusters_ page.
+
*Note:* If you want to exclude specific managed clusters from collecting the observability data, add the following cluster label to your clusters: `observability: disabled`.

The observability service is enabled. After you enable the observability service the following functionalities are initiated:

* All the alert managers from the managed clusters are forwarded to the {product-title-short} hub cluster.
* All the managed clusters that are connected to the {product-title-short} hub cluster are enabled to send alerts back to the {product-title-short} observability service. You can configure the {product-title-short} Alertmanager to take care of deduplicating, grouping, and routing the alerts to the correct receiver integration such as email, PagerDuty, or OpsGenie. You can also handle silencing and inhibition of the alerts.
+
*Note:* Alert forwarding to the {product-title-short} hub cluster feature is only supported by managed clusters with {ocp} version 4.8 or later. After you install {product-title-short} with observability enabled, alerts from {ocp-short} v4.8 and later are automatically forwarded to the hub cluster.
+
See xref:../observability/customize_observability.adoc#forward-alerts[Forwarding alerts] to learn more.

* Access the {ocp-short} 3.11 Grafana dashboards with the following URL: `https://$ACM_URL/grafana/dashboards`. Select the folder named _OCP 3.11_ to view the {ocp-short} 3.11 dashboards.

[#enabling-observability-ocp]
== Enabling observability from the {ocp} console

Optionally, you can enable observability from the {ocp} console, create a project named `open-cluster-management-observability`. Be sure to create an image pull-secret named, `multiclusterhub-operator-pull-secret` in the `open-cluster-management-observability` project.

Create your object storage secret named, `thanos-object-storage` in the `open-cluster-management-observability` project. Enter the object storage secret details, then click *Create*. *Note:* See step 4 of the <<enabling-observability,Enabling observability>> section to view an example of a secret.

Create the `MultiClusterObservability` CR instance. When you receive the following message, the obseravbility service is enabled successfully from {ocp-short}: `Observability components are deployed and running`.

[#external-metric-query]
=== Using the external metric query

Observability provides an external API for metrics to be queried through the OpenShift route, `rbac-query-proxy`. View the following tasks to use `rbac-query-proxy` route:

* You can get the details of the route with the following command:
+
----
oc get route rbac-query-proxy -n open-cluster-management-observability
----

* To access the `rbac-query-proxy` route, you must have an OpenShift OAuth access token. The token should be associated with a user or service account, which has permission to get namespaces. For more information, see https://docs.openshift.com/container-platform/4.11/authentication/managing-oauth-access-tokens.html[Managing user-owned OAuth access tokens].

* Get the default CA certificate and store the content of the key `tls.crt` in a local file. Run the following command:
+
----
oc -n openshift-ingress get secret router-certs-default -o jsonpath="{.data.tls\.crt}" | base64 -d > ca.crt
----

* Run the following command to query metrics:
+
----
curl --cacert ./ca.crt -H "Authorization: Bearer {TOKEN}" https://{PROXY_ROUTE_URL}/api/v1/query?query={QUERY_EXPRESSION}
----
+
*Note:* The `QUERY_EXPRESSION` is the standard Prometheus query expression. For example, query the metrics `cluster_infrastructure_provider` by replacing the URL in the previously mentioned command, with the following URL: `https://{PROXY_ROUTE_URL}/api/v1/query?query=cluster_infrastructure_provider`. For more details, see https://prometheus.io/docs/prometheus/latest/querying/basics/[Querying prometheus].

* You can also replace certificates for the `rbac-query-proxy` route:
** See link:../governance/cert_mgmt_ingress.adoc#openssl-commands-for-generating-a-certificate[OpenSSL commands for generating a certificate] to create certificates. When you customize the `csr.cnf`, update the `DNS.1` to the hostname for the `rbac-query-proxy` route.
** Run the following command to create `proxy-byo-ca` and `proxy-byo-cert` secrets using the generated certificates:
+
----
oc -n open-cluster-management-observability create secret tls proxy-byo-ca --cert ./ca.crt --key ./ca.key

oc -n open-cluster-management-observability create secret tls proxy-byo-cert --cert ./ingress.crt --key ./ingress.key
----

[#dynamic-metrics-for-sno]
=== Dynamic metrics for single-node OpenShift clusters

Dynamic metrics collection supports automatic metric collection based on certain conditions. By default, a SNO cluster does not collect pod and container resource metrics. Once a SNO cluster reaches a specific level of resource consumption, the defined granular metrics are collected dynamically. When the cluster resource consumption is consistently less than the threshold for a period of time, granular metric collection stops.

The metrics are collected dynamically based on the conditions on the managed cluster specified by a collection rule. Because these metrics are collected dynamically, the following {product-title-short} Grafana dashboards do not display any data. When a collection rule is activated and the corresponding metrics are collected, the following panels display data for the duration of the time that the collection rule is initiated:

* Kubernetes / Compute Resources / Namespace (Pods)
* Kubernetes / Compute Resources / Namespace (Workloads)
* Kubernetes / Compute Resources / Nodes (Pods)
* Kubernetes / Compute Resources / Pod
* Kubernetes / Compute Resources / Workload

A collection rule includes the following conditions:

* A set of metrics to collect dynamically.
* Conditions written as a PromQL expression.
* A time interval for the collection, which must be set to `true`.
* A match expression to select clusters where the collect rule must be evaluated.

By default, collection rules are evaluated continuously on managed clusters every 30 seconds, or at a specific time interval. The lowest value between the collection interval and time interval takes precedence. Once the collection rule condition persists for the duration specified by the `for` attribute, the collection rule starts and the metrics specified by the rule are automatically collected on the managed cluster. Metrics collection stops automatically after the collection rule condition no longer exists on the managed cluster, at least 15 minutes after it starts.

The collection rules are grouped together as a parameter section named `collect_rules`, where it can be enabled or disabled as a group. {product-title-short} installation includes the collection rule group, `SNOResourceUsage` with two default collection rules: `HighCPUUsage` and `HighMemoryUsage`. The `HighCPUUsage` collection rule begins when the node CPU usage exceeds 70%. The `HighMemoryUsage` collection rule begins if the overall memory utilization of the SNO cluster exceeds 70% of the available node memory. Currently, the previously mentioned thresholds are fixed and cannot be changed. When a collection rule begins for more than the interval specified by the `for` attribute, the system automatically starts collecting the metrics that are specified in the `dynamic_metrics` section.

View the list of dynamic metrics that from the `collect_rules` section, in the following YAML file:

[source,yaml]
----
collect_rules:
  - group: SNOResourceUsage
    annotations:
      description: >
        By default, a SNO cluster does not collect pod and container resource metrics. Once a SNO cluster 
        reaches a level of resource consumption, these granular metrics are collected dynamically. 
        When the cluster resource consumption is consistently less than the threshold for a period of time, 
        collection of the granular metrics stops.
    selector:
      matchExpressions:
        - key: clusterType
          operator: In
          values: ["SNO"]
    rules:
    - collect: SNOHighCPUUsage
      annotations:
        description: >
          Collects the dynamic metrics specified if the cluster cpu usage is constantly more than 70% for 2 minutes
      expr: (1 - avg(rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100 > 70
      for: 2m
      dynamic_metrics:
        names:
          - container_cpu_cfs_periods_total
          - container_cpu_cfs_throttled_periods_total
          - kube_pod_container_resource_limits 
          - kube_pod_container_resource_requests   
          - namespace_workload_pod:kube_pod_owner:relabel 
          - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate 
          - node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate 
    - collect: SNOHighMemoryUsage
      annotations:
        description: >
          Collects the dynamic metrics specified if the cluster memory usage is constantly more than 70% for 2 minutes
      expr: (1 - sum(:node_memory_MemAvailable_bytes:sum) / sum(kube_node_status_allocatable{resource=\"memory\"})) * 100 > 70
      for: 2m
      dynamic_metrics:
        names:
          - kube_pod_container_resource_limits 
          - kube_pod_container_resource_requests 
          - namespace_workload_pod:kube_pod_owner:relabel
        matches:
          - __name__="container_memory_cache",container!=""
          - __name__="container_memory_rss",container!=""
          - __name__="container_memory_swap",container!=""
          - __name__="container_memory_working_set_bytes",container!=""
----

A `collect_rules.group` can be disabled in the `custom-allowlist` as shown in the following example. When a `collect_rules.group` is disabled, metrics collection reverts to the previous behavior. These metrics are collected at regularly, specified intervals:

[source,yaml]
----
collect_rules:
  - group: -SNOResourceUsage
---- 

The data is only displayed in Grafana when the rule is initiated.

[#disabling-observability-resource]
== Disabling observability

To disable the observability service, uninstall the `observability` resource. From the {ocp-short} console navigation, select *Operators* > *Installed Operators* > *Advanced Cluster Manager for Kubernetes*. Remove the `MultiClusterObservability` custom resource.

To learn more about customizing the observability service, see xref:../observability/customize_observability.adoc#customizing-observability[Customizing observability].


