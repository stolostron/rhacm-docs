[#hosted-control-planes-configure]
= Configuring hosted control planes

Configuring hosted control planes requires a hosting service cluster and a hosted cluster. By deploying the HyperShift operator on an existing cluster, you can make that cluster into a hosting service cluster and start the creation of the hosted cluster. 

Hosted control planes is a Technology Preview feature, so the related components are disabled by default. Enable the feature by editing the `multiclusterengine` custom resource to set the `spec.overrides.components[?(@.name=='hypershift-preview')].enabled` to `true`. 

Enter the following command to ensure that the hosted control planes feature is enabled:

----
oc patch mce multiclusterengine-sample --type=merge -p '{"spec":{"overrides":{"components":[{"name":"hypershift-preview","enabled": true}]}}}'
----

[#hosting-service-cluster-configure]
== Configuring the hosting service cluster

You can deploy hosted control planes by configuring an existing cluster to function as a hosting service cluster. The hosting service cluster is the {ocp-short} cluster where the control planes are hosted, and can be the hub cluster or one of the {ocp-short} managed clusters.

*Best practice:* Run hosted control planes and worker nodes on the same environment.

[#hosting-service-cluster-configure-prereq]
=== Prerequisites

You must have the following prerequisites to configure a hosting service cluster: 

* {mce} installed on at least one cluster that is managed by {ocp}. The {mce} is automatically installed when you install {product-title-short} version 2.5, and later, and can also be installed without {product-title-short} as an operator from the {ocp-short} OperatorHub.

* If you want your {product-title-short} hub cluster to be your hosting service cluster, you must configure `local-cluster` as your hosting service cluster by completing the following steps:
+
. Create a YAML file named `import-hub.yaml` that is similar to the following example: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  labels:
    local-cluster: "true"
    cloud: auto-detect
    vendor: auto-detect
  name: local-cluster
spec:
  hubAcceptsClient: true
  leaseDurationSeconds: 60
----
+
. Apply the file by entering:
+
----
oc apply -f import-hub.yaml
----

+
A hub cluster that is also managed by itself is designated as `local-cluster` in the list of clusters. 

[#hosting-service-cluster]
=== Configure the hosting service cluster

Complete the following steps on the cluster where the {mce} is installed to enable an {ocp-short} managed cluster as a hosting service cluster:

. If you plan to create and manage hosted clusters on AWS, create an OIDC S3 credentials secret named `hypershift-operator-oidc-provider-s3-credentials` for the HyperShift operator. Save the secret in the managed cluster namespace, which is the namespace of the managed cluster that is used as the hosting service cluster. If you used `local-cluster`, then create the secret in the `local-cluster` namespace
+
The secret must contain 3 fields. The `bucket` field contains an S3 bucket with public access to host OIDC discovery documents for your HyperShift clusters. The `credentials` field is a reference to a file that contains the credentials of the `default` profile that can access the bucket. By default, HyperShift only uses the `default` profile to operate the `bucket`. The `region` field specifies the region of the S3 bucket.
+
See https://hypershift-docs.netlify.app/getting-started/[Getting started] in the HyperShift documentation for more information about the secret. The following example shows a sample AWS secret template:
+
----
oc create secret generic hypershift-operator-oidc-provider-s3-credentials --from-file=credentials=$HOME/.aws/credentials --from-literal=bucket=<s3-bucket-for-hypershift> 
--from-literal=region=<region> -n <hypershift-hosting-service-cluster>
----
+
*Note:* Disaster recovery backup for the secret is not automatically enabled. Run the following command to add the label that enables the `hypershift-operator-oidc-provider-s3-credentials` secret to be backed up for disaster recovery:
+
----
oc label secret hypershift-operator-oidc-provider-s3-credentials -n <hypershift-hosting-service-cluster> cluster.open-cluster-management.io/backup=""
----

. If you plan to provision hosted clusters on the AWS platform with Private Link, create an AWS credential secret for the HyperShift operator and name it `hypershift-operator-private-link-credentials`. It must reside in the managed cluster namespace that is the namespace of the managed cluster being used as the hosting service cluster. If you used `local-cluster`, create the secret in the `local-cluster` namespace. See steps 1-5 in https://hypershift-docs.netlify.app/how-to/aws/deploy-aws-private-clusters/[Deploy AWS private clusters] for more details. 
+
The secret must contain the following three fields:
+
* `aws-access-key-id`: AWS credential access key id
+
* `aws-secret-access-key`: AWS credential access key secret
+
* `region`: Region for use with Private Link
+
See https://hypershift-docs.netlify.app/getting-started/[Getting started] in the HyperShift documentation for more information about the secret. The following example shows the sample `hypershift-operator-private-link-credentials` secret template:
+
----
oc create secret generic hypershift-operator-private-link-credentials --from-literal=aws-access-key-id=<aws-access-key-id> --from-literal=aws-secret-access-key=<aws-secret-access-key> --from-literal=region=<region> -n <hypershift-hosting-service-cluster>
----
+
*Note:* Disaster recovery backup for the secret is not automatically enabled. Run the following command to add the label that enables the `hypershift-operator-private-link-credentials` secret to be backed up for disaster recovery:
+
----
oc label secret hypershift-operator-private-link-credentials -n <hypershift-hosting-service-cluster> cluster.open-cluster-management.io/backup=""
----
+
Set the following parameter in the `HypershiftDeployment` custom resource when creating a cluster:
+
[source,yaml]
----
spec:
  hostedClusterSpec:
    platform:
      type: AWS
      aws:
        endpointAccess: Private
----
+
. If you plan to use service-level DNS for control plane services on the AWS platform, create an external DNS credential secret for the HyperShift operator and name it `hypershift-operator-external-dns-credentials`. It must reside in the managed cluster namespace that is the namespace of the managed cluster being used as the hosting service cluster. If you used `local-cluster`, then create the secret in the `local-cluster` namespace
+
The secret must contain the following three fields:
+
* `provider`: DNS provider that manages the service-level DNS zone (example: aws)
+
* `domain-filter`: The service-level domain
+
* `credentials`: (Optional, only when using aws keys) - For all external DNS types, a credential file is supported
+
* `aws-access-key-id`: (Optional) - When using AWS DNS service, credential access key id
+
* `aws-secret-access-key`: (Optional) - When using AWS DNS service, When using AWS DNS service, credential access key secret
+
See https://hypershift-docs.netlify.app/how-to/external-dns/[Use Service-level DNS for Control Plane Services] for more details. The following example shows the sample `hypershift-operator-external-dns-credentials` secret template:
+
----
oc create secret generic hypershift-operator-external-dns-credentials --from-literal=provider=aws --from-literal=domain-filter=service.my.domain.com --from-file=credentials=<credentials-file> -n <hypershift-hosting-service-cluster>
----
+
*Note:* Disaster recovery backup for the secret is not automatically enabled. Run the following command to add the label that enables the `hypershift-operator-external-dns-credentials` secret to be backed up for disaster recovery:
+
----
oc label secret hypershift-operator-external-dns-credentials -n <hypershift-hosting-service-cluster> cluster.open-cluster-management.io/backup=""
----
+
Set the following parameter in the `HypershiftDeployment` custom resource when creating a cluster:
+
[source,yaml]
----
spec:
  hostedClusterSpec:
    platform:
      type: AWS
      aws:
        endpointAccess: PublicAndPrivate
----
+
. Install the HyperShift add-on.
+
The cluster that hosts the HyperShift operator is the hosting service cluster. This step uses the `hypershift-addon` to install the HyperShift operator on a managed cluster.
+
.. Create a namespace where the HyperShift operator is created. 

.. Create the `ManagedClusterAddon` HyperShift add-on by creating a file that resembles the following example:
+
[source,yaml]
----
apiVersion: addon.open-cluster-management.io/v1alpha1
kind: ManagedClusterAddOn
metadata:
  name: hypershift-addon
  namespace: <managed-cluster-name> 
spec:
  installNamespace: open-cluster-management-agent-addon
----
+
Replace `managed-cluster-name` with the name of the managed cluster on which you want to install the HyperShift operator. If you are installing on the {product-title-short} hub cluster, then use `local-cluster` for this value.

.. Apply the file by running the following command:
+
----
oc apply -f <filename>
----
+
Replace `filename` with the name of the file that you created. 

. Confirm that the `hypershift-addon` is installed by running the following command:
+
----
oc get managedclusteraddons -n <hypershift-hosting-service-cluster> hypershift-addon
----
+
The output resembles the following example, when the add-on is installed:
+
----
NAME               AVAILABLE   DEGRADED   PROGRESSING
hypershift-addon   True
----

Your HyperShift add-on is installed and the hosting service cluster is available to manage HyperShift clusters.

[#hosted-deploy-cluster]
== Deploying a hosted cluster

After installing the HyperShift operator and enabling an existing cluster as a hosting service cluster, you can provision a HyperShift hosted cluster by creating a `HypershiftDeployment` custom resource. 

. Create a cloud provider secret as a credential using the console or a file addition. You must have permissions to create infrastructure resources for your cluster, like VPCs, subnets, and NAT gateways. The account also must correspond to the account for your guest cluster, where your workers live. See https://hypershift-docs.netlify.app/how-to/aws/create-infra-iam-separately/[Create AWS infrastructure and IAM resources separately] in the HyperShift documentation for more information about the required permissions.
+
The following example shows the secret format for AWS:
+
[source,yaml]
----
apiVersion: v1
metadata:
  name: my-aws-cred
  namespace: default      # Where you create HypershiftDeployment resources
type: Opaque
kind: Secret
stringData:
  ssh-publickey:          # Value
  ssh-privatekey:         # Value
  pullSecret:             # Value, required
  baseDomain:             # Value, required
  aws_secret_access_key:  # Value, required
  aws_access_key_id:      # Value, required
----
+
* To create this secret with the console, follow the credential creation steps by accessing *Credentials* in the navigation menu. 
+
* To create the secret using the command line, run the following commands:
+
----
oc create secret generic <my-secret> -n <hypershift-deployment-namespace> --from-literal=baseDomain='your.domain.com' --from-literal=aws_access_key_id='your-aws-access-key' --from-literal=aws_secret_access_key='your-aws-secret-key' --from-literal=pullSecret='your-quay-pull-secret' --from-literal=ssh-publickey='your-ssh-publickey' --from-literal=ssh-privatekey='your-ssh-privatekey'
----
+
*Note:* Disaster recovery backup for the secret is not automatically enabled. Run the following command to add a label that enables the secret to be backed up for disaster recovery:
+
----
oc label secret <my-secret> -n <hypershift-deployment-namespace> cluster.open-cluster-management.io/backup=""
----

. Create a `HypershiftDeployment` custom resource. The `HypershiftDeployment` custom resource creates the infrastructure in the provider account, configures the infrastructure compute capacity in the created infrastructure, provisions the `nodePools` that use the hosted control plane, and creates a hosted control plane on a hosting service cluster.
+
.. Create a file that contains information that resembles the following example: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: HypershiftDeployment
metadata:
  name: <cluster>
  namespace: default
spec:
  hostingCluster: <hosting-service-cluster>
  hostingNamespace: clusters
  infrastructure:
    cloudProvider:
      name: <my-secret>
    configure: True
    platform:
      aws:
        region: <region>
----
+
Replace `cluster` with the name of the cluster. 
+
Replace `hosting-service-cluster` with the name of the cluster that hosts the HyperShift operator. 
+
Replace `my-secret` with the secret to access your cloud provider. 
+ 
Replace `region` with the region of your cloud provider.

.. Apply the file by entering the following command:
+
----
oc apply -f <filename>
----
+
You can refer to the https://github.com/stolostron/hypershift-deployment-controller/blob/main/api/v1alpha1/hypershiftdeployment_types.go[field definitions] of the API to ensure that they are correct.

. Check the `HypershiftDeployment` status by running the following command:
+
----
oc get hypershiftdeployment -n default hypershift-demo -w
----

. After the hosted cluster is created, it is automatically imported to the hub. You can verify this by viewing the cluster list in the console, or by running the following command: 
+
----
oc get managedcluster <hypershiftDeployment.Spec.infraID>
----

[#hosted-deploy-cluster-customize]
== Deploying a customized hosted cluster

The `HypershiftDeployment` custom resource that you created provisions the hosted control plane and its nodePools with default values. You can also customize the hosted control plane and the nodePools by specifying `hostedClusterSpec` and `nodePools` in the `HypershiftDeployment` custom resource.

Create a file that contains information that resembles the following example: 

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: HypershiftDeployment
metadata:
  name: <cluster>
  namespace: default
spec:
  hostingCluster: <hosting-service-cluster>
  hostingNamespace: clusters
  hostedClusterSpec:
    networking:
      machineCIDR: 10.0.0.0/16    # Default
      networkType: OVNKubernetes
      podCIDR: 10.132.0.0/14      # Default
      serviceCIDR: 172.31.0.0/16  # Default
    platform:
      type: AWS
    pullSecret:
      name: <cluster>-pull-secret    # This secret is created by the controller
    release:
      image: quay.io/openshift-release-dev/ocp-release:4.11.2-x86_64  # Default
    services:
    - service: APIServer
      servicePublishingStrategy:
        type: LoadBalancer
    - service: OAuthServer
      servicePublishingStrategy:
        type: Route
    - service: Konnectivity
      servicePublishingStrategy:
        type: Route
    - service: Ignition
      servicePublishingStrategy:
        type: Route
    sshKey: {}
  nodePools:
  - name: <cluster>-<zone-1>
    spec:
      clusterName: <cluster>
      management:
        autoRepair: false
        replace:
          rollingUpdate:
            maxSurge: 1
            maxUnavailable: 0
          strategy: RollingUpdate
        upgradeType: Replace
      platform:
        aws:
          instanceType: m5.large
        type: AWS
      release:
        image: quay.io/openshift-release-dev/ocp-release:4.10.15-x86_64
      replicas: 3
  - name: <cluster>-<zone-2>
    spec:
      clusterName: <cluster>
      management:
        autoRepair: false
        replace:
          rollingUpdate:
            maxSurge: 1
            maxUnavailable: 0
          strategy: RollingUpdate
        upgradeType: Replace
      platform:
        aws:
          instanceType: m5.large
        type: AWS
      release:
        image: quay.io/openshift-release-dev/ocp-release:4.10.15-x86_64
      replicas: 3
  infrastructure:
    cloudProvider:
      name: <my-secret>
    configure: True
    platform:
      aws:
        region: <region>
        zones:
          - <zone-1>
          - <zone-2>
----

Replace `zone-1` with the name of the zone in the region.

Replace `zone-2` with the name of the zone in the region. 

[#hosting-service-cluster-access]
== Accessing a hosting service cluster

You can now access your cluster. The access secrets are stored in the `hypershift-hosting-service-cluster` namespace. This namespace is the same as the name of the hosting service cluster. Learn about the following formats secret name formats:

- `kubeconfig` secret: `<hypershiftDeployment.Spec.hostingNamespace>-<hypershiftDeployment.Name>-admin-kubeconfig` (clusters-hypershift-demo-admin-kubeconfig)
- `kubeadmin` password secret: `<hypershiftDeployment.Spec.hostingNamespace>-<hypershiftDeployment.Name>-kubeadmin-password` (clusters-hypershift-demo-kubeadmin-password)
