[#upgrading-disconnected-clusters-with-cincinnati]
= Upgrading disconnected clusters with {cincinnati}

You can use {cincinnati} with {product-title} to upgrade your clusters in a disconnected environment.

In some cases, security concerns prevent clusters from being connected directly to the Internet. This makes it difficult to know when upgrades are available, and how to process those upgrades. Configuring {cincinnati-short} can help. 

{cincinnati-short} is a separate operator and operand that monitors the available versions of your managed clusters in a disconnected environment, and makes them available for upgrading your clusters in a disconnected environment. After {cincinnati-short} is configured, it can perform the following actions:

. Monitors when upgrades are available for your disconnected clusters
. Identifies which updates are mirrored to your local site for upgrading by using the graph data file
. Notifies you that an upgrade is available for your cluster by using the {product-title-short} console

[#cincinnati-prerequisites]
== Prerequisites

You must have the following prerequisites before you can use {cincinnati-short} to upgrade your disconnected clusters:

* A deployed {product-title-short} hub cluster that is running on {ocp} version 4.5, or later with restricted OLM configured. See https://docs.openshift.com/container-platform/4.5/operators/olm-restricted-networks.html[Using Operator Lifecycle Manager on restricted networks] for details about how to configure restricted OLM. *Tip:* Make a note of the catalog source image when you configure restricted OLM.
* An {ocp-short} cluster that is managed by the {product-title-short} hub cluster
* Access credentials to a local repository where you can store the cluster images. At least two release images must be mirrored. See https://docs.openshift.com/container-platform/4.5/installing/install_config/installing-restricted-networks-preparations.html[Creating a mirror registry for installation in a restricted network] for more information about how to create this repository.
+
*Note:* The image for the current version of the cluster that you upgrade must be available as one of the mirrored images. If an upgrade fails, the cluster reverts back to the version of the cluster at the time that the upgrade was attempted.

[#build-the-graph-data-init-container]
== Build the graph data init container

{cincinnati-short} uses graph data information to determine the available upgrades. In a connected environment, {cincinnati-short} pulls the graph data information for available upgrades directly from the https://github.com/openshift/cincinnati-graph-data[Cincinnati graph data GitHub repository]. Because you are configuring a disconnected environment, you must make the graph data available in a local repository by using an `init container`. Complete the following steps to create a graph data `init container`:

. Create a file that contains the information for your graph data init. You can find this sample https://github.com/openshift/cincinnati-operator/blob/master/dev/Dockerfile[Dockerfile] in the `cincinnati-operator` GitHub repository. The contents of the file is shown in the following sample:
+
----
FROM registry.access.redhat.com/ubi8/ubi:8.1

RUN curl -L -o cincinnati-graph-data.tar.gz https://github.com/openshift/cincinnati-graph-data/archive/master.tar.gz

CMD exec /bin/bash -c "tar xvzf cincinnati-graph-data.tar.gz -C /var/lib/cincinnati/graph-data/ --strip-components=1"  
----
+
In this example:
+
* The `FROM` value is the external registry where {cincinnati-short} finds the images.

* The `RUN` command packages the upgrade files. 

* The `CMD` command copies the package file to the local repository and extracts the files for an upgrade. Replace `var/lib/cincinnati/graph-data/` with the path to your local repository. 

. Run the following commands to build the `graph data init container`:
+
----
podman build -f ./dev/Dockerfile -t host/user/cincinnati-graph-data-container:latest
podman push host/user/cincinnati-graph-data-container:latest
----
+
Replace _.dev/Dockerfile_ with the path to the file that you created in the previous step.
+
Replace _host/user/cincinnati-graph-data-container_ with the path to your local graph data init container.
+
*Note:* You can also replace `podman` with `docker`, if you don't have `podman` installed.

[#deploy-the-operator-for-cincinnati]
== Deploy the operator for {cincinnati-short}

To deploy the operator for {cincinnati-short} in your {ocp-short} environment, complete the following steps:

. Access the {ocp-short} operator hub. 
. Deploy the operator by selecting `{cincinnati} Operator`. Update the default values, if necessary. The deployment of the operator creates a new project named `openshift-cincinnati`.
. Wait for the installation of the operator to finish. Tip: You can check the status of the installation by entering the `oc get pods` command on your {ocp-short} command line. The operator should be in the `running` state.

[#deploy-the-cincinnati-instance]
== Deploy the {cincinnati-short} instance

When you finish deploying the {cincinnati-short} instance on your hub cluster, this instance is where the images for the cluster upgrades are mirrored and made available to the disconnected managed cluster.

. Create a namespace for your {cincinnati-short} instance:
.. In the {ocp-short} hub cluster console navigation menu, select *Administration* > *Namespaces*.
.. Select *Create Namespace*.
.. Add the name of your namespace, and any other information for your namespace.
.. Select *Create* to create the namespace.
. In the _Installed Operators_ section of the {ocp-short} console, select *{cincinnati} Operator*.
. Select *Create Instance* in the menu.
. Paste text that is similar to the following manifest:
+
----
apiVersion: cincinnati.openshift.io/v1beta1
kind: Cincinnati
metadata:
  name: openshift-update-service-instance
  namespace: openshift-cincinnati
spec:
  registry: local/registry
  replicas: 1
  repository: openshift-release-dev/ocp-release
  graphDataImage: 'host/user/cincinnati-graph-data-container'
----
+
Replace the `spec: registry` value with the path to your local disconnected registry for your images that you set up in the prerequisites.
+
Replace the `spec: graphDataImage` value with the path to your graph data init container. *Tip:* This is the same value that you used when you ran the `podman push` command to push your graph data init container.
. Select *Create* to create the instance. 
. From the hub cluster CLI, enter the `oc get pods` command to view the status of the instance creation. It might take a while, but the process is complete when the result of the command shows that the instance and the operator are running.

[#deploy-a-policy-to-override-the-default-registry]
== Deploy a policy to override the default registry

{ocp-short} has a default image registry value that specifies where it finds the upgrade packages. In a disconnected environment, you can create a policy to replace that value with the path to your local image registry where you mirrored your release images. 

For these steps, the policy is named _imageContentSourcePolicy_.  Complete the following steps to create the policy:

. From the {product-title-short} console, select *Govern risk* > *Create policy*.
. Set the `YAML` switch to _On_ to view the YAML version of the policy.
. Find the _Setup_ section and locate the _Custom policy template_.
. Find the `imageContentSourcePolicy.yaml` file on the {product-title-short} hub cluster. This file was created when the restricted OLM was configured.
. Copy the contents of the `imageContentSourcePolicy.yaml` into the _Custom Resource_ section of the _Custom policy template_.
.. Replace *Unique name* with a name for your policy.
.. Replace *Managed clusters* with the name of the managed cluster that you are updating in the _Cluster binding_ field. *Tip:* You can find this name by viewing the _Cluster details_ page in the {product-title-short} console. 
. Select the box for *Enforce if supported*.
. Select *Create* to create the policy. 

[#deploy-a-policy-to-deploy-a-disconnected-catalog-source]
== Deploy a policy to deploy a disconnected catalog source

Push the _Catalogsource_ policy to the managed cluster to change the default location from a connected location to your disconnected local registry. 

. In the {product-title-short} console, select *Automate infrastructure* > *Clusters*.
. Find the managed cluster to receive the policy in the list of clusters.
. Note the value of the `name` label for the managed cluster. The label format is `name=managed-cluster-name`. This value is used when pushing the policy.
. In the {product-title-short} console menu, select *Governance and Risk* > *Create a policy*.
. Set the `YAML` switch to _On_ to view the YAML version of the policy.
. Find the _Custom Resource_ section of the custom policy template in the setup section. Add the following content to the _setup_ section of the custom policy template:
+
----
apiVersion: config.openshift.io/vi
kind: OperatorHub
metadata:
 name: cluster
spec:
 disableAllDefaultSources: true
----
+
. Add the following content into the _Custom Resource_ section:
+
----
apiVersion: operators.coreos.com/v1alpha1
kind: CatalogSource
metadata:
  name: my-operator-catalog
  namespace: openshift-marketplace
spec:
  sourceType: grpc
  image: <registry_host_name>:<port>/olm/redhat-operators:v1 
  displayName: My Operator Catalog
  publisher: grpc
----
+
Replace the value of _image:_ with the path to your local restricted catalog source image.

. In the {product-title-short} console navigation, select *Automate infrastructure* > *Clusters* to check the status of the managed cluster. When the policy is applied, the cluster status is `ready`.

[#deploy-a-policy-to-change-the-managed-cluster-parameter]
== Deploy a policy to change the managed cluster parameter

Push the _ClusterVersion_ policy to the managed cluster to change the default location where it retrieves its upgrades. 

. From the managed cluster, confirm that the _ClusterVersion_ upstream parameter is currently the default public {cincinnati-short} operand by entering the following command:
+
----
oc get clusterversion -o yaml
----
+
The returned content should look similar to the following content:
+
----
apiVersion: v1
items:
- apiVersion: config.openshift.io/v1
  kind: ClusterVersion
[..]
  spec:
    channel: stable-4.4
    upstream: https://api.openshift.com/api/upgrades_info/v1/graph
----
+
. Replace the value of _items: spec: upstream_ with the path to the local registry where your upgrade images are stored. See link:../security/create_policy.adoc#managing-security-policies[Managing security policies] for information about creating a policy. 
 
. From the hub cluster, identify the route URL to the {cincinnati-short} operand by entering the following command: `oc get routes`. *Tip:* Note this value for later steps.

. In the hub cluster {product-title-short} console menu, select *Governance and Risk* > *Create a policy*.
. Set the `YAML` switch to _On_ to view the YAML version of the policy.
. Find the _Custom Resource_ section of the custom policy template in the setup section. 
. Add the following content to the _custom policy template_ in the _setup_ section:
+
----
apiVersion: config.openshift.io/v1
  kind: ClusterVersion
  metadata:
    name: version
  spec:
    channel: stable-4.4
    clusterID: example-cluster-id
    upstream: https://example-cincinnati-policy-engine-uri/api/upgrades_info/v1/graph
----
+
Replace the value of _spec: upstream:_ with the path to your hub cluster {cincinnati-short} operand.
. In the managed cluster CLI, confirm that the upstream parameter in the `ClusterVersion` is updated with the local hub cluster {cincinnati-short} URL by entering: 
+
----
oc get clusterversion -o yaml
----
+
The results should look similar to the following content:
+
----
apiVersion: v1
items:
- apiVersion: config.openshift.io/v1
  kind: ClusterVersion
[..]
  spec:
    channel: stable-4.4
    clusterID: 46acf6fb-471a-45c8-9a59-0fac0685dec6
    upstream: https://<hub-cincinnati-url>/api/upgrades_info/v1/graph
----

[#viewing-available-upgrades]
== Viewing available upgrades

You can view a list of available upgrades for your managed cluster by completing the following steps:

. Log in to your {product-title-short} console.
. In the navigation menu, select *Automate Infrastructure* > *Clusters*.
. Select a cluster that is in the _Ready_ state.
. From the *Options* menu, select *Upgrade cluster*. 
. Verify that the optional upgrade paths are available. 
+
*Note:* No available upgrade versions are shown if the current version is not mirrored into the local image repository.  

[#upgrading-the-cluster]
== Upgrading the cluster

After configuring the disconnnected registry, {product-title-short} and {cincinnati-short} use the disconnected registry to determine if updates are available. If no available upgrades are displayed, make sure that you have the release image of the current level of the cluster and at least one later level mirrored in the local repository. If the release image for the current version of the cluster is not available, no upgrades are available. 

. In the {product-title-short} console, select *Automate infrastructure* > *Clusters*.

. Find the cluster that you want to determine if there is an available upgrade. 

. If there is an upgrade available, the *Distribution version* column for the cluster indicates that there is an upgrade available. 

. Select the _Options_ menu for the cluster, and select *Upgrade cluster*.

. Select the target version for the upgrade, and select *Upgrade*. 

The managed cluster is updated to the selected version. 