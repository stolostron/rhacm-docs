[#submariner]
= Submariner

The `submariner-addon` component is a *tech preview* feature. 

Submariner is an open source tool that can be used with {product-title} to provide direct networking between two or more Kubernetes clusters in your environment, either on-premises or in the cloud. For more information about Submariner, see link:https://submariner.io/[Submariner].

You can enable Submariner on the {ocp-short} clusters that are hosted in the following environments:

* Amazon Web Services
* Google Cloud Platform
* Microsoft Azure
* IBM Cloud
* VMware vSphere
* Bare metal
* Red Hat OpenShift Dedicated

{product-title} provides a Submariner component that you can deploy in your environment by using your hub cluster. 

[#submariner-prereq]
== Prerequisites

Ensure that you have the following prerequisites before using Submariner:

* A {product-title-short} hub cluster that is running on {ocp} version 4.4, or later, with Kubernetes version 1.17, or later.
* A credential for accessing the hub cluster with `cluster administrator` permissions.
* Two or more {ocp-short} managed clusters that are running on {ocp-short} version 4.4, or later, with Kubernetes version 1.17, or later, and are managed by the {product-title-short} hub cluster.
* Pod and Service Classless Inter-Domain Routing (CIDR) between the clusters that do not overlap.
* IP connectivity must be configured between the Gateway nodes. When connecting two clusters, at least one of the clusters must have a publicly routable IP address designated to the Gateway node.
* Firewall configuration across all nodes in each of the managed clusters must allow 4800/UDP in both directions. *Note:* This is configured automatically when your clusters are deployed in an Amazon Web Services environment, but must be configured manually for clusters on other environments and for the firewalls that protect private clouds like bare metal and VMware vSphere. 
* Firewall configuration on the Gateway nodes allows ingress 8080/TCP so the other nodes in the cluster can access it. 
* Firewall configuration open for UDP/4500, UDP/500, and any other ports that are used for IPSec traffic on the gateway nodes.

See link:https://submariner.io/getting-started/#prerequisites[Submariner prerequisites] for more detailed information about the prerequisites.

[#preparing-the-hosts-to-deploy-submariner]
== Preparing the hosts to deploy Submariner

Before deploying Submariner with {product-title}, you must prepare the clusters on the hosting environment for the connection. The requirements vary by the hosting environment, so follow the instructions for your hosting environment.

[#preparing-aws]
=== Preparing Amazon Web Services to deploy Submariner

There are 2 ways that you can configure the {ocp-short} cluster that is hosted on Amazon Web Services to integrate with a Submariner deployment. Select one of these options to prepare for the 

* Method 1 
+
You can use the `SubmarinerConfig` API to build the cluster environment. With this method, the `submariner-addon` configures the environment, so you use your configurations and cloud provider credentials in your `SubmarinerConfig` definition. *Note:* This method is only supported when the cluster is on Amazon Web Services, and not on other environments. 
+
. Create a yaml file that contains the following content:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
    name: <cloud-provider-credential-secret-name>
    namespace: <managed-cluster-namespace>
type: Opaque
data:
    aws_access_key_id: <aws-access-key-id>
    aws_secret_access_key: <aws-secret-access-key>
----
+
The format of `name` is the same as the credential secret name that you used to provision the cluster with {product-title-short}.
+
If you have already configured your Submariner cluster environment manually, include the configurations in the your `SubmarinerConfig` addition. In this example, the `IPSecIKEPort` is set to 501, and the `IPSecNATTPort` is set to 4501.
+
[source,yaml]
----
apiVersion: submarineraddon.open-cluster-management.io/v1alpha1
kind: SubmarinerConfig
metadata:
    name: <config-name>
    namespace: <managed-cluster-namespace>
spec:
    IPSecIKEPort: 501
    IPSecNATTPort: 4501
    ...
----

* Method 2    
+
You can use the script file, `prep_for_subm.sh`, that is provided on the Submariner web site to update your {ocp-short} installer-provisioned Amazon Web Services infrastructure for Submariner deployments.
See link:https://submariner.io/getting-started/quickstart/openshift/aws/#prepare-aws-clusters-for-submariner[Prepare AWS Clusters for Submariner] for the script and instructions for running it.

[#preparing-gcp]
=== Preparing Google Cloud Platform to deploy Submariner

To prepare the clusters on your Google Cloud Platform for deploying the Submariner component, complete the following steps:

. Create the inbound and outbound firewall rules on your Google Cloud Platform to open the IPsec IKE (by default 500/UDP) and NAT traversal ports (by default 4500/UDP) to enable Submariner communication.
+
----
$ gcloud compute firewall-rules create <name> --network=<network-name> --allow=udp:<ipsec-port> --direction=IN
$ gcloud compute firewall-rules create <rule-name> --network=<network-name> --allow=udp:<ipsec-port>  --direction=OUT
----
Replace _rule-name_ with your rule name.
Replace _network-name_ with your Google Cloud Platform cluster network name.
Replace_ipsec-port_ with your IPsec port.

. Create the inbound and outbound firewall rules on your Google Cloud Platform to open the 4800/UDP port to encapsulate Pod traffic from the worker and master nodes to the Submariner Gateway nodes.
+
----
$ gcloud compute firewall-rules create <name> --network=<network-name> --allow=udp:4800 --direction=IN
$ gcloud compute firewall-rules create <name> --network=<network-name> --allow=udp:4800 --direction=OUT
----
Replace _name_ with your rule name.
Replace _network-name_ with your Google Cloud Platform cluster network name.

. Create the inbound and outbound firewall rules on your Google Cloud Platform to open the 8080/TCP port to export metrics service from the Submariner Gateway nodes.
+
----
$ gcloud compute firewall-rules create <name> --network=<network-name> --allow=tcp:8080 --direction=IN
$ gcloud compute firewall-rules create <name> --network=<network-name> --allow=tcp:8080 --direction=OUT
----
Replace _name_ with your rule name.
Replace _network-name_ with your GCP cluster network name.

[#preparing-azure]
=== Preparing Microsoft Azure to deploy Submariner

To prepare the clusters on your Microsoft Azure for deploying the Submariner component, complete the following steps:

. Create the inbound and outbound firewall rules on your Microsoft Azure environment to open the IP security IKE (by default 500/UDP) and NAT traversal ports (by default 4500/UDP) to enable Submariner communication.
+
----
# create inbound nat rule
$ az network lb inbound-nat-rule create --lb-name <lb-name> \
--resource-group <res-group> \
--name <name> \
--protocol Udp --frontend-port <ipsec-port> \
--backend-port <ipsec-port> \
--frontend-ip-name <frontend-ip-name>

# add your vm network interface to the created inbound nat rule
$ az network nic ip-config inbound-nat-rule add \
--lb-name <lb-name> --resource-group <res-group> \
--inbound-nat-rule <nat-name> \
--nic-name <nic-name> --ip-config-name <pipConfig>
----
Replace _lb-name_ with your load balancer name.
Replace _res-group_ with your resource group name.
Replace _nat-name_ with your load balancing inbound NAT rule name.
Replace _ipsec-port_with your IPsec port.
Replace _pipConfig_ with your cluster frontend IP configuration name.
Replace _nic-name_ with your network interface card (NIC) name.

. Create one load balancing inbound NAT rules to forward Submariner gateway metrics service request.
+
----
# create inbound nat rule
$ az network lb inbound-nat-rule create --lb-name <lb-name> \
--resource-group <res-group> \
--name <name> \
--protocol Tcp --frontend-port 8080 --backend-port 8080 \
--frontend-ip-name <frontend-ip-name>

# add your vm network interface to the created inbound nat rule
$ az network nic ip-config inbound-nat-rule add \
--lb-name <lb-name> --resource-group <res-group> \
--inbound-nat-rule <nat-name> \
--nic-name <nic-name> --ip-config-name <pipConfig>
----
Replace _lb-name_ with your load balancer name.
Replace _res-group_ with your resource group name.
Replace _nat-name_ with your load balancing inbound NAT rule name.
Replace _pipConfig_ with your cluster frontend IP configuration name.
Replace _nic-name_ with your network interface card (NIC) name.

. Create NSG (network security groups) security rules on your Azure to open IPsec IKE (by default 500/UDP) and NAT traversal ports (by default 4500/UDP) for Submariner.
+
----
$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Inbound --access Allow \
--protocol Udp --destination-port-ranges <ipsec-port>

$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Outbound --access Allow \
--protocol Udp --destination-port-ranges <ipsec-port>
Replace _res-group_ with your resource group name.
Replace _nsg-name_ with your NSG name.
Replace _priority_ with your rule priority.
Replace _name_ with your rule name.
Replace _ipsec-port_ with your IPsec port.
----

. Create the NSG rules to open 4800/UDP port to encapsulate Pod traffic from the worker and master nodes to the Submariner Gateway nodes.
+
----
$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Inbound --access Allow \
--protocol Udp --destination-port-ranges 4800 \

$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Outbound --access Allow \
--protocol Udp --destination-port-ranges 4800
----
Replace _res-group_ with your resource group name.
Replace _nsg-name_ with your NSG name.
Replace _priority_ with your rule priority.
Replace _name_ with your rule name.

. Create the NSG rules to open 8080/TCP port to export metrics service from the Submariner Gateway nodes.
+
----
$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Inbound --access Allow \
--protocol Tcp --destination-port-ranges 8080 \

$ az network nsg rule create --resource-group <res-group> \
--nsg-name <nsg-name> --priority <priority> \
--name <name> --direction Outbound --access Allow \
--protocol Udp --destination-port-ranges 8080
----
Replace _res-group_ with your resource group name.
Replace _nsg-name_ with your NSG name.
Replace _priority_ with your rule priority.
Replace _name_ with your rule name.

[#preparing-ibm]
=== Preparing IBM Cloud to deploy Submariner

There are 2 kinds of Red Hat OpenShift Kubernetes Service (ROKS) on IBM Cloud: the classic cluster and the second generation of compute infrastructure in a virtual private cloud (VPC). Submariner cannot run on the classic ROKS cluster since cannot configure the IPSec ports for the classic cluster.

To configure the ROKS clusters on a VPC to use Submariner, complete the steps in the following links:

. Before creating a cluster, specify subnets for pods and services, which avoids overlapping CIDRs with other clusters. Make sure there are no overlapping pods and services CIDRs between clusters if you are using an existing cluster.See link:https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-subnets#vpc_basics[VPC Subnets] for the procedure. 

. Attach a public gateway to subnets used in the cluster. See link:https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-subnets#vpc_basics_pgw[Public Gateway] for the procedure. 

. Create inbound rules for the default security group of the cluster by completing the steps in link:https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-network-policy#security_groups_ui[Security Group]. Ensure that the firewall allows inbound and outbound traffic on UDP/4500 and UDP/500 ports for Gateway nodes, and allows inbound and outbound UDP/4800 for all the other nodes.

. Label a node that has the public gateway as `submariner.io/gateway=true` in the cluster.

. Refer to link:https://submariner.io/operations/deployment/calico/[Calico] to configure Calico CNI by creating IPPools in the cluster.

[#preparing-osd]
=== Preparing Red Hat OpenShift Dedicated to deploy Submariner

Red Hat OpenShift Dedicated supports clusters that were provisioned by AWS and Google Cloud Platform.

[#preparing-osd-aws]
==== Preparing Red Hat OpenShift Dedicated to deploy Submariner on AWS

To configure the AWS clusters on Red Hat OpenShift Dedicated, complete the following steps:

. Submit a link:https://issues.redhat.com/secure/CreateIssue!default.jspa[support ticket] to the Red Hat OpenShift Hosted SRE Support team to grant `cluster-admin` group access to the Red Hat OpenShift Dedicated cluster. The default access of `dedicated-admin` does not have the permission that is required the create a `MachineSet`.

. After the group is created, add the user name to the `cluster-admin` group that you created by completing the steps in link:https://docs.openshift.com/dedicated/4/administering_a_cluster/cluster-admin-role.html[Granting the cluster-admin role to users] in the Red Hat OpenShift Dedicated documentation.

. Complete the prerequisites that are listed in the xref:/submariner.adoc#preparing-aws[Preparing Amazon Web Services to deploy Submariner].

. Configure the credentials of the user `osdCcsAdmin`, so you can use that as a service account.  

[#preparing-osd-gcp]
==== Preparing Red Hat OpenShift Dedicated to deploy Submariner on Google Cloud Platform

To configure the Google Cloud Platform clusters on Red Hat OpenShift Dedicated, complete the following steps:

. Complete the prerequisites in xref:/submariner.adoc#preparing-gcp[Preparing Google Cloud Platform to deploy Submariner].

. Configure a service account named `osd-ccs-admin` that you can use to manage the deployment.

[#preparing-vm-bare]
=== Preparing to deploy Submariner on VMware vSphere or bare metal

To prepare the VMware vSphere and bare metal clusters for deploying Submariner, complete the following steps:

. Configure a publicly routable IP address that is designated to the gateway node on at least one of the clusters. 

. Ensure that ports for IP security are open. The default ports are 4500/UDP and 500/UDP. If the default ports are blocked by a firewall, configure a pair of custom ports that are available, like 4501/UDP and 501/UDP.

[#deploying-submariner]
= Deploying Submariner

Complete the following steps to deploy Submariner:

. Log on to your hub cluster with cluster administrator permissions. 

. Create a `ManagedClusterSet` on the hub cluster by using the instructions provided in xref:../manage_cluster/custom_resource.adoc#managedclustersets[ManagedClusterSets]. The `submariner-addon` creates a namespace called `submariner-clusterset-<clusterset-name>-broker` and deploys the Submariner Broker to it. The name of the ManagedClusterSet replaces <clusterset-name> in the namespace name. Your entry for the `ManagedClusterSet` should resemble the following content:
+ 
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: ManagedClusterSet
metadata:
  name: <ManagedClusterSet-name>
----
Replace _ManagedClusterSet-name_ with a name for the `ManagedClusterSet` that you are creating.

. Enable Submariner to provide communication between managed clusters by entering the following command:
+
---- 
oc label managedclusters <managedcluster-name> "cluster.open-cluster-management.io/submariner-agent=true" --overwrite
----
+
Replace _managedcluster-name_ with the name of the managed cluster that you would like to use with Submariner. 

. Add the managed clusters to the `ManagedClusterSet` by entering the following command:
+
----
oc label managedclusters <managedcluster-name> "cluster.open-cluster-management.io/clusterset=<ManagedClusterSet-name>" --overwrite
----
Replace _managedcluster-name_ with the name of the managed cluster that you want to add to the `ManagedClusterSet`.
Replace _ManagedClusterSet-name_ with the name of the `ManagedClusterSet` to which you want to add the managed cluster. 

. Repeat those steps for all of the managed clusters that you want to add to the `ManagedClusterSet`.

[#enable-service-discovery-submariner]
= Enabling service discovery for Submariner

After Submariner is deployed into the same environment as your managed clusters, the routes are configured for secure IP routing between the Pod and services across the clusters in the `ManagedClusterSet`. To make a service from a cluster visible and discoverable to other clusters in the `ManagedClusterSet`, you must create a `ServiceExport` object. After a service is exported with a `ServiceExport` object, you can access the the service by the following format: `<service>.<namespace>.svc.clusterset.local`. If multiple clusters export a service with the same name, and from the same namespace, they are recognized by other clusters as a single logical service. 

This example uses the `nginx` service in the `default` namespace, but you can discover any Kubernetes `ClusterIP` service or headless service. 

. Apply an instance of the `nginx` service on a managed cluster that is in the `ManagedClusterSet` by entering the following commands:
+
----
oc -n default create deployment nginx --image=nginxinc/nginx-unprivileged:stable-alpine
oc -n default expose deployment nginx --port=8080
----

. Export the service by creating a `ServiceExport` entry that resembles the following content in the yaml file:
+
[source,yaml]
----
apiVersion: lighthouse.submariner.io/v2alpha1
kind: ServiceExport
metadata:
  name: <service-name>
  namespace: <service-namespace>
----
Replace _service-name_ with the name of the service that you are exporting. In this example, it is `nginx`. 
Replace _service-namespace_ with the name of the namespace where the service is located. In this example, it is `default`.

. Run the following command from a different managed cluster to confirm that it can access the `nginx` service:
+
----
oc -n default run --generator=run-pod/v1 tmp-shell --rm -i --tty --image quay.io/submariner/nettest -- /bin/bash curl nginx.default.svc.clusterset.local:8080
----
