[#policy-generator]
= Policy generator

The policy generator is a part of the {product-title} application lifecycle subscription GitOps workflow that generates {product-title-short} policies using Kustomize. The policy generator builds {product-title-short} policies from Kubernetes manifest YAML files, which are provided through a `PolicyGenerator` manifest YAML file that is used to configure it. The policy generator is implemented as a Kustomize generator plugin. For more information on Kustomize, see the link:https://kustomize.io/[Kustomize documentation]. 

The policy generator version bundled in this version of {product-title-short} is v1.9.0.

[#policy-generator-capabilities]
== Policy generator capabilities

The policy generator and its integration with the {product-title-short} application lifecycle link:../applications/subscription_sample.adoc#applying-kustomize[subscription] GitOps workflow simplifies the distribution of Kubernetes resource objects to managed OpenShift clusters, and Kubernetes clusters through {product-title-short} policies. In particular, use the policy generator to complete the following actions:

- Convert any Kubernetes manifest files to {product-title-short} link:../governance/config_policy_ctrl.adoc#kubernetes-configuration-policy-controller[configuration policies], including manifests created from a Kustomize directory.
- Patch the input Kubernetes manifests before they are inserted into a generated {product-title-short} policy.
- Generate additional configuration policies to be able to report on link:https://open-policy-agent.github.io/gatekeeper/website/docs/[Gatekeeper] and policy violations through {product-title}.
- Generate policy sets on the hub cluster. See xref:../governance/policy_set_ctrl.adoc#policy-set-controller[Policy set controller] for more details.

View the following topics to for more information:

* <<policy-generator-configuration,Policy generator configuration structure>>
* <<policy-gen-install-operator,Generating a policy to install an Operator>>
** <<policy-install-ocp-gitops,A policy to install OpenShift GitOps>>
** <<policy-gen-install-compliance-operator,A policy to install the Compliance Operator>>
* <<policy-gen-install-on-openshift-gitops,Install the policy generator on OpenShift GitOps (ArgoCD)>>
* <<policy-gen-yaml-table,Policy generator configuration reference table>>

[#policy-generator-configuration]
== Policy generator configuration structure

The policy generator is a Kustomize generator plugin that is configured with a manifest of the `PolicyGenerator` kind and `policy.open-cluster-management.io/v1` API version. 

To use the plugin, start by adding a `generators` section in a link:https://kubectl.docs.kubernetes.io/references/kustomize/kustomization/[`kustomization.yaml`] file. View the following example:

[source,yaml]
----
generators:
  - policy-generator-config.yaml
----

The `policy-generator-config.yaml` file referenced in the previous example is a YAML file with the instructions of the policies to generate. A simple policy generator configuration file might resemble the following example:

[source,yaml]
----
apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: config-data-policies
policyDefaults:
  namespace: policies
  policySets: []
policies:
  - name: config-data
    manifests:
      - path: configmap.yaml
----

The `configmap.yaml` represents a Kubernetes manifest YAML file to be included in the policy. Alternatively, you can set the path to a Kustomize directory, or a directory with multiple Kubernetes manifest YAML files. View the following example:

[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
  namespace: default
data:
  key1: value1
  key2: value2
----

The generated `Policy`, along with the generated `PlacementRule` and `PlacementBinding` might resemble the following example:

[source,yaml]
----
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: placement-config-data
  namespace: policies
spec:
  clusterConditions:
  - status: "True"
    type: ManagedClusterConditionAvailable
  clusterSelector:
    matchExpressions: []
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: binding-config-data
  namespace: policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: placement-config-data
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: config-data
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  annotations:
    policy.open-cluster-management.io/categories: CM Configuration Management
    policy.open-cluster-management.io/controls: CM-2 Baseline Configuration
    policy.open-cluster-management.io/standards: NIST SP 800-53
  name: config-data
  namespace: policies
spec:
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: config-data
      spec:
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: v1
            data:
              key1: value1
              key2: value2
            kind: ConfigMap
            metadata:
              name: my-config
              namespace: default
        remediationAction: inform
        severity: low
----

See the link:https://github.com/open-cluster-management-io/policy-generator-plugin[`policy-generator-plugin`] repository for more details.

[#policy-gen-install-operator]
== Generating a policy to install an Operator

A common use of {product-title-short} policies is to link:hhttps://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/operators/administrator-tasks#olm-installing-operator-from-operatorhub-using-cli_olm-adding-operators-to-a-cluster[install an Operator] on one or more managed OpenShift clusters. View the following examples of the different installation modes and the required resources. 

[#policy-install-ocp-gitops]
=== A policy to install OpenShift GitOps

This example shows how to generate a policy that installs OpenShift GitOps using the policy generator. The OpenShift GitOps operator offers the link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/operators/administrator-tasks#olm-installing-operators-from-operatorhub_olm-adding-operators-to-a-cluster[_all namespaces_ installation mode]. First, a `Subscription` manifest file called `openshift-gitops-subscription.yaml` needs to be created like the following example.

[source,yaml]
----
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: openshift-gitops-operator
  namespace: openshift-operators
spec:
  channel: stable
  name: openshift-gitops-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
----

To pin to a specific version of the operator, you can add the following parameter and value: `spec.startingCSV: openshift-gitops-operator.v<version>`. Replace `<version>` with your preferred version.

Next, a policy generator configuration file called `policy-generator-config.yaml` is required. The following example shows a single policy that installs OpenShift GitOps on all OpenShift managed clusters:

[source,yaml]
----
apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: install-openshift-gitops
policyDefaults:
  namespace: policies
  placement:
    clusterSelectors:
      vendor: "OpenShift"
  remediationAction: enforce
policies:
  - name: install-openshift-gitops
    manifests:
      - path: openshift-gitops-subscription.yaml
----

The last file that is required is the `kustomization.yaml` file. The `kustomization.yaml` file requires the following configuration:

[source,yaml]
----
generators:
  - policy-generator-config.yaml
----

The generated policy might resemble the following file:

[source,yaml]
----
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: placement-install-openshift-gitops
  namespace: policies
spec:
  clusterConditions:
    - status: "True"
      type: ManagedClusterConditionAvailable
  clusterSelector:
    matchExpressions:
      - key: vendor
        operator: In
        values:
          - OpenShift
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: binding-install-openshift-gitops
  namespace: policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: placement-install-openshift-gitops
subjects:
  - apiGroup: policy.open-cluster-management.io
    kind: Policy
    name: install-openshift-gitops
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  annotations:
    policy.open-cluster-management.io/categories: CM Configuration Management
    policy.open-cluster-management.io/controls: CM-2 Baseline Configuration
    policy.open-cluster-management.io/standards: NIST SP 800-53
  name: install-openshift-gitops
  namespace: policies
spec:
  disabled: false
  policy-templates:
    - objectDefinition:
        apiVersion: policy.open-cluster-management.io/v1
        kind: ConfigurationPolicy
        metadata:
          name: install-openshift-gitops
        spec:
          object-templates:
            - complianceType: musthave
              objectDefinition:
                apiVersion: operators.coreos.com/v1alpha1
                kind: Subscription
                metadata:
                  name: openshift-gitops-operator
                  namespace: openshift-operators
                spec:
                  channel: stable
                  name: openshift-gitops-operator
                  source: redhat-operators
                  sourceNamespace: openshift-marketplace
          remediationAction: enforce
          severity: low
----

All policies where the input is from the {ocp-short} documentation and are generated by the policy generator are fully supported. View the following examples of YAML input that is supported in the {ocp-short} documentation:

* link:https://docs.openshift.com/container-platform/4.10/post_installation_configuration/cluster-tasks.html[Post-installation cluster tasks]
* link:https://docs.openshift.com/container-platform/4.10/security/audit-log-policy-config.html[Configuring the audit log policy]
* link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/logging/cluster-logging-external#cluster-logging-collector-log-forwarding-about_cluster-logging-external[About forwarding logs to third-party systems]

See link:https://docs.openshift.com/container-platform/4.11/cicd/gitops/understanding-openshift-gitops.html[Understanding OpenShift GitOps] and the link:https://cloud.redhat.com/learn/topics/operators[Operator] documentation for more details.

[#policy-gen-install-compliance-operator]
=== A policy to install the Compliance Operator

For an operator that uses the link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.10/html/operators/administrator-tasks#olm-installing-operators-from-operatorhub_olm-adding-operators-to-a-cluster[_namespaced_ installation mode], such as the Compliance Operator, an `OperatorGroup` manifest is also required. This example shows a generated policy to install the Compliance Operator.

First, a YAML file with a `Namespace`, a `Subscription`, and an `OperatorGroup` manifest called `compliance-operator.yaml` must be created. The following example installs these manifests in the `compliance-operator` namespace:

[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-compliance
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: compliance-operator
  namespace: openshift-compliance
spec:
  channel: release-0.1
  name: compliance-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: compliance-operator
  namespace: openshift-compliance
spec:
  targetNamespaces:
    - compliance-operator
----

Next, a policy generator configuration file called `policy-generator-config.yaml` is required. The following example shows a single policy that installs the Compliance Operator on all OpenShift managed clusters:

[source,yaml]
----
apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: install-compliance-operator
policyDefaults:
  namespace: policies
  placement:
    clusterSelectors:
      vendor: "OpenShift"
  remediationAction: enforce
policies:
  - name: install-compliance-operator
    manifests:
      - path: compliance-operator.yaml
----

The last file that is required is the `kustomization.yaml` file. The following configuration is required in the `kustomization.yaml` file:

[source,yaml]
----
generators:
  - policy-generator-config.yaml
----

As a result, the generated policy resembles the following file:

[source,yaml]
----
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: placement-install-compliance-operator
  namespace: policies
spec:
  clusterConditions:
    - status: "True"
      type: ManagedClusterConditionAvailable
  clusterSelector:
    matchExpressions:
      - key: vendor
        operator: In
        values:
          - OpenShift
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: binding-install-compliance-operator
  namespace: policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: placement-install-compliance-operator
subjects:
  - apiGroup: policy.open-cluster-management.io
    kind: Policy
    name: install-compliance-operator
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  annotations:
    policy.open-cluster-management.io/categories: CM Configuration Management
    policy.open-cluster-management.io/controls: CM-2 Baseline Configuration
    policy.open-cluster-management.io/standards: NIST SP 800-53
  name: install-compliance-operator
  namespace: policies
spec:
  disabled: false
  policy-templates:
    - objectDefinition:
        apiVersion: policy.open-cluster-management.io/v1
        kind: ConfigurationPolicy
        metadata:
          name: install-compliance-operator
        spec:
          object-templates:
            - complianceType: musthave
              objectDefinition:
                apiVersion: v1
                kind: Namespace
                metadata:
                  name: openshift-compliance
            - complianceType: musthave
              objectDefinition:
                apiVersion: operators.coreos.com/v1alpha1
                kind: Subscription
                metadata:
                  name: compliance-operator
                  namespace: openshift-compliance
                spec:
                  channel: release-0.1
                  name: compliance-operator
                  source: redhat-operators
                  sourceNamespace: openshift-marketplace
            - complianceType: musthave
              objectDefinition:
                apiVersion: operators.coreos.com/v1
                kind: OperatorGroup
                metadata:
                  name: compliance-operator
                  namespace: openshift-compliance
                spec:
                  targetNamespaces:
                    - compliance-operator
          remediationAction: enforce
          severity: low
----

See the link:https://docs.openshift.com/container-platform/4.11/security/compliance_operator/compliance-operator-understanding.html[Compliance Operator documentation] for more details. 

[#policy-gen-install-on-openshift-gitops]
== Install the policy generator on OpenShift GitOps (ArgoCD)

OpenShift GitOps, based on link:https://argoproj.github.io/argo-cd/[ArgoCD], can also be used to generate policies using the policy generator through GitOps. Since the policy generator does not come preinstalled in the OpenShift GitOps container image, some customization must take place. In order to follow along, it is expected that you have the link:https://docs.openshift.com/container-platform/4.10/cicd/gitops/installing-openshift-gitops.html[OpenShift GitOps Operator] installed on the {product-title-short} hub cluster and be sure to log into the hub cluster.

In order for OpenShift GitOps to have access to the policy generator when you run Kustomize, an Init Container is required to copy the policy generator binary from the {product-title-short} Application Subscription container image to the OpenShift GitOps container, that runs Kustomize. For more details, see link:https://docs.openshift.com/container-platform/4.10/nodes/containers/nodes-containers-init.html[Using Init Containers to perform tasks before a pod is deployed]. Additionally, OpenShift GitOps must be configured to provide the `--enable-alpha-plugins` flag when you run Kustomize. Start editing the OpenShift GitOps `argocd` object with the following command:

[source,bash]
----
oc -n openshift-gitops edit argocd openshift-gitops
----


Then modify the OpenShift GitOps `argocd` object to contain the following additional YAML content. When a new major version of {product-title-short} is released and you want to update the policy generator to a newer version, you need to update the `registry.redhat.io/rhacm2/multicluster-operators-subscription-rhel8` image used by the Init Container to a newer tag. View the following example and replace `<version>` with {product-version} or your desired {product-title-short} version:

[source,yaml]
----
apiVersion: argoproj.io/v1alpha1
kind: ArgoCD
metadata:
  name: openshift-gitops
  namespace: openshift-gitops
spec:
  kustomizeBuildOptions: --enable-alpha-plugins
  repo:
    env:
    - name: KUSTOMIZE_PLUGIN_HOME
      value: /etc/kustomize/plugin
    initContainers:
    - args:
      - -c
      - cp /etc/kustomize/plugin/policy.open-cluster-management.io/v1/policygenerator/PolicyGenerator
        /policy-generator/PolicyGenerator
      command:
      - /bin/bash
      image: registry.redhat.io/rhacm2/multicluster-operators-subscription-rhel8:v<version>
      name: policy-generator-install
      volumeMounts:
      - mountPath: /policy-generator
        name: policy-generator
    volumeMounts:
    - mountPath: /etc/kustomize/plugin/policy.open-cluster-management.io/v1/policygenerator
      name: policy-generator
    volumes:
    - emptyDir: {}
      name: policy-generator
----

Now that OpenShift GitOps can use the policy generator, OpenShift GitOps must be granted access to create policies on the {product-title-short} hub cluster. Create the following `ClusterRole` resource called `openshift-gitops-policy-admin`, with access to create, read, update, and delete policies and placements. Your `ClusterRole` might resemble the following example:

[source,yaml]
----
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: openshift-gitops-policy-admin
rules:
  - verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
    apiGroups:
      - policy.open-cluster-management.io
    resources:
      - policies
      - placementbindings
  - verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
    apiGroups:
      - apps.open-cluster-management.io
    resources:
      - placementrules
  - verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
    apiGroups:
      - cluster.open-cluster-management.io
    resources:
      - placements
      - placements/status
      - placementdecisions
      - placementdecisions/status
----

Additionally, create a `ClusterRoleBinding` object to grant the OpenShift GitOps service account access to the `openshift-gitops-policy-admin` `ClusterRole`. Your `ClusterRoleBinding` might resemble the following resource:

[source,yaml]
----
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: openshift-gitops-policy-admin
subjects:
  - kind: ServiceAccount
    name: openshift-gitops-argocd-application-controller
    namespace: openshift-gitops
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: openshift-gitops-policy-admin
----

[#policy-gen-yaml-table]
== Policy generator configuration reference table

Note that all the fields in the `policyDefaults` section except for `namespace` can be overridden per policy.

.Parameter table
|===
| Field | Optional or required | Description

| `apiVersion`
| Required
| Set the value to `policy.open-cluster-management.io/v1`.

| `kind`
| Required
| Set the value to `PolicyGenerator` to indicate the type of policy.

| `metadata.name`
| Required
| The name for identifying the policy resource.

| `placementBindingDefaults.name`
| Optional
| If multiple policies use the same placement, this name is used to generate a unique name for the resulting `PlacementBinding`, binding the placement with the array of policies that reference it.

|*`policyDefaults`*
| Required
| Any default value listed here is overridden by an entry in the policies array except for `namespace`.

| `policyDefaults.namespace`
| Required
| The namespace of all the policies.

| `policyDefaults.complianceType`
| Optional
| Determines the policy controller behavior when comparing the manifest to objects on the cluster. The values that you can use are `musthave`,  `mustonlyhave`, or `mustnothave`. The default value is `musthave`.

| `policyDefaults.metadataComplianceType`
| Optional
| Overrides `complianceType` when comparing the manifest metadata section to objects on the cluster. The values that you can use are `musthave`, and `mustonlyhave`. The default value is empty (`{}`) to avoid overriding the `complianceType` for metadata.

| `policyDefaults.categories`
| Optional
| Array of categories to be used in the `policy.open-cluster-management.io/categories` annotation. The default value is `CM Configuration Management`.

| `policyDefaults.controls`
| Optional
| Array of controls to be used in the `policy.open-cluster-management.io/controls` annotation. The default value is `CM-2 Baseline Configuration`.

| `policyDefaults.standards`
| Optional
| An array of standards to be used in the `policy.open-cluster-management.io/standards` annotation. The default value is `NIST SP 800-53`.

| `policyDefaults.policyAnnotations`
| Optional
| Annotations that the policy includes in the `metadata.annotations` section. It is applied for all policies unless specified in the policy. The default value is empty (`{}`).

| `policyDefaults.configurationPolicyAnnotations`
| Optional
| Key-value pairs of annotations to set on generated configuration policies. For example, you can disable policy templates by defining the following parameter: `{"policy.open-cluster-management.io/disable-templates": "true"}`. The default value is empty (`{}`).

| `policyDefaults.severity`
| Optional
| The severity of the policy violation. The default value is `low`.

| `policyDefaults.disabled`
| Optional
| Whether the policy is disabled, meaning it is not propagated and no status as a result. The default value is `false` to enable the policy.

| `policyDefaults.remediationAction`
| Optional
| The remediation mechanism of your policy. The parameter values are `enforce` and `inform`. The default value is `inform`.

| `policyDefaults.namespaceSelector`
| Required for namespaced objects that do not have a namespace specified
| Determines namespaces in the managed cluster that the object is applied to. The `include` and `exclude` parameters accept file path expressions to include and exclude namespaces by name. The `matchExpressions` and `matchLabels` parameters specify namespaces to include by label. See the https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/[Kubernetes labels and selectors] documentation. The resulting list is compiled by using the intersection of results from all parameters.

| `policyDefaults.evaluationInterval`
| Optional
| Use the parameters `compliant` and `noncompliant` to specify the frequency for a policy to be evaluated when in a particular compliance state. When managed clusters have low CPU resources, the evaluation interval can be increased to reduce CPU usage on the Kubernetes API. These are in the format of durations. For example, `"1h25m3s"` represents 1 hour, 25 minutes, and 3 seconds. These can also be set to "never" to avoid evaluating the policy after it has become a particular compliance state.

| `policyDefaults.consolidateManifests`
| Optional
| This determines if a single configuration policy is generated for all the manifests being wrapped in the policy. If set to `false`, a configuration policy per manifest is generated. The default value is `true`.

| `policyDefaults.informGatekeeperPolicies`
| Optional
| When the policy references a violated gatekeeper policy manifest, this determines if an additional configuration policy is generated in order to receive policy violations in {product-title-short}. The default value is `true`.

| `policyDefaults.policySets`
| Optional
| Array of policy sets that the policy joins. Policy set details can be defined in the `policySets` section. When a policy is part of a policy set, a placement binding is not generated for the policy since one is generated for the set. Set `policies[].generatePlacementWhenInSet` or `policyDefaults.generatePlacementWhenInSet` to override `policyDefaults.policySets`.

| `policyDefaults.generatePlacementWhenInSet`
| Optional
| When a policy is part of a policy set, by default, the generator does not generate the placement for this policy since a placement is generated for the policy set. Set `generatePlacementWhenInSet` to `true` to deploy the policy with both policy placement and policy set placement. The default value is `false`.

| *`policyDefaults.placement`*
| Optional
| The placement configuration for the policies. This defaults to a placement configuration that matches all clusters.

| `policyDefaults.placement.name`
| Optional
| Specifying a name to consolidate placement rules that contain the same cluster selectors.

| `policyDefaults.placement.placementName`
| Optional
| Define this parameter to use a placement that already exists on the cluster. A `Placement` is not created, but a `PlacementBinding` binds the policy to this `Placement`.

| `policyDefaults.placement.placementPath`
| Optional
| To reuse an existing placement, specify the path here relative to the `kustomization.yaml` file. If provided, this placement rule is used by all policies by default. See `clusterSelectors` to generate a new `Placement`.

| `policyDefaults.placement.clusterSelectors`
| Optional
| Specify a placement by defining a cluster selector in the following format, `key:value`. See `placementPath` to specify an existing file.

| `policyDefaults.placement.placementRuleName`
| Optional
| To use a placement rule that already exists on the cluster, specify its name here. A `PlacementRule` is not created, but a `PlacementBinding` binds the policy to this `PlacementRule`.

| `policyDefaults.placement.placementRulePath`
| Optional
| To reuse an existing placement rule, specify the path here relative to the `kustomization.yaml` file. If provided, this placement rule is used by all policies by default. See `labelSelector` to generate a new `PlacementRule`.

| `policyDefaults.placement.labelSelector`
| Optional
| Specify a placement rule by defining a cluster selector in the following format, `key:value`. See `placementRulePath` to specify an existing file.

| *`policies`*
| Required. 
| The list of policies to create along with overrides to either the default values, or the values that are set in `policyDefaults`.

| `policies[].name`
| Required
| The name of the policy to create.

| *`policies[].manifests`*
| Required
| The list of Kubernetes object manifests to include in the policy.

| `policies[].manifests[].path`
| Required
| Path to a single file, a flat directory of files, or a Kustomize directory relative to the `kustomization.yaml` file. If the directory is a Kustomize directory, the generator runs Kustomize against the directory before generating the policies.

| `policies[].manifests[].complianceType`
| Optional
| Determines the policy controller behavior when comparing the manifest to objects on the cluster. The parameter values are `musthave`, `mustonlyhave`, or `mustnothave`. The default value is `musthave` (or the value set in `policyDefaults.complianceType`).

| `policies[].manifests[].patches`
| Optional
| A Kustomize patch to apply to the manifest at the path. If there are multiple manifests, the patch requires the `apiVersion`, `kind`, `metadata.name`, and `metadata.namespace` (if applicable) fields to be set so Kustomize can identify the manifest that the patch applies to. If there is a single manifest, the `metadata.name` and `metadata.namespace` fields can be patched.

| *`policySets`*
| Optional
| The list of policy sets to create. To include a policy in a policy set, use `policyDefaults.policySets`, `policies[].policySets`,  or `policySets.policies`.

| `policySets[].name`
| Required
| The name of the policy set to create.

| `policySets[].description`
| Optional
| The description of the policy set to create.

| `policySets[].policies`
| Optional
| The list of policies to be included in the policy set. If `policyDefaults.policySets` or `policies[].policySets` is also specified, the lists are merged.

| `policySets[].placement`
| Optional
| The placement configuration for the policy set. This defaults to a placement configuration that matches all clusters. See `policyDefaults.placement` for placement documentation, however `policyDefaults.placement` settings do not apply to policy sets.
|===

Return to the xref:../governance/third_party_policy.adoc#integrate-third-party-policy-controllers[Integrate third-party policy controllers] documentation, or refer to the xref:../governance/grc_intro.adoc#governance[Governance] documentation for more topics.

//Add reference to new file at the end of this file 
