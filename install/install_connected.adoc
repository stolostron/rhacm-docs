[#installing-while-connected-online]
= Installing while connected online

Install {acm} through {olm}, which manages the installation, upgrade, and removal of the components that encompass the {acm-short} hub cluster. When you install the {acm-short} operator, you create the `MultiClusterHub` resource. The `MultiClusterHub` resource then installs the {mce} and creates the `MultiClusterEngine` resource. You must have a supported version of {ocp-short} to install {acm-short}.

*Required access:* Cluster administrator

*{ocp-short} Dedicated environment required access:* You need `cluster-admin` permissions. By default the `dedicated-admin` role does not have the required permissions to create namespaces in the {ocp-short} Dedicated environment. 

*Notes:*

- By default, the hub cluster components are installed on worker nodes of your {ocp-short} cluster without any additional configuration. You can install the hub cluster on worker nodes by using the {ocp-short} OperatorHub web console interface, or by using the {ocp-short} CLI.

- If you have configured your {ocp-short} cluster with infrastructure nodes, you can install the hub cluster on those infrastructure nodes by using the {ocp-short} CLI with additional resource parameters. See the _Installing the {acm-short} hub cluster on infrastructure node_ section for more details.

- If you plan to import Kubernetes clusters that are not {ocp-short} or {acm-short} clusters, you need to configure an image pull secret. 

For information on how to configure advanced configurations, see options in the xref:../install/adv_config_install.adoc#advanced-config-hub[MultiClusterHub advanced configuration] section of the documentation. 

* <<connect-prerequisites,Prerequisites>>
* <<confirm-ocp-installation,Confirm your {ocp-short} installation>>
* <<installing-from-the-operatorhub,Installing from the OperatorHub web console interface>>
* <<installing-from-the-cli,Installing from the {ocp-short} CLI>>
* <<installing-on-infra-node,Installing the {acm-short} hub cluster on infrastructure nodes>>

[#connect-prerequisites]
== Prerequisites

Before you install {acm-short}, see the following requirements:

* Your {ocp} cluster must have access to the {acm-short} operator in the OperatorHub catalog from the {ocp-short} console. 

* You need access to the link:https://catalog.redhat.com/software/containers/search?p=1&application_categories_list=Container%20Platform%20%2F%20Management[catalog.redhat.com].

* You need a supported {ocp-short} and the {ocp-short} CLI. See link:https://docs.redhat.com/en/documentation/openshift_container_platform_installation/4.15[{ocp-short} installing].

* Your {ocp-short} command line interface (CLI) must be configured to run `oc` commands. See link:https://docs.redhat.com/documentation/en-us/openshift_container_platform/4.15/html/cli_tools/openshift-cli-oc#cli-getting-started[Getting started with the CLI] for information about installing and configuring the {ocp-short} CLI.

* Your {ocp-short} permissions must allow you to create a namespace. Without a namespace, installation fails.

* You must have an Internet connection to access the dependencies for the operator.

* To install in a {ocp-short} Dedicated environment, see the following requirements:

** You must have the {ocp-short} Dedicated environment configured and running.

** You must have `cluster-admin` authority to the {ocp-short} Dedicated environment where you are installing the hub cluster.

** To import, you must use the `stable-2.0` channel of the klusterlet operator for {product-version}.

[#confirm-ocp-installation]
== Confirm your {ocp-short} installation

Verify that a {product-title-short} hub cluster is not already installed on your {ocp-short} cluster. You cannot have more than one hub cluster. 

You can only have one single {acm-short} hub cluster installation on each {ocp-short} cluster. Continue with the following steps if there is no {acm-short} hub cluster installed:

. To ensure that the {ocp-short} cluster is set up correctly, access the {ocp-short} web console with the following command:

+
----
oc -n openshift-console get route
----

+
See the following example output:

+
----
openshift-console console console-openshift-console.apps.new-coral.purple-chesterfield.com               
console   https   reencrypt/Redirect     None
----

. Open the URL in your browser and check the result. If the console URL displays `console-openshift-console.router.default.svc.cluster.local`, set the value for `openshift_master_default_subdomain` when you install {ocp-short}. See the following example of a URL: `https://console-openshift-console.apps.new-coral.purple-chesterfield.com`.

You can proceed to install {acm-short} from the console or the CLI. 

* <<installing-from-the-operatorhub,Installing from the OperatorHub web console interface>>
* <<installing-from-the-cli,Installing from the {ocp-short} CLI>>

[#installing-from-the-operatorhub]
== Installing from the OperatorHub web console interface

*Best practice:* From the _Administrator_ view in your console, install the OperatorHub web console interface that is provided with {ocp-short}.

. Select *Operators* > *OperatorHub* to access the list of available operators, and select _Advanced Cluster Management for Kubernetes_ operator.

. On the _Operator subscription_ page, select the options for your installation:

Channel:: The channel that you select corresponds to the release that you are installing. When you select the channel, it installs the identified release, and establishes that the future Errata updates within that release are obtained.

Namespace information:: The {acm-short} hub cluster must be installed in its own namespace, or project. 

- By default, the OperatorHub console installation process creates a namespace that is titled `open-cluster-management`. *Best practice:* Continue to use the `open-cluster-management` namespace if it is available.  
  
- If there is already a namespace named `open-cluster-management`, choose a different namespace.

Approval strategy for updates:: The approval strategy identifies the human interaction that is required for applying updates to the channel or release to which you subscribed. 

- Select *Automatic* to ensure any updates within that release are automatically applied. 
  
- Select *Manual* to receive a notification when an update is available. If you have concerns about when the updates are applied, this might be best practice for you.
+
*Important:* To upgrade to the next minor release, you must return to the _OperatorHub_ page and select a new channel for a more recent release.

. Select *Install* to apply your changes and create the operator. 

. Create the _MultiClusterHub_ custom resource.
 .. In the {ocp-short} console navigation, select *Installed Operators* > *Advanced Cluster Management for Kubernetes*.
 .. Select the *MultiClusterHub* tab.
 .. Select *Create MultiClusterHub*.
 .. Update the default values in the YAML file. See options in the _MultiClusterHub advanced configuration_ section of the documentation.

. Click to _MultiClusterHub_ tab to see the list of resources where your operator is listed.
 
* The following example shows the default template from the YAML view. Confirm that `namespace` is your project namespace. See the sample:

+
[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
----

+ 
. Select *Create* to initialize the custom resource. It can take up to 10 minutes for the {acm-short} hub cluster to build and deploy components.

+
After the {acm-short} hub cluster is created, the `MultiClusterHub` resource status displays _Running_ from the _MultiClusterHub_ tab of the {acm-short} operator details. 

To gain access to the console, see the link:../console/console_access.adoc#accessing-your-console[Accessing your console] topic.

[#installing-from-the-cli]
== Installing from the {ocp-short} CLI

Install the operator and the objects. Complete the following steps:

. Create a {acm-short} hub cluster namespace where the operator requirements are contained. Run the following command, where `namespace` is the name for your {acm-short} hub cluster namespace. The value for `namespace` might be referred to as _Project_ in the {ocp-short} environment:

+
[source,bash]
----
oc create namespace <namespace>
----

. Switch your project namespace to the one that you created. Replace `namespace` with the name of the {acm-short} hub cluster namespace that you created in step 1.

+
[source,bash]
----
oc project <namespace>
----

. Create a YAML file to configure an `OperatorGroup` resource. Each namespace can have only one operator group:

+
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: <default> <1>
  namespace: <namespace> <2>
spec:
  targetNamespaces:
  - <namespace>
----
<1> Replace `<default>` with the name of your operator group. 
<2> Replace `<namespace>` with the name of your project namespace. 

. Run the following command to create the `OperatorGroup` resource. Replace `operator-group` with the name of the operator group YAML file that you created:

+
[source,bash]
----
oc apply -f <path-to-file>/<operator-group>.yaml
----
+

. Create a YAML file to configure an {ocp-short} subscription to choose the version that you want to install. Your file is similar to the following sample, replacing `release-<2.x>` with the selected release:

+
[source,yaml]
----
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: acm-operator-subscription
spec:
  sourceNamespace: openshift-marketplace
  source: redhat-operators
  channel: release-<2.x>
  installPlanApproval: Automatic
  name: advanced-cluster-management
----

+
*Note:* For installing the {acm-short} hub cluster on infrastructure nodes, the see the xref:../install/install_connected.adoc#infra-olm-sub-add-config[{olm} Subscription additional configuration] section.

+
. Run the following command to apply the file and create the {ocp-short} subscription. Replace `subscription` with the name of the subscription file that you created:

+
[source,bash]
----
oc apply -f <path-to-file>/<subscription>.yaml
----

. Create a YAML file to configure the `MultiClusterHub` custom resource. Your default template should look similar to the following example. Replace `namespace` with your project namespace:

+
[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec: {}
----

+
*Note:* For installing the {acm-short} hub cluster on infrastructure nodes, see the xref:../install/install_connected.adoc#installing-on-infra-node[Installing the {acm-short} hub cluster on infrastructure nodes] section.

+
. Run the following command to apply the file and create the `MultiClusterHub` custom resource. Replace `custom-resource` with the name of your custom resource file:
 
+
[source,bash]
----
oc apply -f <path-to-file>/<custom-resource>.yaml
----

+
If you receive the following error, the resource process is still running. Run the `oc apply` command again in a few minutes when the resources are created:

+
----
error: unable to recognize "./mch.yaml": no matches for kind "MultiClusterHub" in version "operator.open-cluster-management.io/v1"
----

. Run the following command to get the custom resource. It can take up to 10 minutes for the `MultiClusterHub` custom resource status to display as `Running`:

+
[source,bash]
----
oc get mch -o yaml
----

If you are reinstalling {acm-short} and the pods do not start, see link:../troubleshooting/trouble_reinstall.adoc#troubleshooting-reinstallation-failure[Troubleshooting reinstallation failure] for steps to work around this problem.

*Notes:*

- A `ServiceAccount` with a `ClusterRoleBinding` automatically gives cluster administrator privileges to {acm-short} and to any user credentials with access to the namespace where you install {acm-short}.

- A namespace called `local-cluster` is reserved for the {product-title-short} hub cluster when it is self-managed. This is the only `local-cluster` namespace that can exist in the product. 

- *Important:* For security reasons, do not give access to the `local-cluster` namespace to any user that is not a `cluster-administrator`.

[#installing-on-infra-node]
== Installing the {acm-short} hub cluster on infrastructure nodes

An {ocp-short} cluster can be configured to contain infrastructure nodes for running approved management components. Running components on infrastructure nodes avoids allocating {ocp-short} subscription quota for the nodes that are running those management components.

After adding infrastructure nodes to your {ocp-short} cluster, follow the xref:../install/install_connected.adoc#installing-from-the-cli[Installing from the {ocp-short} CLI] instructions and add configurations to the {olm} subscription and `MultiClusterHub` custom resource.

[#adding-infra-nodes]
=== Add infrastructure nodes to the {ocp-short} cluster

Follow the procedures that are described in link:https://docs.redhat.com/documentation/en-us/openshift_container_platform/4.15/html/machine_management/creating-infrastructure-machinesets[Creating infrastructure machine sets] in the {ocp-short} documentation. Infrastructure nodes are configured with a Kubernetes `taint` and `label` to keep non-management workloads from running on them.

. To be compatible with the infrastructure node enablement provided by {acm-short}, ensure your infrastructure nodes have the following `taint` and `label` applied:

+
[source,yaml]
----
metadata:
  labels:
    node-role.kubernetes.io/infra: ""
spec:
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/infra
----

. Add the following additional configuration before applying the {olm} Subscription:

+
[source,yaml]
----
spec:
  config:
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    tolerations:
    - key: node-role.kubernetes.io/infra
      effect: NoSchedule
      operator: Exists
----

. Add the following additional configuration before you apply the `MultiClusterHub` custom resource:

+
[source,yaml]
----
spec:
  nodeSelector:
    node-role.kubernetes.io/infra: ""
----

[#additional-resources-install]

Learn about sizing, scaling, and advanced configuration.

* xref:../install/cluster_size.adoc#sizing-your-cluster[Sizing your cluster]
* xref:../install/perform_scale.adoc#performance-and-scalability[Performance and scalability]
* xref:../install/adv_config_install.adoc#advanced-config-hub[MultiClusterHub advanced configuration]
