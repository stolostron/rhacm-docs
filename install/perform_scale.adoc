[#performance-and-scalability]
= Performance and scalability

{product-title} is tested to determine certain scalability and performance data.
The major areas that are tested are cluster scalability and search performance.

You can use this information to help you plan your environment.

*Note:* Data is based on the results from a lab environment at the time of testing.
Your results might vary, depending on your environment, network speed, and changes to the product.

* <<maximum-number-of-managed-clusters,Maximum number of managed clusters>>
* <<search-scalability,Search scalability>>
* <<scaling-for-observability,Scaling for observability>>

[#maximum-number-of-managed-clusters]
== Maximum number of managed clusters

The maximum number of clusters that {product-title-short} can manage varies based on several factors, including:

* Number of resources in the cluster, which depends on factors like the number of policies and applications that are deployed.
* Configuration of the hub cluster, such as how many pods are used for scaling.

The following table shows the configuration information for the clusters on the Amazon Web Services cloud platform that were used during this testing:

|===
| Node | Flavor | vCPU | RAM (GiB) | Disk type | Disk size (GiB) | Count | Region

| Master
| m5.2xlarge
| 8
| 32
| gp2
| 100
| 3
| us-east-1

| Worker or Infrastructure
| m5.2xlarge
| 8
| 32
| gp2
| 100
| 3 or 5 nodes
| us-east-1
|===

For more information about infrastructure nodes, see, xref:../install/install_connected.adoc#installing-on-infra-node[Installing the {product-title-short} hub cluster on infrastructure nodes]. Also see link:https://docs.openshift.com/container-platform/4.10/machine_management/creating-infrastructure-machinesets.html[Creating infrastructure machine sets].

[#search-scalability]
== Search scalability

The scalability of the Search component depends on the performance of the data store.
The following variables are important when analyzing the search performance:

* Physical memory
* Write throughput (Cache recovery time)
* Query execution time

[#physical-memory]
=== Physical memory

Search keeps the data in-memory to achieve fast response times.
The memory required is proportional to the number of Kubernetes resources and their relationships in the cluster.

|===
| Clusters | Kubernetes resources | Relationships | Observed size (with simulated data)

| 1 medium
| 5000
| 9500
| 50 Mi

| 5 medium
| 25,000
| 75,000
| 120 Mi

| 15 medium
| 75,000
| 20,0000
| 492 Mi

| 30 medium
| 150,000
| 450,000
| 1 Gi

| 50 medium
| 250,000
| 750,000
| 2 Gi
|===

For more information on how you can change the amount of memory used for the search component, see link:../observability/search.adoc#options-increase-memory[Options to increase the redisgraph memory]. 

[#write-throughput-cache-recovery-time]
=== Write throughput (cache recovery time)

Most clusters in steady state generate a small number of resource updates.
The highest rate of updates happen when the data in RedisGraph is cleared, which causes the remote collectors to synchronize their full state around the same time. When the datastore is cleared, recovery times are measured for a different number of managed clusters.

|===
| Clusters | Kubernetes resources | Relationships | Average recovery time from simulation

| 1 medium
| 5000
| 9500
| less than 2 seconds

| 5 medium
| 25,000
| 75,000
| less than 15 seconds

| 15 medium
| 75,000
| 200,000
| 2 minutes and 40 seconds

| 30 medium
| 150,000
| 450,000
| 5-8 minutes
|===

*Remember:* Times might increase for clusters that have a slow network connection to the hub. The write throughput information that is previously stated is applicable only if `persistence` is disabled.

[#query-execution-considerations]
=== Query execution considerations

There are some things that can affect the time that it takes to run and return results from a query.
Consider the following items when planning and configuring your environment:

* Searching for a keyword is not efficient.
+
If you search for `RedHat` and you manage a large number of clusters, it might take a longer time to receive search results.

* The first search takes longer than later searches because it takes additional time to gather user role-based access control rules.
* The length of time to complete a request is proportional to the number of namespaces and resources the user is authorized to access.
+
*Note:* If you save and share a Search query with another user, returned results depend on access level for that user.
For more information on role access, see https://docs.openshift.com/container-platform/4.11/authentication/using-rbac.html[Using RBAC to define and apply permissions] in the {ocp-short} documentation.

//_Using RBAC Authorization_ in the https://kubernetes.io/docs/reference/access-authn-authz/rbac/[Kubernetes documentation].
* The worst performance is observed for a request by a non-administrator user with access to all of the namespaces, or all of the managed clusters.


[#scaling-for-observability]
== Scaling for observability

You need to plan your environment if you want to enable and use the observability service. The resource consumption later is for the {ocp-short} project, where observability components are installed. Values that you plan to use are sums for all observability components.

*Note:* Data is based on the results from a lab environment at the time of testing. Your results might vary, depending on your environment, network speed, and changes to the product.

[#sample-observability-environment]
=== Sample observability environment

In the sample environment, hub clusters and managed clusters are located in Amazon Web Services cloud platform and have the following topology and configuration:

|===
| Node | Flavor | vCPU | RAM (GiB) | Disk type | Disk size (GiB) | Count | Region

| Master node
| m5.4xlarge
| 16
| 64 
| gp2
| 100 
| 3
| sa-east-1

| Worker node
| m5.4xlarge
| 16
| 64 
| gp2
| 100
| 3
| sa-east-1
|===

The observability deployment is configured for high availability environments. With a high availability environment, each Kubernetes deployment has two instances, and each StatefulSet has three instances.

During the sample test, a different number of managed clusters are simulated to push metrics, and each test lasts for 24 hours. See the following throughput:

[#write-throughput]
=== Write throughput 

|===
| Pods| Interval (minute)| Time series per min

| 400
| 1
| 83000
|===

[#cpu-usage]
=== CPU usage (millicores)

CPU usage is stable during testing:

|===
| Size | CPU Usage 

| 10 clusters 
| 400
| 20 clusters 
| 800
|===

[#RSS-memory]
=== RSS and working set memory

View the following descriptions of the RSS and working set memory:

- *Memory usage RSS:* From the metrics `container_memory_rss` and remains stable during the test. 

- *Memory usage working set:* From the metrics `container_memory_working_set_bytes`, increases along with the test. 

The following results are from a 24-hour test:

|===
| Size| Memory usage RSS| Memory usage working set

| 10 clusters
| 9.84 
| 4.93

| 20 clusters
| 13.10
| 8.76
|===

[#persistent-volume-thanos]
=== Persistent volume for `thanos-receive` component

*Important:* Metrics are stored in `thanos-receive` until retention time (four days) is reached. Other components do not require as much volume as `thanos-receive` components.
 
Disk usage increases along with the test. Data represents disk usage after one day, so the final disk usage is multiplied by four. 

See the following disk usage:

|===
| Size| Disk usage (GiB)

| 10 clusters
| 2

| 20 clusters
| 3
|===


[#network-transfer]
=== Network transfer

During tests, network transfer provides stability. See the sizes and network transfer values:

|===
|Size | Inbound network transfer | Outbound network transfer

| 10 clusters
| 6.55 MBs per second
| 5.80 MBs per second

| 20 clusters
| 13.08 MBs per second
| 10.9 MBs per second
|===

[#s3-storage]
=== Amazon Simple Storage Service (S3)

Total usage in Amazon Simple Storage Service (S3) increases. The metrics data is stored in S3 until default retention time (five days) is reached. See the following disk usages:

|===
| Size| Disk usage (GiB)

| 10 clusters
| 16.2

| 20 clusters
| 23.8
|===
