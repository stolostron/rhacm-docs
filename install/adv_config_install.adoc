[#advanced-config-hub]
= MultiClusterHub advanced configuration 

{product-title} is installed by using an operator that deploys all of the required components. Some of the listed components are enabled by default. If a component is _disabled_, that resource is not deployed to the cluster until it is enabled. The operator works to deploy the following components:

.Table list of the deployed components
|===
| Name | Description | Enabled
| app-lifecycle | Unifies and simplifies options for constructing and deploying applications and application updates. | True
| cluster-backup | Provides backup and restore support for all hub cluster resources such as managed clusters, applications, and policies. | False
| cluster-lifecycle | Provides cluster management capabilities for {ocp-short} and {product-title-short} hub clusters. | True
| cluster-permission |  Automatically distributes RBAC resources to managed clusters and manage the lifecycle of those resources. | True
| console | Enables {product-title-short} web console plug-in. | True
| grc | Enables the security enhancement for you to define policies for your clusters. | True
| insights | Identifies existing or potential problems in your clusters. | True
| multicluster-observability | Enables monitoring to gain further insights into the health of your managed clusters. | True
| search | Provides visibility into your Kubernetes resources across all of your clusters. | True
| submariner-addon | Enables direct networking and service discovery between two or more managed clusters in your environment, either on-premises or in the cloud. | True
| volsync | Supports asynchronous replication of persistent volumes within a cluster, or across clusters with storage types that are not otherwise compatible for replication. | True
|===

When you install {product-title-short} on to the cluster, not all of the listed components are enabled by default.

You can further configure {product-title-short} during or after installation by adding one or more attributes to the `MultiClusterHub` custom resource. Continue reading for information about the attributes that you can add.

[#component-config]
== Console and component configuration

The following example displays the `spec.overrides` default template that you can use to enable or disable the component:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace> <1>
spec:
  overrides:
    components:
    - name: <name> <2>
      enabled: true
----
1. Replace `namespace` with the name of your project.
2. Replace `name` with the name of the component.

Alternatively, you can run the following command. Replace `namespace` with the name of your project and `name` with the name of the component:

----
oc patch MultiClusterHub multiclusterhub -n <namespace> --type=json -p='[{"op": "add", "path": "/spec/overrides/components/-","value":{"name":"<name>","enabled":true}}]'
----

*Note:* When the `console` component is disabled, the {ocp} console is disabled.

[#custom-image-pull-secret]
== Custom Image Pull Secret

If you plan to import Kubernetes clusters that were not created by {ocp-short} or {product-title-short}, generate a secret that has your {ocp-short} pull secret information to access the entitled content from the distribution registry. 

The secret requirements for {ocp-short} clusters are automatically resolved by {ocp-short} and {product-title-short}, so you do not have to create the secret if you are not importing other types of Kubernetes clusters to be managed. Your {ocp-short} pull secret is associated with your Red Hat Customer Portal ID, and is the same across all Kubernetes providers.

**Important:** These secrets are namespace-specific, so make sure that you are in the namespace that you use for your hub cluster.

. Go to link:https://cloud.redhat.com/openshift/install/pull-secret[cloud.redhat.com/openshift/install/pull-secret] to download the {ocp-short} pull secret file.
. Click *Download pull secret*.
. Run the following command to create your secret:
+
----
oc create secret generic <secret> -n <namespace> --from-file=.dockerconfigjson=<path-to-pull-secret> --type=kubernetes.io/dockerconfigjson
----
+
 - Replace `secret` with the name of the secret that you want to create.
 - Replace `namespace` with your project namespace, as the secrets are namespace-specific.
 - Replace `path-to-pull-secret` with the path to your {ocp-short} pull secret that you downloaded.

The following example displays the `spec.imagePullSecret` template to use if you want to use a custom pull secret. Replace secret with the name of your pull secret:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  imagePullSecret: <secret>
----

[#availability-config]
== availabilityConfig

The {product-title-short} hub cluster has two availabilities: `High` and `Basic`. By default, the hub cluster has an availability of `High`, which gives hub cluster components a `replicaCount` of `2`. This provides better support in cases of failover but consumes more resources than the `Basic` availability, which gives components a `replicaCount` of `1`.

*Important:* Set `spec.availabilityConfig` to `Basic` if you are using {mce-short} on a {sno} cluster.

The following example shows the `spec.availabilityConfig` template with `Basic` availability:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  availabilityConfig: "Basic"
----

[#node-selector]
== nodeSelector

You can define a set of node selectors in the {product-title-short} hub cluster to install to specific nodes on your cluster. The following example shows `spec.nodeSelector` to assign {product-title-short} pods to nodes with the label `node-role.kubernetes.io/infra`:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  nodeSelector:
    node-role.kubernetes.io/infra: ""
----

[#tolerations]
== tolerations

You can define a list of tolerations to allow the {product-title-short} hub cluster to tolerate specific taints defined on the cluster.

The following example shows a `spec.tolerations` that matches a `node-role.kubernetes.io/infra` taint:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  tolerations:
  - key: node-role.kubernetes.io/infra
    effect: NoSchedule
    operator: Exists
----

The previous infra-node toleration is set on pods by default without specifying any tolerations in the configuration. Customizing tolerations in the configuration replaces this default.

[#disable-hub-self-management]
== disableHubSelfManagement

By default, the {product-title-short} hub cluster is automatically imported and managed by itself. This _managed_ hub cluster is named, `local-cluster`. The setting that specifies whether a hub cluster manages itself is in the `multiclusterengine` custom resource. Changing this setting in {product-title-short} automatically changes the setting in the `multiclusterengine` custom resource. 

*Note:* On a {product-title-short} hub cluster that is managing a {mce-short} cluster, any earlier manual configurations are replaced by this action.

If you do not want the {product-title-short} hub cluster to manage itself, you need to change the setting for `spec.disableHubSelfManagement` from `false` to `true`. If the setting is not included in the YAML file that defines the custom resource, you need to add it. The hub cluster can only be managed with this option. 

Setting this option to `true` and attempting to manage the hub manually leads to unexpected behavior. 

The following example shows the default template to use if you want to disable the hub cluster self-management feature. Replace `namespace` with the name of your project:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  disableHubSelfManagement: true
----

To enable the default `local-cluster`, return the setting to `false`, or remove this setting.

[#disable-update-cluster-image-sets]
== disableUpdateClusterImageSets

If you want to ensure that you use the same release image for all of your clusters, you can create your own custom list of release images that are available when you create a cluster. 

See the following instructions in link:../clusters/cluster_lifecycle/release_image_connected.adoc#maintaining-a-custom-list-of-release-images-when-connected[Maintaining a custom list of release images when connected] to manage your available release images and to set the `spec.disableUpdateClusterImageSets` attribute, which stops the custom image list from being overwritten.

The following example shows the default template that disables updates to the cluster image set. Replace `namespace` with the name of your project:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  disableUpdateClusterImageSets: true
----

[#custom-ca-configmap]
== customCAConfigmap (Deprecated)

By default, {ocp} uses the Ingress Operator to create an internal CA. 

The following example shows the default template used to provide a customized {ocp-short} default ingress CA certificate to {product-title-short}. Replace `namespace` with the name of your project. Replace the `spec.customCAConfigmap` value with the name of your `ConfigMap`:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  customCAConfigmap: <configmap>
----

[#ssl-ciphers]
== sslCiphers (Deprecated)

By default, the {product-title-short} hub cluster includes the full list of supported SSL ciphers. 

The following example shows the default `spec.ingress.sslCiphers` template that is used to list `sslCiphers` for the management ingress. Replace `namespace` with the name of your project:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  ingress:
    sslCiphers:
    - "ECDHE-ECDSA-AES128-GCM-SHA256"
    - "ECDHE-RSA-AES128-GCM-SHA256"
----

[#cluster-backup]
== ClusterBackup

The `enableClusterBackup` field is no longer supported and is replaced by this component.

The following example shows the `spec.overrides` default template used to enable `ClusterBackup`. Replace `namespace` with the name of your project:

[source,yaml]
----
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: <namespace>
spec:
  overrides:
    components:
    - name: cluster-backup
      enabled: true
----

Alternatively, you can run the following command. Replace `namespace` with the name of your project.

----
oc patch MultiClusterHub multiclusterhub -n <namespace> --type=json -p='[{"op": "add", "path": "/spec/overrides/components/-","value":{"name":"cluster-backup","enabled":true}}]'
----
