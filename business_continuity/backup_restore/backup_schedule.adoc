[#using-backup-restore]
= Scheduling and restoring backups

Complete the following steps to schedule and restore backups:

. Use the backup and restore operator, `backupschedule.cluster.open-cluster-management.io`, to create a backup schedule and use the `restore.cluster.open-cluster-management.io` resources to restore a backup.

. Run the following command to create a `backupschedule.cluster.open-cluster-management.io` resource:
+
----
oc create -f cluster_v1beta1_backupschedule.yaml
----
+
Your `cluster_v1beta1_backupschedule.yaml` resource might resemble the following file:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: BackupSchedule
metadata:
  name: schedule-acm
  namespace: open-cluster-management-backup
spec:
  veleroSchedule: 0 */2 * * * <1>
  veleroTtl: 120h <2>
----
+
<1> Create a backup every 2 hours
<2> *Optional:* Deletes scheduled backups after 120h. If not specified, the maximum Velero default value of 720h is used.
+
View the following descriptions of the `backupschedule.cluster.open-cluster-management.io` `spec` properties:
+
** `veleroSchedule` is a required property and defines a cron job for scheduling the backups.
** `veleroTtl` is an optional property and defines the expiration time for a scheduled backup resource. If not specified, the maximum default value set by Velero is used, which is `720h`.

. Check the status of your `backupschedule.cluster.open-cluster-management.io` resource, which displays the definition for the three `schedule.velero.io` resources. Run the following command:
+
----
oc get BackupSchedule -n open-cluster-management-backup
----

. As a reminder, the restore operation is run on a different hub cluster for restore scenarios. To initiate a restore operation, create a `restore.cluster.open-cluster-management.io` resource on the hub cluster where you want to restore backups.
+
*Note:* When you restore a backup on a new hub cluster, make sure that you shut down the previous hub cluster where the backup was created. If it is running, the previous hub cluster tries to reimport the managed clusters as soon as the managed cluster reconciliation finds that the managed clusters are no longer available.
+
You can use the cluster backup and restore operator, `backupschedule.cluster.open-cluster-management.io` and `restore.cluster.open-cluster-management.io` resources, to create a backup or restore resource. See the _cluster-backup-operator_ samples.
+
. Run the following command to create a `restore.cluster.open-cluster-management.io` resource:
+
----
oc create -f cluster_v1beta1_backupschedule.yaml
----
+
Your resource might resemble the following file:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Restore
metadata:
  name: restore-acm
  namespace: open-cluster-management-backup
spec:
  veleroManagedClustersBackupName: latest
  veleroCredentialsBackupName: latest
  veleroResourcesBackupName: latest
----

. View the Velero `Restore` resource by running the following command:
+
----
oc get restore.velero.io -n open-cluster-management-backup
----

. View the {product-title-short} `Restore` events by running the following command:
+
----
oc describe restore.cluster.open-cluster-management.io -n open-cluster-management-backup
----

For descriptions of the parameters and samples of `Restore` YAML resources, see the _Restoring a backup_ section.

[#extend-backup-data]
== Extending backup data

You can backup third-party resources with cluster backup and restore by adding the `cluster.open-cluster-management.io/backup` label to the resources. The value of the label can be any string, including an empty string. Use a value that can help you identify the component that you are backing up. For example, use the `cluster.open-cluster-management.io/backup: idp` label if the components are provided by an IDP solution.

*Note:* Use the `cluster-activation` value for the `cluster.open-cluster-management.io/backup` label if you want the resources to be restored when the managed clusters activation resources are restored. Restoring the managed clusters activation resources result in managed clusters being actively managed by the hub cluster, where the restore was started.

[#schedule-backup]
== Scheduling a cluster backup

A backup schedule is activated when you create the `backupschedule.cluster.open-cluster-management.io` resource. View the following `backupschedule.cluster.open-cluster-management.io` sample:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: BackupSchedule
metadata:
  name: schedule-acm
  namespace: open-cluster-management-backup
spec:
  veleroSchedule: 0 */2 * * *
  veleroTtl: 120h
----

After you create a `backupschedule.cluster.open-cluster-management.io` resource, run the following command to get the status of the scheduled cluster backups:

----
oc get BackupSchedule -n open-cluster-management-backup
----

The `backupschedule.cluster.open-cluster-management.io` resource creates six `schedule.velero.io` resources, which are used to generate backups. Run the following command to view the list of the backups that are scheduled:

----
oc get schedules -A | grep acm
----

Resources are separately backed up in the groups as seen in the following table:

.Resource groups table
|===
| Resource | Description

| _Credentials backup_
| Backup file that stores Hive credentials, {product-title-short}, and user-created credentials and ConfigMaps.

| _Resources backup_
| Contains one backup for the {product-title-short} resources and one for generic resources. These resources use the `cluster.open-cluster-management.io/backup` label.

| _Managed clusters backup_
| Contains only resources that activate the managed cluster connection to the hub cluster, where the backup is restored.
|===

*Note:* The _resources backup_ file contains managed cluster-specific resources, but does not contain the subset of resources that connect managed clusters to the hub cluster. The resources that connect managed clusters are called activation resources and are contained in the managed clusters backup. When you restore backups only for the _credentials_ and _resources_ backup on a new hub cluster, the new hub cluster shows all managed clusters that are created by using the Hive API in a detached state. The managed clusters that are imported on the primary hub cluster by using the import operation appear only when the activation data is restored on the passive hub cluster. The managed clusters are still connected to the original hub cluster that created the backup files.

When the activation data is restored, only managed clusters created by using the Hive API are automatically connected with the new hub cluster. All other managed clusters appear in a _Pending_ state. You need to manually reattach them to the new cluster.

[#avoid-backup-collision]
=== Avoiding backup collisions

Backup collisions might occur if the hub cluster changes from being a passive hub cluster to becoming a primary hub cluster, or the other way around, and different managed clusters back up data at the same storage location.

As a result, the latest backups are generated by a hub cluster that is no longer set as the primary hub cluster. This hub cluster still produces backups because the `BackupSchedule.cluster.open-cluster-management.io` resource is still enabled.

See the following list to learn about two scenarios that might cause a backup collision:

. The primary hub cluster fails unexpectedly, which is caused by the following conditions:
- Communication from the primary hub cluster fails.
- The primary hub cluster backup data is restored on a secondary hub cluster, called the passive hub cluster.
- The administrator creates the `BackupSchedule.cluster.open-cluster-management.io` resource on the passive hub cluster, which is now the primary hub cluster and generates backup data to the common storage location.
- The primary hub cluster unexpectedly starts working again.
+
Since the `BackupSchedule.cluster.open-cluster-management.io` resource is still enabled on primary hub cluster, the primary hub cluster resumes writing backups to the same storage location as the passive hub cluster. Both hub clusters are now writing backup data at the same storage location. Any hub cluster restoring the latest backups from this storage location might use the primary hub cluster data instead of the passive hub cluster data.

. The administrator tests a disaster scenario by making the passive hub cluster a primary hub cluster, which is caused by the following conditions:
- The primary hub cluster is stopped.
- The primary hub cluster backup data is restored on the passive hub cluster.
- The administrator creates the `BackupSchedule.cluster.open-cluster-management.io` resource on the passive hub cluster, which is now the primary hub cluster and generates backup data to the common storage location.
- After the disaster test is completed, the administrator reverts to the previous state and reinstates the primary hub cluster. 
- The primary hub cluster starts while the passive hub cluster is still active.
+
Since the `BackupSchedule.cluster.open-cluster-management.io` resource is still enabled on the passive hub cluster, it writes backups at the same storage location that corrupts the backup data. Any hub cluster restoring the latest backups from this location might use the passive hub cluster data instead of the primary hub cluster data. In this scenario, stopping the passive hub cluster first or deleting the `BackupSchedule.cluster.open-cluster-management.io` resource on the passive hub cluster before starting the primary hub cluster fixes the backup collision issue.

. The administrator tests a disaster scenario by making the passive hub cluster a primary hub cluster, without stopping the primary hub cluster first, causing the following conditions: 
- The primary hub cluster is still running.
- The primary hub cluster backup data is restored on the passive hub cluster, including managed clusters backup. Therefore, the passive hub cluster is now the active cluster.
- Since the `BackupSchedule.cluster.open-cluster-management.io` resource is still enabled on the primary hub cluster, it writes backups at the same storage location which corrupts the backup data. For example, any hub cluster restoring the latest backups from this location might use the primary hub cluster data instead of the passive hub cluster data. To avoid data corruption, the primary hub cluster `BackupSchedule` resource status automatically changes to `BackupCollision`. In this scenario, to avoid getting into this backup collision state, stop the primary hub cluster first or delete the `BackupSchedule.cluster.open-cluster-management.io` resource on the primary hub cluster before restoring managed clusters data on  the passive hub cluster.
+
To avoid and report backup collisions, a `BackupCollision` state exists for the `BackupSchedule.cluster.open-cluster-management.io` resource. The controller checks regularly if the latest backup in the storage location has been generated from the current hub cluster. If not, a different hub cluster has recently written backup data to the storage location, indicating that the hub cluster is colliding with a different hub cluster.

In this case, the current hub cluster `BackupSchedule.cluster.open-cluster-management.io` resource status is set to `BackupCollision` and the `Schedule.velero.io` resources created by this resource are deleted to avoid data corruption. The `BackupCollision` is reported by the backup policy. The administrator verifies which hub cluster writes to the storage location, before removing the `BackupSchedule.cluster.open-cluster-management.io` resource from the invalid hub cluster and creating a new `BackupSchedule.cluster.open-cluster-management.io` resource on the valid primary hub cluster, to resume the backup.

Run the following command to check if there is a backup collision:

----
oc get backupschedule -A
----

If there is a backup collision, the output might resemble the following example:

----
NAMESPACE       NAME               PHASE             MESSAGE
openshift-adp   schedule-hub-1   BackupCollision   Backup acm-resources-schedule-20220301234625, from cluster with id [be97a9eb-60b8-4511-805c-298e7c0898b3] is using the same storage location. This is a backup collision with current cluster [1f30bfe5-0588-441c-889e-eaf0ae55f941] backup. Review and resolve the collision then create a new BackupSchedule resource to  resume backups from this cluster.
----

[#dr4hub-schedule-resources]
== Additional resources

- See the link:https://github.com/stolostron/cluster-backup-operator/tree/release-2.8/config/samples[_cluster-backup-operator_] samples.

- See the xref:../backup_restore/backup_restore.adoc#restore-backup[Restoring a backup] section for descriptions of the parameters and samples of `Restore` YAML resources.

- Return to <<using-backup-restore,Scheduling and restoring backups>>
